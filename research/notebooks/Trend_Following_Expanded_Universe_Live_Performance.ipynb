{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9713c5fc-1969-47a7-aef0-6da3d56d8410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary modules\n",
    "import os\n",
    "import sys\n",
    "import os, sys\n",
    "# from .../research/notebooks -> go up two levels to repo root\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.insert(0, repo_root)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as mtick\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score \n",
    "import pandas_datareader as pdr\n",
    "import math\n",
    "import datetime\n",
    "from datetime import datetime, timezone\n",
    "import itertools\n",
    "import ast\n",
    "import yfinance as yf\n",
    "import seaborn as sn\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from IPython.display import display, HTML\n",
    "from strategy_signal.trend_following_signal import (\n",
    "    apply_jupyter_fullscreen_css, get_trend_donchian_signal_for_portfolio_with_rolling_r_sqr_vol_of_vol\n",
    ")\n",
    "from portfolio.strategy_performance import (calculate_sharpe_ratio, calculate_calmar_ratio, calculate_CAGR, calculate_risk_and_performance_metrics,\n",
    "                                          calculate_compounded_cumulative_returns, estimate_fee_per_trade, rolling_sharpe_ratio)\n",
    "from utils import coinbase_utils as cn\n",
    "from portfolio import strategy_performance as perf\n",
    "from sizing import position_sizing_binary_utils as size_bin\n",
    "from sizing import position_sizing_continuous_utils as size_cont\n",
    "from strategy_signal import trend_following_signal as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2a93d8b-94a7-440a-81b8-8467d5e865b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'sizing.position_sizing_continuous_utils' from '/Users/adheerchauhan/Documents/git/trend_following/sizing/position_sizing_continuous_utils.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(cn)\n",
    "importlib.reload(perf)\n",
    "importlib.reload(tf)\n",
    "importlib.reload(size_bin)\n",
    "importlib.reload(size_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a92b4a2-7660-4d15-817b-21853ac5b7b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>:root {\n",
       "    --jp-notebook-max-width: 100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('Display.max_rows', None)\n",
    "pd.set_option('Display.max_columns',None)\n",
    "apply_jupyter_fullscreen_css()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eed7120-dc1d-4492-9891-4065452c1362",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bedc6782-f2ce-4d46-9bc2-6c99e9e530c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Config file for the strategy\n",
    "def load_prod_strategy_config(strategy_version='v0.1.0'):\n",
    "    nb_cwd = Path.cwd()  # git/trend_following/research/notebooks\n",
    "    config_path = (\n",
    "            nb_cwd.parents[1]  # -> git/trend_following\n",
    "            / \"live_strategy\"\n",
    "            / f\"trend_following_strategy_{strategy_version}-live\"\n",
    "            / \"config\"\n",
    "            / f\"trend_strategy_config_{strategy_version}.yaml\"\n",
    "    )\n",
    "\n",
    "    print(config_path)  # sanity check\n",
    "    print(config_path.exists())  # should be True\n",
    "\n",
    "    with open(config_path, \"r\") as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73bdf98-aaa7-4696-b7ef-3831ffde85ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def print_strategy_params():\n",
    "    \"\"\"\n",
    "    Pretty-print the strategy’s configuration values, with a blank line\n",
    "    separating each logical section.\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- Define sections (title is just for dev readability) --------------\n",
    "    sections = [\n",
    "        (\"Dates & universe\", OrderedDict([\n",
    "            (\"start_date\",      start_date),\n",
    "            (\"end_date\",        end_date),\n",
    "            (\"warm_up_days\",    WARMUP_DAYS),\n",
    "            (\"ticker_list\",     ticker_list),\n",
    "        ])),\n",
    "\n",
    "        (\"Moving-average / trend\", OrderedDict([\n",
    "            (\"fast_mavg\",                  fast_mavg),\n",
    "            (\"slow_mavg\",                  slow_mavg),\n",
    "            (\"mavg_stepsize\",              mavg_stepsize),\n",
    "            (\"mavg_z_score_window\",        mavg_z_score_window),\n",
    "            (\"moving_avg_type\",            moving_avg_type),\n",
    "            (\"ma_crossover_signal_weight\", ma_crossover_signal_weight),\n",
    "        ])),\n",
    "\n",
    "        (\"Donchian channel\", OrderedDict([\n",
    "            (\"entry_rolling_donchian_window\", entry_rolling_donchian_window),\n",
    "            (\"exit_rolling_donchian_window\", exit_rolling_donchian_window),\n",
    "            (\"use_donchian_exit_gate\", use_donchian_exit_gate),\n",
    "            (\"donchian_signal_weight\",  donchian_signal_weight),\n",
    "        ])),\n",
    "\n",
    "        (\"Volatility & risk\", OrderedDict([\n",
    "            (\"volatility_window\",            volatility_window),\n",
    "            (\"annualized_target_volatility\", annualized_target_volatility),\n",
    "            (\"rolling_cov_window\",           rolling_cov_window),\n",
    "            (\"rolling_atr_window\",           rolling_atr_window),\n",
    "            (\"atr_multiplier\",               atr_multiplier),\n",
    "            (\"log_std_window\",               log_std_window),\n",
    "            (\"coef_of_variation_window\",     coef_of_variation_window),\n",
    "            (\"vol_of_vol_z_score_window\",    vol_of_vol_z_score_window),\n",
    "            (\"vol_of_vol_p_min\",             vol_of_vol_p_min),\n",
    "            (\"r2_strong_threshold\",          r2_strong_threshold)\n",
    "        ])),\n",
    "\n",
    "        (\"Signal gating / quality\", OrderedDict([\n",
    "            (\"lower_r_sqr_limit\",             lower_r_sqr_limit),\n",
    "            (\"upper_r_sqr_limit\",             upper_r_sqr_limit),\n",
    "            (\"rolling_r2_window\",             rolling_r2_window),\n",
    "            (\"r2_smooth_window\",              r2_smooth_window),\n",
    "            (\"r2_confirm_days\",               r2_confirm_days),\n",
    "            (\"rolling_sharpe_window\",         rolling_sharpe_window),\n",
    "            (\"use_activation\",                use_activation),\n",
    "            (\"tanh_activation_constant_dict\", tanh_activation_constant_dict),\n",
    "            (\"weighted_signal_ewm_window\",    weighted_signal_ewm_window)\n",
    "        ])),\n",
    "\n",
    "        (\"Trading toggles & thresholds\", OrderedDict([\n",
    "            (\"long_only\",                  long_only),\n",
    "            (\"use_coinbase_data\",          use_coinbase_data),\n",
    "            (\"use_saved_files\",            use_saved_files),\n",
    "            (\"saved_file_end_date\",        saved_file_end_date),\n",
    "            (\"use_specific_start_date\",    use_specific_start_date),\n",
    "            (\"signal_start_date\",          signal_start_date),\n",
    "            (\"price_or_returns_calc\",      price_or_returns_calc),\n",
    "            (\"notional_threshold_pct\",     notional_threshold_pct),\n",
    "            (\"cooldown_counter_threshold\", cooldown_counter_threshold),\n",
    "            (\"warmup_days\",                WARMUP_DAYS)\n",
    "        ])),\n",
    "\n",
    "        (\"Capital & execution\", OrderedDict([\n",
    "            (\"initial_capital\",        initial_capital),\n",
    "            (\"cash_buffer_percentage\", cash_buffer_percentage),\n",
    "            (\"transaction_cost_est\",   transaction_cost_est),\n",
    "            (\"passive_trade_rate\",     passive_trade_rate),\n",
    "            (\"annual_trading_days\",    annual_trading_days),\n",
    "        ])),\n",
    "    ]\n",
    "\n",
    "    # ---- Compute width for neat alignment ---------------------------------\n",
    "    longest_key = max(len(k) for _, sec in sections for k in sec)\n",
    "\n",
    "    print(\"\\nStrategy Parameters\\n\" + \"-\" * (longest_key + 30))\n",
    "    for _, sec in sections:\n",
    "        for k, v in sec.items():\n",
    "            print(f\"{k:<{longest_key}} : {v}\")\n",
    "        print()  # blank line between sections\n",
    "    print(\"-\" * (longest_key + 30) + \"\\n\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Example usage (uncomment after your own parameter definitions are in scope)\n",
    "# ---------------------------------------------------------------------------\n",
    "# if __name__ == \"__main__\":\n",
    "#     print_strategy_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75baba8-c2c9-45e1-9efe-a0cca127acae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_signal_performance(df_1, df_2, ticker):\n",
    "\n",
    "    fig = plt.figure(figsize=(20,12))\n",
    "    layout = (2,2)\n",
    "    signal_ax = plt.subplot2grid(layout, (0,0))\n",
    "    price_ax = signal_ax.twinx()\n",
    "    equity_curve_ax = plt.subplot2grid(layout, (0,1))\n",
    "    sharpe_ax = plt.subplot2grid(layout, (1,0))\n",
    "    portfolio_value_ax = plt.subplot2grid(layout, (1,1))\n",
    "\n",
    "    _ = signal_ax.plot(df_1.index, df_1[f'{ticker}_final_signal'], label='Orig Signal', alpha=0.9)\n",
    "    _ = signal_ax.plot(df_2.index, df_2[f'{ticker}_final_signal'], label='New Signal', alpha=0.9)\n",
    "    _ = price_ax.plot(df_1.index, df_2[f'{ticker}_open'], label='Price', alpha=0.7, linestyle='--', color='magenta')\n",
    "    _ = signal_ax.set_title(f'Orignal Signal vs New Signal')\n",
    "    _ = signal_ax.set_ylabel('Signal')\n",
    "    _ = signal_ax.set_xlabel('Date')\n",
    "    _ = signal_ax.legend(loc='upper left')\n",
    "    _ = signal_ax.grid()\n",
    "\n",
    "    _ = equity_curve_ax.plot(df_1.index, df_1[f'equity_curve'], label='Orig Signal', alpha=0.9)\n",
    "    _ = equity_curve_ax.plot(df_2.index, df_2[f'equity_curve'], label='New Signal', alpha=0.9)\n",
    "    _ = equity_curve_ax.set_title(f'Equity Curve')\n",
    "    _ = equity_curve_ax.set_ylabel('Equity Curve')\n",
    "    _ = equity_curve_ax.set_xlabel('Date')\n",
    "    _ = equity_curve_ax.legend(loc='upper left')\n",
    "    _ = equity_curve_ax.grid()\n",
    "\n",
    "    _ = sharpe_ax.plot(df_1.index, df_1[f'portfolio_rolling_sharpe_50'], label='Orig Signal', alpha=0.9)\n",
    "    _ = sharpe_ax.plot(df_2.index, df_2[f'portfolio_rolling_sharpe_50'], label='New Signal', alpha=0.9)\n",
    "    _ = sharpe_ax.set_title(f'Rolling Sharpe')\n",
    "    _ = sharpe_ax.set_ylabel(f'Rolling Sharpe')\n",
    "    _ = sharpe_ax.set_xlabel('Date')\n",
    "    _ = sharpe_ax.legend(loc='upper left')\n",
    "    _ = sharpe_ax.grid()\n",
    "\n",
    "    _ = portfolio_value_ax.plot(df_1.index, df_1[f'total_portfolio_value'], label='Orig Signal', alpha=0.9)\n",
    "    _ = portfolio_value_ax.plot(df_2.index, df_2[f'total_portfolio_value'], label='New Signal', alpha=0.9)\n",
    "    _ = portfolio_value_ax.set_title(f'Total Portfolio Value')\n",
    "    _ = portfolio_value_ax.set_ylabel('Portfolio Value')\n",
    "    _ = portfolio_value_ax.set_xlabel('Date')\n",
    "    _ = portfolio_value_ax.legend(loc='upper left')\n",
    "    _ = portfolio_value_ax.grid()\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75161822-57c5-4298-9c09-a3c0b2bb5e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_prod_strategy_config(strategy_version='v0.2.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17e723c-7bab-44e2-ae8e-19901a31429b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# assume cfg is already loaded from YAML as shown in your message\n",
    "\n",
    "# --- Prod Configuration (from cfg) ---\n",
    "start_date  = pd.Timestamp(cfg['run']['start_date']).date()\n",
    "end_date    = pd.Timestamp(cfg['run']['end_date']).date()\n",
    "warmup_days = int(cfg['run']['warmup_days'])\n",
    "\n",
    "portfolio_name = cfg['portfolio']['name']\n",
    "ticker_list = list(cfg['universe']['tickers'])\n",
    "\n",
    "## Get Sleeve Budgets\n",
    "sleeve_budgets = cfg['universe']['sleeves']\n",
    "ticker_to_sleeve = {}\n",
    "for sleeve in sleeve_budgets.keys():\n",
    "    sleeve_tickers = sleeve_budgets[sleeve]['tickers']\n",
    "    for ticker in sleeve_tickers:\n",
    "        ticker_to_sleeve[ticker] = sleeve\n",
    "risk_min_signal = float(cfg['risk_and_sizing']['risk_min_signal'])\n",
    "sleeve_risk_mode = str(cfg['risk_and_sizing']['sleeve_risk_mode']).strip().lower()\n",
    "risk_sleeve_budget_tolerance = float(cfg['risk_and_sizing']['risk_sleeve_budget_tolerance'])\n",
    "risk_optimizer_step = float(cfg['risk_and_sizing']['risk_optimizer_step'])\n",
    "risk_max_iterations = int(cfg['risk_and_sizing']['risk_max_iterations'])\n",
    "\n",
    "# signals.moving_average\n",
    "fast_mavg        = int(cfg['signals']['moving_average']['fast_mavg'])\n",
    "slow_mavg        = int(cfg['signals']['moving_average']['slow_mavg'])\n",
    "mavg_stepsize    = int(cfg['signals']['moving_average']['mavg_stepsize'])\n",
    "mavg_z_score_window = int(cfg['signals']['moving_average']['mavg_z_score_window'])\n",
    "\n",
    "# signals.donchian\n",
    "entry_rolling_donchian_window = int(cfg['signals']['donchian']['entry_rolling_donchian_window'])\n",
    "exit_rolling_donchian_window  = int(cfg['signals']['donchian']['exit_rolling_donchian_window'])\n",
    "use_donchian_exit_gate        = bool(cfg['signals']['donchian']['use_donchian_exit_gate'])\n",
    "\n",
    "# signals.weighting\n",
    "ma_crossover_signal_weight = float(cfg['signals']['weighting']['ma_crossover_signal_weight'])\n",
    "donchian_signal_weight     = float(cfg['signals']['weighting']['donchian_signal_weight'])\n",
    "weighted_signal_ewm_window = int(cfg['signals']['weighting']['weighted_signal_ewm_window'])  # (new config but same value)\n",
    "\n",
    "# signals.filters.rolling_r2\n",
    "rolling_r2_window   = int(cfg['signals']['filters']['rolling_r2']['rolling_r2_window'])\n",
    "lower_r_sqr_limit   = float(cfg['signals']['filters']['rolling_r2']['lower_r_sqr_limit'])\n",
    "upper_r_sqr_limit   = float(cfg['signals']['filters']['rolling_r2']['upper_r_sqr_limit'])\n",
    "r2_smooth_window    = int(cfg['signals']['filters']['rolling_r2']['r2_smooth_window'])\n",
    "r2_confirm_days     = int(cfg['signals']['filters']['rolling_r2']['r2_confirm_days'])\n",
    "r2_strong_threshold = float(cfg['signals']['filters']['rolling_r2']['r2_strong_threshold'])\n",
    "\n",
    "# signals.filters.vol_of_vol\n",
    "log_std_window            = int(cfg['signals']['filters']['vol_of_vol']['log_std_window'])\n",
    "coef_of_variation_window  = int(cfg['signals']['filters']['vol_of_vol']['coef_of_variation_window'])\n",
    "vol_of_vol_z_score_window = int(cfg['signals']['filters']['vol_of_vol']['vol_of_vol_z_score_window'])\n",
    "vol_of_vol_p_min          = float(cfg['signals']['filters']['vol_of_vol']['vol_of_vol_p_min'])\n",
    "\n",
    "# signals.activation\n",
    "use_activation              = bool(cfg['signals']['activation']['use_activation'])\n",
    "tanh_activation_constant_dict = cfg['signals']['activation']['tanh_activation_constant_dict']  # likely None\n",
    "\n",
    "# data / run toggles\n",
    "moving_avg_type        = str(cfg['data']['moving_avg_type'])\n",
    "long_only              = bool(cfg['run']['long_only'])\n",
    "price_or_returns_calc  = str(cfg['data']['price_or_returns_calc'])\n",
    "\n",
    "initial_capital        = float(cfg['run']['initial_capital'])\n",
    "\n",
    "rolling_cov_window     = int(cfg['risk_and_sizing']['rolling_cov_window'])\n",
    "volatility_window      = int(cfg['risk_and_sizing']['volatility_window'])\n",
    "\n",
    "# stop loss strategy (new)\n",
    "stop_loss_strategy     = str(cfg['risk_and_sizing']['stop_loss_strategy'])\n",
    "rolling_atr_window     = int(cfg['risk_and_sizing']['rolling_atr_window'])\n",
    "atr_multiplier         = float(cfg['risk_and_sizing']['atr_multiplier'])\n",
    "highest_high_window    = int(cfg['risk_and_sizing']['highest_high_window'])\n",
    "\n",
    "# cooldown (new)\n",
    "cooldown_counter_threshold = int(cfg['execution_and_costs']['cooldown_counter_threshold'])\n",
    "\n",
    "# target vol (new value)\n",
    "annualized_target_volatility = float(cfg['risk_and_sizing']['annualized_target_volatility'])\n",
    "\n",
    "transaction_cost_est   = float(cfg['execution_and_costs']['transaction_cost_est'])\n",
    "passive_trade_rate     = float(cfg['execution_and_costs']['passive_trade_rate'])\n",
    "notional_threshold_pct = float(cfg['execution_and_costs']['notional_threshold_pct'])\n",
    "\n",
    "rolling_sharpe_window  = int(cfg['risk_and_sizing']['rolling_sharpe_window'])\n",
    "cash_buffer_percentage = float(cfg['risk_and_sizing']['cash_buffer_percentage'])\n",
    "annual_trading_days    = int(cfg['run']['annual_trading_days'])\n",
    "\n",
    "use_coinbase_data      = bool(cfg['data']['use_coinbase_data'])\n",
    "use_saved_files        = bool(cfg['data']['use_saved_files'])\n",
    "saved_file_end_date    = str(cfg['data']['saved_file_end_date'])\n",
    "\n",
    "use_specific_start_date = bool(cfg['run']['use_specific_start_date'])\n",
    "signal_start_date       = pd.Timestamp(cfg['run']['signal_start_date']).date()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffba9c53-8d82-49c9-9ad1-a65875d1a245",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a931b2-4a65-4a4b-8b1c-daaffe4ab140",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleeve_budgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cc3cf6-a968-4993-b15f-87f9c5661ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(risk_min_signal)\n",
    "print(sleeve_risk_mode)\n",
    "print(risk_sleeve_budget_tolerance)\n",
    "print(risk_optimizer_step)\n",
    "print(risk_max_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da386c13-f5e5-426e-8e15-2d2650e73894",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = start_date\n",
    "end_date = datetime.now(timezone.utc).date()#- pd.Timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02e9f91-79da-46f1-9af6-5a9f5a99ca97",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef88fb6-c714-4721-a629-3c7847d4b85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9e532d-4dd2-410d-9246-39eb215eabfc",
   "metadata": {},
   "source": [
    "## Expanded Universe Production Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69767970-fa80-4aef-98f5-4fa0ef43ceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate a multiplier by date that when applied to the volatility adjusted signals, brings the\n",
    "## risk contribution of each sleeve close to the allocated Risk Budget per sleeve\n",
    "def risk_budget_by_sleeve_optimized_by_signal(signals, daily_cov_matrix, ticker_list, ticker_to_sleeve, sleeve_budgets,\n",
    "                                              max_iter=100, tol=1e-5, step=0.5,\n",
    "                                              min_signal_eps=1e-4,\n",
    "                                              mode=\"cap\" # \"cap\" = treat budgets as max, \"target\" = your current behaviour\n",
    "                                             ):\n",
    "    \"\"\"\n",
    "    signals: 1d np.array of base weights (vol-adjusted signals), length N\n",
    "    daily_cov_matrix: NxN covariance matrix\n",
    "    ticker_to_sleeve: dict {ticker: sleeve_name}\n",
    "    sleeve_budgets:   dict {sleeve_name: {'weight': target_risk_share}}\n",
    "\n",
    "    mode:\n",
    "      - \"cap\": only reduce risk of sleeves whose risk_share > budget\n",
    "      - \"target\": symmetric adjustment (your original behaviour)\n",
    "    \"\"\"\n",
    "    ## Convert signals and covariance matrix to floating point numbers\n",
    "    signals = np.asarray(signals, dtype=float)\n",
    "    daily_cov_matrix = np.asarray(daily_cov_matrix, dtype=float)\n",
    "    \n",
    "    ## Get a list of all Sleeves in the Portfolio\n",
    "    sleeves = list(sleeve_budgets.keys())\n",
    "\n",
    "    ## Start with a Multiplier of 1 for Each Sleeve\n",
    "    risk_multiplier = {s: 1.0 for s in sleeves}\n",
    "\n",
    "    ## Identify active sleeves based on signal magnitude\n",
    "    sleeve_signal_abs = {s: 0.0 for s in sleeves}\n",
    "    for i, t in enumerate(ticker_list):\n",
    "        s = ticker_to_sleeve[t]\n",
    "        sleeve_signal_abs[s] += abs(signals[i])\n",
    "    active_sleeves = {s for s in sleeves if sleeve_signal_abs[s] > min_signal_eps}\n",
    "\n",
    "    ## If no sleeve has any signal, just return zeros\n",
    "    if not active_sleeves:\n",
    "        return np.zeros_like(signals, dtype=float), risk_multiplier\n",
    "\n",
    "    ## If only one sleeve is active, no need for optimization – just use original signals\n",
    "    if len(active_sleeves) == 1:\n",
    "        return np.asarray(signals, dtype=float), risk_multiplier\n",
    "\n",
    "    ## Renormalize budgets over active sleeves only (optional but helpful)\n",
    "    total_budget_active = sum(sleeve_budgets[s]['weight'] for s in active_sleeves)\n",
    "    eff_budget = {}\n",
    "    for s in sleeves:\n",
    "        if s in active_sleeves and total_budget_active > 0:\n",
    "            eff_budget[s] = sleeve_budgets[s]['weight'] / total_budget_active\n",
    "        else:\n",
    "            eff_budget[s] = 0.0\n",
    "\n",
    "    ## Iterate through to calculate the multiplier to minimize the max absolute error between the \n",
    "    ## allocated and actual risk budgets per sleeve\n",
    "    for _ in range(max_iter):\n",
    "        ## Build weights per ticker multiplying the vol adjusted signal with the current multiplier\n",
    "        sleeve_risk_adj_weights = np.array([signals[i] * risk_multiplier[ticker_to_sleeve[t]] for i, t in enumerate(ticker_list)])\n",
    "\n",
    "        ## If all signals are zero return\n",
    "        if np.allclose(sleeve_risk_adj_weights, 0):\n",
    "            return sleeve_risk_adj_weights, risk_multiplier\n",
    "\n",
    "        ## Calculate the Portfolio Variance and Standard Deviaition for today given the current weights\n",
    "        sigma2 = float(sleeve_risk_adj_weights @ daily_cov_matrix @ sleeve_risk_adj_weights)\n",
    "        sigma = np.sqrt(sigma2)\n",
    "        \n",
    "        ## Calculate the Marginal Risk Contribution to Portfolio Risk\n",
    "        ## This calculates the unit change in the portfolio volatility for a unit change in the weight of a coin\n",
    "        ## This is essentially the first derivative of portfolio weight wrt signal weight w\n",
    "        ## σ(w) = sqrt(w⊤Σw)\n",
    "        ## ∂σ/∂w ​= 1 / (2*sqrt(w⊤Σw)) * 2Σw = Σw / σ​\n",
    "        marginal_risk_unit = daily_cov_matrix @ sleeve_risk_adj_weights / sigma   # length N\n",
    "        \n",
    "        ## This calculates the risk contribution per coin\n",
    "        ## This metric shows how much of the portfolio volatility comes from each coin in the portfolio\n",
    "        ## Important Property: Sum of the risk contribution of all coins equals the portfolio volatility\n",
    "        ## RCi ​= wi​ * marginali ​= wi​ * (Σw)i / σ\n",
    "        risk_contribution_coin = sleeve_risk_adj_weights * marginal_risk_unit      # length N\n",
    "\n",
    "        ## Calculate sleeve level volatility metrics and risk share\n",
    "        ## RCs​ = i∈s∑ ​RCi​\n",
    "        risk_contribution_sleeve = {s: 0.0 for s in sleeves}\n",
    "        for i, t in enumerate(ticker_list):\n",
    "            s = ticker_to_sleeve[t]\n",
    "            risk_contribution_sleeve[s] += risk_contribution_coin[i]\n",
    "\n",
    "        ## Calculate percent of risk contribution per sleeve or risk share\n",
    "        ## s∑​risk_shares ​= 1/σ * ∑​RCs ​= 1/σ * ​i∑​RCi ​= 1\n",
    "        risk_share_sleeve = {s: risk_contribution_sleeve[s] / sigma for s in sleeves}\n",
    "\n",
    "        ## Calculate the maximum absolute difference between actual risk share per sleeve and desired risk budget\n",
    "        ## If the maximum absolute difference is below the tolerance threshold, we exit and keep the calculated multiplier\n",
    "        # risk_allocation_error = max(abs(risk_share_sleeve[s] - sleeve_budgets[s]['weight']) for s in sleeves)\n",
    "        risk_allocation_error = max(abs(risk_share_sleeve[s] - eff_budget[s]) for s in active_sleeves)\n",
    "        if risk_allocation_error < tol:\n",
    "            break\n",
    "\n",
    "        ## Multiplicative Update: \n",
    "        ## If a sleeve has too much risk, we shrink its multiplier\n",
    "        ### For too much risk, desired risk budget / actual risk per sleeve is less than 1\n",
    "        ### We square this fraction by the step leading to a smaller multiplier for the next iteration\n",
    "        \n",
    "        ## If a sleeve has too little risk, we grow its multiplier\n",
    "        ### For too little risk, desired risk budget / actual risk per sleeve is greater than 1\n",
    "        ### We square this fraction by the step leading to a larger multiplier for the next iteration\n",
    "        for s in active_sleeves:\n",
    "            rs = risk_share_sleeve[s]\n",
    "            b = eff_budget[s]\n",
    "            if rs <= 0:\n",
    "                continue\n",
    "\n",
    "            if mode == 'target':\n",
    "                ratio = b / rs\n",
    "                risk_multiplier[s] *= ratio ** step\n",
    "\n",
    "            elif mode == 'cap':\n",
    "                ## only shrink sleeves that are ABOVE their budget\n",
    "                if rs > b and b > 0:\n",
    "                    ratio = b / rs\n",
    "                    risk_multiplier[s] *= ratio ** step\n",
    "                ## if rs <= b, leave multiplier unchanged (don't lever up weak sleeves)\n",
    "\n",
    "    ## Final Sleeve Risk Adjusted Weights\n",
    "    sleeve_risk_adj_weights = np.array([signals[i] * risk_multiplier[ticker_to_sleeve[t]]\n",
    "                                        for i, t in enumerate(ticker_list)], dtype=float)\n",
    "    \n",
    "    return sleeve_risk_adj_weights, risk_multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bde4a4e-ed9b-45ea-8eda-1b6683293f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_volatility_daily_portfolio_positions_with_risk_multiplier_sleeve_weights_opt(df, ticker_list, initial_capital, rolling_cov_window,\n",
    "                                                                                            stop_loss_strategy, rolling_atr_window, atr_multiplier,\n",
    "                                                                                            highest_high_window, cash_buffer_percentage,\n",
    "                                                                                            annualized_target_volatility, transaction_cost_est=0.001,\n",
    "                                                                                            passive_trade_rate=0.05, notional_threshold_pct=0.02,\n",
    "                                                                                            min_trade_notional_abs=10, cooldown_counter_threshold=3,\n",
    "                                                                                            annual_trading_days=365, use_specific_start_date=False,\n",
    "                                                                                            signal_start_date=None, ticker_to_sleeve=None,\n",
    "                                                                                            sleeve_budgets=None, risk_max_iterations=None, risk_sleeve_budget_tolerance=None,\n",
    "                                                                                            risk_optimizer_step=None, risk_min_signal=None, sleeve_risk_mode=None):\n",
    "\n",
    "    # ensure DatetimeIndex (tz-naive), normalized, sorted\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        df.index = pd.to_datetime(df.index, utc=True).tz_localize(None)\n",
    "    elif df.index.tz is not None:\n",
    "        df.index = df.index.tz_localize(None)\n",
    "    df.index = df.index.normalize()\n",
    "    df.sort_index(inplace=True)\n",
    "\n",
    "    ## Calculate the covariance matrix for tickers in the portfolio\n",
    "    returns_cols = [f'{ticker}_t_1_close_pct_returns' for ticker in ticker_list]\n",
    "    cov_matrix = df[returns_cols].rolling(rolling_cov_window).cov(pairwise=True).dropna()\n",
    "\n",
    "    ## Delete rows prior to the first available date of the covariance matrix\n",
    "    cov_matrix_start_date = cov_matrix.index[0][0]\n",
    "    df = df[df.index >= cov_matrix_start_date]\n",
    "\n",
    "    ## Derive the Daily Target Portfolio Volatility\n",
    "    daily_target_volatility = annualized_target_volatility / np.sqrt(annual_trading_days)\n",
    "\n",
    "    ## Reorder dataframe columns\n",
    "    for ticker in ticker_list:\n",
    "        df[f'{ticker}_new_position_size'] = 0.0\n",
    "        df[f'{ticker}_new_position_notional'] = 0.0\n",
    "        df[f'{ticker}_open_position_size'] = 0.0\n",
    "        df[f'{ticker}_open_position_notional'] = 0.0\n",
    "        df[f'{ticker}_actual_position_size'] = 0.0\n",
    "        df[f'{ticker}_actual_position_notional'] = 0.0\n",
    "        df[f'{ticker}_short_sale_proceeds'] = 0.0\n",
    "        df[f'{ticker}_new_position_entry_exit_price'] = 0.0\n",
    "        df[f'{ticker}_target_vol_normalized_weight'] = 0.0\n",
    "        df[f'{ticker}_target_notional'] = 0.0\n",
    "        df[f'{ticker}_target_size'] = 0.0\n",
    "        df[f'{ticker}_stop_loss'] = 0.0\n",
    "        df[f'{ticker}_stopout_flag'] = False\n",
    "        df[f'{ticker}_cooldown_counter'] = 0.0\n",
    "        df[f'{ticker}_sleeve_risk_multiplier'] = 0.0\n",
    "        df[f'{ticker}_sleeve_risk_adj_weights'] = 0.0\n",
    "        df[f'{ticker}_event'] = np.nan\n",
    "    ord_cols = size_bin.reorder_columns_by_ticker(df.columns, ticker_list)\n",
    "    df = df[ord_cols]\n",
    "\n",
    "    ## Portfolio Level Cash and Positions are all set to 0\n",
    "    df['daily_portfolio_volatility'] = 0.0\n",
    "    df['available_cash'] = 0.0\n",
    "    df['count_of_positions'] = 0.0\n",
    "    df['total_actual_position_notional'] = 0.0\n",
    "    df['total_target_notional'] = 0.0\n",
    "    df['total_portfolio_value'] = 0.0\n",
    "    df['total_portfolio_value_upper_limit'] = 0.0\n",
    "    df['target_vol_scaling_factor'] = 1.0\n",
    "    df['cash_scaling_factor'] = 1.0\n",
    "    df['final_scaling_factor'] = 1.0\n",
    "    df[f'cash_shrink_factor'] = 1.0\n",
    "\n",
    "    ## Cash and the Total Portfolio Value on Day 1 is the initial capital for the strategy\n",
    "    if use_specific_start_date and signal_start_date is not None:\n",
    "        # start_index_position = df.index.get_loc(signal_start_date)\n",
    "        key = pd.Timestamp(signal_start_date).normalize()\n",
    "        start_index_position = df.index.get_loc(key)\n",
    "    else:\n",
    "        start_index_position = 0\n",
    "    df['available_cash'][start_index_position] = initial_capital\n",
    "    df['total_portfolio_value'][start_index_position] = initial_capital\n",
    "\n",
    "    ## Identify Daily Positions starting from day 2\n",
    "    for date in df.index[start_index_position + 1:]:\n",
    "        previous_date = df.index[df.index.get_loc(date) - 1]\n",
    "\n",
    "        ## Start the day with the available cash from yesterday\n",
    "        df['available_cash'].loc[date] = df['available_cash'].loc[previous_date]\n",
    "\n",
    "        ## Roll Portfolio Value from the Previous Day\n",
    "        total_portfolio_value = df['total_portfolio_value'].loc[previous_date]\n",
    "        df['total_portfolio_value'].loc[date] = total_portfolio_value\n",
    "\n",
    "        ## Update Total Portfolio Value Upper Limit based on the Total Portfolio Value\n",
    "        total_portfolio_value_upper_limit = (df['total_portfolio_value'].loc[date] *\n",
    "                                             (1 - cash_buffer_percentage))\n",
    "        df['total_portfolio_value_upper_limit'].loc[date] = total_portfolio_value_upper_limit\n",
    "\n",
    "        ## Calculate the target notional by ticker\n",
    "        df = get_target_volatility_position_sizing_with_risk_multiplier_sleeve_weights_opt(df, cov_matrix, date, ticker_list, daily_target_volatility,\n",
    "                                                                                           total_portfolio_value_upper_limit, ticker_to_sleeve, sleeve_budgets,\n",
    "                                                                                           risk_max_iterations, risk_sleeve_budget_tolerance,\n",
    "                                                                                           risk_optimizer_step, risk_min_signal, sleeve_risk_mode)\n",
    "\n",
    "        ## Adjust Positions for Cash Available\n",
    "        desired_positions, cash_shrink_factor = size_cont.get_cash_adjusted_desired_positions(\n",
    "            df, date, previous_date, ticker_list, cash_buffer_percentage, transaction_cost_est, passive_trade_rate,\n",
    "            total_portfolio_value, notional_threshold_pct, min_trade_notional_abs)\n",
    "\n",
    "        ## Get the daily positions\n",
    "        df = size_cont.get_daily_positions_and_portfolio_cash(\n",
    "            df, date, previous_date, desired_positions, cash_shrink_factor, ticker_list,\n",
    "            stop_loss_strategy, rolling_atr_window, atr_multiplier, highest_high_window,\n",
    "            transaction_cost_est, passive_trade_rate, cooldown_counter_threshold)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c9641b-3425-41a8-9418-739ce1278e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_volatility_position_sizing_with_risk_multiplier_sleeve_weights_opt(df, cov_matrix, date, ticker_list, daily_target_volatility,\n",
    "                                                                                  total_portfolio_value_upper_limit, ticker_to_sleeve, sleeve_budgets, risk_max_iterations, risk_sleeve_budget_tolerance,\n",
    "                                                                                  risk_optimizer_step, risk_min_signal, sleeve_risk_mode):\n",
    "\n",
    "    ## Scale weights of positions to ensure the portfolio is in line with the target volatility\n",
    "    unscaled_weight_cols = [f'{ticker}_vol_adjusted_trend_signal' for ticker in ticker_list]\n",
    "    scaled_weight_cols = [f'{ticker}_target_vol_normalized_weight' for ticker in ticker_list]\n",
    "    target_notional_cols = [f'{ticker}_target_notional' for ticker in ticker_list]\n",
    "    t_1_price_cols = [f'{ticker}_t_1_close' for ticker in ticker_list]\n",
    "    returns_cols = [f'{ticker}_t_1_close_pct_returns' for ticker in ticker_list]\n",
    "    sleeve_risk_multiplier_cols = [f'{ticker}_sleeve_risk_multiplier' for ticker in ticker_list]\n",
    "    sleeve_risk_adj_cols = [f'{ticker}_sleeve_risk_adj_weights' for ticker in ticker_list]\n",
    "\n",
    "    if date not in df.index or date not in cov_matrix.index:\n",
    "        raise ValueError(f\"Date {date} not found in DataFrame or covariance matrix index.\")\n",
    "\n",
    "    ## Iterate through each day and get the unscaled weights and calculate the daily covariance matrix\n",
    "    daily_weights = df.loc[date, unscaled_weight_cols].values\n",
    "    daily_cov_matrix = cov_matrix.loc[date].loc[returns_cols, returns_cols].values\n",
    "    \n",
    "    ## Apply the Sleeve Risk Adjusted Multiplier to the Daily Weights\n",
    "    if ticker_to_sleeve is not None and sleeve_budgets is not None:\n",
    "        rb_weights, sleeve_risk_multiplier = risk_budget_by_sleeve_optimized_by_signal(\n",
    "            signals=daily_weights,\n",
    "            daily_cov_matrix=daily_cov_matrix,\n",
    "            ticker_list=ticker_list,\n",
    "            ticker_to_sleeve=ticker_to_sleeve,\n",
    "            sleeve_budgets=sleeve_budgets,\n",
    "            max_iter=risk_max_iterations,\n",
    "            tol=risk_sleeve_budget_tolerance,\n",
    "            step=risk_optimizer_step,\n",
    "            min_signal_eps=risk_min_signal,\n",
    "            mode=sleeve_risk_mode\n",
    "        )\n",
    "        sleeve_risk_multiplier = np.array(\n",
    "            [float(sleeve_risk_multiplier.get(ticker_to_sleeve[t], 1.0)) for t in ticker_list],\n",
    "            dtype=float\n",
    "        )\n",
    "    else:\n",
    "        rb_weights = daily_weights.copy()\n",
    "        sleeve_risk_multiplier = np.ones(len(ticker_list))\n",
    "    rb_weights = np.asarray(rb_weights, dtype=float)\n",
    "    rb_weights = np.clip(rb_weights, 0.0, None)\n",
    "    sleeve_risk_multiplier = np.asarray(sleeve_risk_multiplier, dtype=float)\n",
    "    df.loc[date, sleeve_risk_adj_cols] = rb_weights\n",
    "    df.loc[date, sleeve_risk_multiplier_cols] = sleeve_risk_multiplier\n",
    "    \n",
    "    ## If all weights are zero, we can just zero out and return\n",
    "    if np.allclose(rb_weights, 0):\n",
    "        df.loc[date, scaled_weight_cols] = 0.0\n",
    "        df.loc[date, target_notional_cols] = 0.0\n",
    "        df.loc[date, 'daily_portfolio_volatility'] = 0.0\n",
    "        df.loc[date, 'target_vol_scaling_factor'] = 0.0\n",
    "        df.loc[date, 'cash_scaling_factor'] = 1.0\n",
    "        df.loc[date, 'final_scaling_factor'] = 0.0\n",
    "        df.loc[date, 'total_target_notional'] = 0.0\n",
    "        return df\n",
    "        \n",
    "    ## Calculate the portfolio volatility based on the new weights\n",
    "    daily_portfolio_volatility = size_bin.calculate_portfolio_volatility(rb_weights, daily_cov_matrix)\n",
    "    df.loc[date, 'daily_portfolio_volatility'] = daily_portfolio_volatility\n",
    "    if daily_portfolio_volatility > 0:\n",
    "        vol_scaling_factor = daily_target_volatility / daily_portfolio_volatility\n",
    "    else:\n",
    "        vol_scaling_factor = 0\n",
    "\n",
    "    ## Apply Scaling Factor with No Leverage\n",
    "    gross_weight_sum = np.sum(np.abs(rb_weights))\n",
    "    cash_scaling_factor = 1.0 / np.maximum(gross_weight_sum, 1e-12)            # ∑ w ≤ 1  (long‑only)\n",
    "    final_scaling_factor = min(vol_scaling_factor, cash_scaling_factor)\n",
    "\n",
    "    df.loc[date, 'target_vol_scaling_factor'] = vol_scaling_factor\n",
    "    df.loc[date, 'cash_scaling_factor'] = cash_scaling_factor\n",
    "    df.loc[date, 'final_scaling_factor'] = final_scaling_factor\n",
    "\n",
    "    # Scale the weights to target volatility\n",
    "    scaled_weights = rb_weights * final_scaling_factor\n",
    "    df.loc[date, scaled_weight_cols] = scaled_weights\n",
    "\n",
    "    ## Calculate the target notional and size\n",
    "    target_notionals = scaled_weights * total_portfolio_value_upper_limit\n",
    "    df.loc[date, target_notional_cols] = target_notionals\n",
    "    target_sizes = target_notionals / df.loc[date, t_1_price_cols].values\n",
    "\n",
    "    for i, ticker in enumerate(ticker_list):\n",
    "        df.loc[date, f'{ticker}_target_size'] = target_sizes[i]\n",
    "\n",
    "    total_target_notional = target_notionals.sum()\n",
    "    df.loc[date, 'total_target_notional'] = total_target_notional\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d6c840-c8a6-4fcd-b8d8-020649a6aad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_target_volatility_position_sizing_continuous_strategy_with_rolling_r_sqr_vol_of_vol_with_risk_multiplier_sleeve_weights_opt(\n",
    "    start_date, end_date, ticker_list, fast_mavg, slow_mavg, mavg_stepsize, mavg_z_score_window,\n",
    "    entry_rolling_donchian_window, exit_rolling_donchian_window, use_donchian_exit_gate,\n",
    "    ma_crossover_signal_weight, donchian_signal_weight, weighted_signal_ewm_window,\n",
    "    rolling_r2_window=30, lower_r_sqr_limit=0.2, upper_r_sqr_limit=0.8, r2_smooth_window=3, r2_confirm_days=0,\n",
    "    log_std_window=14, coef_of_variation_window=30, vol_of_vol_z_score_window=252, vol_of_vol_p_min=0.6,\n",
    "    r2_strong_threshold=0.8, use_activation=True, tanh_activation_constant_dict=None, moving_avg_type='exponential',\n",
    "    long_only=False, price_or_returns_calc='price', initial_capital=15000, rolling_cov_window=20,\n",
    "    volatility_window=20, stop_loss_strategy='Chandelier', rolling_atr_window=20, atr_multiplier=0.5,\n",
    "    highest_high_window=56, transaction_cost_est=0.001,\n",
    "    passive_trade_rate=0.05, notional_threshold_pct=0.05, min_trade_notional_abs=10, cooldown_counter_threshold=3,\n",
    "    use_coinbase_data=True, use_saved_files=True, saved_file_end_date='2025-07-31', rolling_sharpe_window=50,\n",
    "    cash_buffer_percentage=0.10, annualized_target_volatility=0.20, annual_trading_days=365,\n",
    "    use_specific_start_date=False, signal_start_date=None, sleeve_budgets=None, risk_max_iterations=None,\n",
    "    risk_sleeve_budget_tolerance=None, risk_optimizer_step=None, risk_min_signal=None, sleeve_risk_mode=None):\n",
    "\n",
    "    ## Check if data is available for all the tickers\n",
    "    date_list = cn.coinbase_start_date_by_ticker_dict\n",
    "    ticker_list = [ticker for ticker in ticker_list if pd.Timestamp(date_list[ticker]).date() < end_date]\n",
    "\n",
    "    print('Generating Moving Average Ribbon Signal!!')\n",
    "    ## Generate Trend Signal for all tickers\n",
    "\n",
    "    df_trend = get_trend_donchian_signal_for_portfolio_with_rolling_r_sqr_vol_of_vol(\n",
    "        start_date=start_date, end_date=end_date, ticker_list=ticker_list, fast_mavg=fast_mavg, slow_mavg=slow_mavg,\n",
    "        mavg_stepsize=mavg_stepsize, mavg_z_score_window=mavg_z_score_window,\n",
    "        entry_rolling_donchian_window=entry_rolling_donchian_window,\n",
    "        exit_rolling_donchian_window=exit_rolling_donchian_window, use_donchian_exit_gate=use_donchian_exit_gate,\n",
    "        ma_crossover_signal_weight=ma_crossover_signal_weight, donchian_signal_weight=donchian_signal_weight,\n",
    "        weighted_signal_ewm_window=weighted_signal_ewm_window, rolling_r2_window=rolling_r2_window,\n",
    "        lower_r_sqr_limit=lower_r_sqr_limit, upper_r_sqr_limit=upper_r_sqr_limit, r2_smooth_window=r2_smooth_window,\n",
    "        r2_confirm_days=r2_confirm_days, log_std_window=log_std_window, coef_of_variation_window=coef_of_variation_window,\n",
    "        vol_of_vol_z_score_window=vol_of_vol_z_score_window, vol_of_vol_p_min=vol_of_vol_p_min,\n",
    "        r2_strong_threshold=r2_strong_threshold, use_activation=use_activation,\n",
    "        tanh_activation_constant_dict=tanh_activation_constant_dict, moving_avg_type=moving_avg_type,\n",
    "        long_only=long_only, price_or_returns_calc=price_or_returns_calc, use_coinbase_data=use_coinbase_data,\n",
    "        use_saved_files=use_saved_files, saved_file_end_date=saved_file_end_date)\n",
    "\n",
    "    print('Generating Volatility Adjusted Trend Signal!!')\n",
    "    ## Get Volatility Adjusted Trend Signal\n",
    "    df_signal = size_cont.get_volatility_adjusted_trend_signal_continuous(df_trend, ticker_list, volatility_window,\n",
    "                                                                          annual_trading_days)\n",
    "\n",
    "    print('Getting Average True Range for Stop Loss Calculation!!')\n",
    "    ## Get Average True Range for Stop Loss Calculation\n",
    "    df_atr = size_cont.get_average_true_range_portfolio(start_date=start_date, end_date=end_date,\n",
    "                                                        ticker_list=ticker_list, rolling_atr_window=rolling_atr_window,\n",
    "                                                        highest_high_window=highest_high_window,\n",
    "                                                        price_or_returns_calc='price',\n",
    "                                                        use_coinbase_data=use_coinbase_data,\n",
    "                                                        use_saved_files=use_saved_files,\n",
    "                                                        saved_file_end_date=saved_file_end_date)\n",
    "    df_signal = pd.merge(df_signal, df_atr, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    print('Calculating Volatility Targeted Position Size and Cash Management!!')\n",
    "    ## Get Target Volatility Position Sizing and Run Cash Management\n",
    "    # cfg_v2 = load_prod_strategy_config(strategy_version='v0.2.0')\n",
    "    # sleeve_budgets = cfg_v2['universe']['sleeves']\n",
    "    ticker_to_sleeve = {}\n",
    "    for sleeve in sleeve_budgets.keys():\n",
    "        print(sleeve)\n",
    "        sleeve_tickers = sleeve_budgets[sleeve]['tickers']\n",
    "        for ticker in sleeve_tickers:\n",
    "            ticker_to_sleeve[ticker] = sleeve\n",
    "    \n",
    "    df = get_target_volatility_daily_portfolio_positions_with_risk_multiplier_sleeve_weights_opt(\n",
    "        df_signal, ticker_list=ticker_list, initial_capital=initial_capital, rolling_cov_window=rolling_cov_window,\n",
    "        stop_loss_strategy=stop_loss_strategy, rolling_atr_window=rolling_atr_window, atr_multiplier=atr_multiplier,\n",
    "        highest_high_window=highest_high_window,\n",
    "        cash_buffer_percentage=cash_buffer_percentage, annualized_target_volatility=annualized_target_volatility,\n",
    "        transaction_cost_est=transaction_cost_est, passive_trade_rate=passive_trade_rate,\n",
    "        notional_threshold_pct=notional_threshold_pct, min_trade_notional_abs=min_trade_notional_abs,\n",
    "        cooldown_counter_threshold=cooldown_counter_threshold, annual_trading_days=annual_trading_days,\n",
    "        use_specific_start_date=use_specific_start_date, signal_start_date=signal_start_date,\n",
    "        ticker_to_sleeve=ticker_to_sleeve, sleeve_budgets=sleeve_budgets, risk_max_iterations=risk_max_iterations,\n",
    "        risk_sleeve_budget_tolerance=risk_sleeve_budget_tolerance, risk_optimizer_step=risk_optimizer_step,\n",
    "        risk_min_signal=risk_min_signal, sleeve_risk_mode=sleeve_risk_mode)\n",
    "\n",
    "    print('Calculating Portfolio Performance!!')\n",
    "    ## Calculate Portfolio Performance\n",
    "    df = size_bin.calculate_portfolio_returns(df, rolling_sharpe_window)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c155ee4a-a042-47b1-9d28-a0dbf532b6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sleeve_series(\n",
    "    df,\n",
    "    sleeves,\n",
    "    target_risk_budget=None,    # e.g. {\"core_l1\": 0.45, \"l1_alt\": 0.20, \"l2\": 0.25, \"ai\": 0.10}\n",
    "    budget_band=0.20,           # +/- 20% of target as “close enough”\n",
    "    strategy_trade_count_col=None  # e.g. \"strategy_trade_count\"\n",
    "):\n",
    "    \"\"\"\n",
    "    For each sleeve:\n",
    "      - {sleeve}_daily_pct_returns : value-weighted return of tickers in that sleeve\n",
    "      - {sleeve}_gross_notional    : sum of abs notional (t-1) of sleeve\n",
    "      - {sleeve}_risk_share        : sleeve gross / total gross (t-1)\n",
    "      - {sleeve}_alloc_share       : sleeve NAV / total portfolio value (t-1)\n",
    "      - {sleeve}_risk_share_target : desired risk budget for this sleeve (if provided)\n",
    "      - {sleeve}_risk_share_diff   : realized risk_share - target\n",
    "      - {sleeve}_in_budget_band    : 1 if risk_share is within budget_band of target, else 0\n",
    "      - {sleeve}_trade_count       : sleeve-level trade count (allocated from strategy_trade_count_col via risk_share)\n",
    "\n",
    "    Also adds:\n",
    "      - invested_fraction_prev : NAV_{t-1} / total_portfolio_value_{t-1}\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # --- infer global ticker universe from sleeves ---\n",
    "    all_tickers = sorted({t for tlist in sleeves.values() for t in tlist})\n",
    "    pos_cols_all = [f\"{t}_actual_position_notional\" for t in all_tickers]\n",
    "\n",
    "    # total gross & NAV from previous day\n",
    "    pos_prev_all = df[pos_cols_all].shift(1)\n",
    "    total_gross_notional_t_1 = pos_prev_all.abs().sum(axis=1)\n",
    "    total_net_notional_t_1 = pos_prev_all.sum(axis=1)\n",
    "\n",
    "    # total portfolio value (if missing, approximate as nav + cash)\n",
    "    if \"total_portfolio_value\" not in df.columns:\n",
    "        if \"available_cash\" in df.columns:\n",
    "            df[\"total_portfolio_value\"] = (\n",
    "                df[pos_cols_all].sum(axis=1) + df[\"available_cash\"]\n",
    "            )\n",
    "        else:\n",
    "            df[\"total_portfolio_value\"] = df[pos_cols_all].sum(axis=1)\n",
    "\n",
    "    total_portfolio_value_t_1 = df[\"total_portfolio_value\"].shift(1)\n",
    "\n",
    "    # how much of the portfolio is invested at all? (for diagnostics)\n",
    "    df[\"invested_fraction_t_1\"] = np.where(\n",
    "        total_portfolio_value_t_1 > 0,\n",
    "        total_net_notional_t_1 / total_portfolio_value_t_1,\n",
    "        0.0,\n",
    "    )\n",
    "\n",
    "    for sleeve_name, tlist in sleeves.items():\n",
    "        sleeve_ret_cols = [f\"{t}_daily_pct_returns\" for t in tlist]\n",
    "        sleeve_pos_cols = [f\"{t}_actual_position_notional\" for t in tlist]\n",
    "\n",
    "        sleeve_notionals_t_1 = df[sleeve_pos_cols].shift(1)                ## Notional Cols for All Tickers in the Sleeve\n",
    "        sleeve_gross_notional_t_1 = sleeve_notionals_t_1.abs().sum(axis=1) ## Absolute Sum Gross Notional\n",
    "        sleeve_net_notional_t_1 = sleeve_notionals_t_1.sum(axis=1)         ## Position Notional Sum\n",
    "\n",
    "        # sleeve PnL and value-weighted return\n",
    "        sleeve_pnl = (sleeve_notionals_t_1.values * df[sleeve_ret_cols].values).sum(axis=1)\n",
    "        sleeve_ret = np.where(\n",
    "            sleeve_gross_notional_t_1.values > 0,\n",
    "            sleeve_pnl / sleeve_gross_notional_t_1.values,\n",
    "            0.0,\n",
    "        )\n",
    "\n",
    "        df[f\"{sleeve_name}_daily_pct_returns\"] = sleeve_ret\n",
    "        df[f\"{sleeve_name}_gross_notional\"] = sleeve_gross_notional_t_1\n",
    "\n",
    "        # risk share: conditional on total gross > 0\n",
    "        risk_share = np.where(\n",
    "            total_gross_notional_t_1.values > 0,\n",
    "            sleeve_gross_notional_t_1.values / total_gross_notional_t_1.values,\n",
    "            0.0,\n",
    "        )\n",
    "        df[f\"{sleeve_name}_risk_share\"] = risk_share\n",
    "\n",
    "        # allocation share vs total portfolio value (includes cash)\n",
    "        alloc_share = np.where(\n",
    "            total_portfolio_value_t_1.values > 0,\n",
    "            sleeve_net_notional_t_1.values / total_portfolio_value_t_1.values,\n",
    "            0.0,\n",
    "        )\n",
    "        df[f\"{sleeve_name}_alloc_share\"] = alloc_share\n",
    "\n",
    "        # --- risk-budget diagnostics ---\n",
    "        if target_risk_budget is not None and sleeve_name in target_risk_budget:\n",
    "            target = float(target_risk_budget[sleeve_name])\n",
    "            df[f\"{sleeve_name}_risk_share_target\"] = target\n",
    "\n",
    "            diff = risk_share - target\n",
    "            df[f\"{sleeve_name}_risk_share_diff\"] = diff\n",
    "\n",
    "            # within ±budget_band * target?\n",
    "            lower = target * (1.0 - budget_band)\n",
    "            upper = target * (1.0 + budget_band)\n",
    "            in_band = np.where(\n",
    "                (risk_share >= lower) & (risk_share <= upper),\n",
    "                1,\n",
    "                0,\n",
    "            )\n",
    "            df[f\"{sleeve_name}_in_budget_band\"] = in_band\n",
    "\n",
    "        # --- allocate trade_count to sleeves (for cost-consistent metrics) ---\n",
    "        if strategy_trade_count_col is not None and strategy_trade_count_col in df.columns:\n",
    "            # proportional allocation by risk share\n",
    "            df[f\"{sleeve_name}_trade_count\"] = (\n",
    "                df[strategy_trade_count_col] * df[f\"{sleeve_name}_risk_share\"]\n",
    "            )\n",
    "\n",
    "    return df\n",
    "\n",
    "import portfolio.strategy_performance as perf\n",
    "from portfolio.strategy_performance import calculate_risk_and_performance_metrics\n",
    "\n",
    "def summarize_sleeves_with_user_metrics(\n",
    "    df,\n",
    "    sleeves,\n",
    "    target_risk_budget=None,\n",
    "    include_transaction_costs_and_fees=False,\n",
    "    transaction_cost_est=0.001,\n",
    "    passive_trade_rate=0.05,\n",
    "    annual_rf=0.05,\n",
    "    annual_trading_days=365,\n",
    "):\n",
    "    \"\"\"\n",
    "    For each sleeve, compute your full risk/performance metrics using\n",
    "    calculate_risk_and_performance_metrics, plus risk-budget diagnostics.\n",
    "\n",
    "    Assumes df already has (from add_sleeve_series):\n",
    "      - {sleeve}_daily_pct_returns\n",
    "      - {sleeve}_trade_count      (if you passed strategy_trade_count_col)\n",
    "      - {sleeve}_risk_share\n",
    "      - {sleeve}_in_budget_band   (optional)\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for sleeve_name in sleeves.keys():\n",
    "        ret_col   = f\"{sleeve_name}_daily_pct_returns\"\n",
    "        tc_col    = f\"{sleeve_name}_trade_count\"\n",
    "        rs_col    = f\"{sleeve_name}_risk_share\"\n",
    "        band_col  = f\"{sleeve_name}_in_budget_band\"\n",
    "\n",
    "        if ret_col not in df.columns:\n",
    "            continue\n",
    "\n",
    "        # if we didn't allocate trade_count, fall back to zeros\n",
    "        df_sleeve = pd.DataFrame(index=df.index)\n",
    "        df_sleeve[\"sleeve_daily_return\"] = df[ret_col]\n",
    "        df_sleeve['sleeve_trade_count'] = np.where(df_sleeve['sleeve_daily_return'] != 0, 1, 0)\n",
    "\n",
    "        # if tc_col in df.columns:\n",
    "        #     df_sleeve[\"sleeve_trade_count\"] = df[tc_col]\n",
    "        # else:\n",
    "        #     df_sleeve[\"sleeve_trade_count\"] = 0.0\n",
    "\n",
    "        # --- core metrics using YOUR definitions ---\n",
    "        perf = calculate_risk_and_performance_metrics(\n",
    "            df_sleeve,\n",
    "            strategy_daily_return_col=\"sleeve_daily_return\",\n",
    "            strategy_trade_count_col=\"sleeve_trade_count\",\n",
    "            annual_rf=annual_rf,\n",
    "            annual_trading_days=annual_trading_days,\n",
    "            include_transaction_costs_and_fees=include_transaction_costs_and_fees,\n",
    "            transaction_cost_est=transaction_cost_est,\n",
    "            passive_trade_rate=passive_trade_rate,\n",
    "        )\n",
    "        # perf is a dict like:\n",
    "        # {\n",
    "        #   'annualized_return', 'annualized_sharpe_ratio', 'calmar_ratio',\n",
    "        #   'annualized_std_dev', 'max_drawdown', 'max_drawdown_duration',\n",
    "        #   'hit_rate', 't_statistic', 'p_value', 'trade_count'\n",
    "        # }\n",
    "\n",
    "        # --- risk-budget diagnostics ---\n",
    "        if rs_col in df.columns:\n",
    "            rs = df[rs_col].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "            if not rs.empty:\n",
    "                perf[\"mean_risk_share\"] = rs.mean()\n",
    "                q = rs.quantile([0.05, 0.95])\n",
    "                perf[\"p5_risk_share\"] = q.loc[0.05]\n",
    "                perf[\"p95_risk_share\"] = q.loc[0.95]\n",
    "            else:\n",
    "                perf[\"mean_risk_share\"] = np.nan\n",
    "                perf[\"p5_risk_share\"] = np.nan\n",
    "                perf[\"p95_risk_share\"] = np.nan\n",
    "        else:\n",
    "            perf[\"mean_risk_share\"] = np.nan\n",
    "            perf[\"p5_risk_share\"] = np.nan\n",
    "            perf[\"p95_risk_share\"] = np.nan\n",
    "\n",
    "        if target_risk_budget is not None and sleeve_name in target_risk_budget:\n",
    "            target = float(target_risk_budget[sleeve_name])\n",
    "            perf[\"target_risk_share\"] = target\n",
    "            if rs_col in df.columns:\n",
    "                perf[\"mean_risk_share_diff\"] = df[rs_col].mean() - target\n",
    "            else:\n",
    "                perf[\"mean_risk_share_diff\"] = np.nan\n",
    "\n",
    "            if band_col in df.columns:\n",
    "                perf[\"pct_days_in_band\"] = df[band_col].mean()\n",
    "            else:\n",
    "                perf[\"pct_days_in_band\"] = np.nan\n",
    "        else:\n",
    "            perf[\"target_risk_share\"] = np.nan\n",
    "            perf[\"mean_risk_share_diff\"] = np.nan\n",
    "            perf[\"pct_days_in_band\"] = np.nan\n",
    "\n",
    "        perf[\"sleeve\"] = sleeve_name\n",
    "        rows.append(perf)\n",
    "\n",
    "    if not rows:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    return pd.DataFrame(rows).set_index(\"sleeve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1504c6d7-aacd-48ae-b419-8d84841552c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_uuid = cn.get_portfolio_uuid(client, portfolio_name)\n",
    "df_portfolio_positions = cn.get_portfolio_breakdown(client, portfolio_uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d69d8fd-a749-4094-9983-e12ee793d413",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_portfolio_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2100f87c-e144-4230-a6bb-44693a89504f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_portfolio_positions['total_balance_fiat'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a811434-58e2-4aad-9430-a12c5f1da323",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_universe = apply_target_volatility_position_sizing_continuous_strategy_with_rolling_r_sqr_vol_of_vol_with_risk_multiplier_sleeve_weights_opt(\n",
    "    start_date=start_date - pd.Timedelta(days=warmup_days),\n",
    "    end_date=end_date,\n",
    "    ticker_list=ticker_list,\n",
    "    fast_mavg=fast_mavg,\n",
    "    slow_mavg=slow_mavg,\n",
    "    mavg_stepsize=mavg_stepsize,\n",
    "    mavg_z_score_window=mavg_z_score_window,\n",
    "    entry_rolling_donchian_window=entry_rolling_donchian_window,\n",
    "    exit_rolling_donchian_window=exit_rolling_donchian_window,\n",
    "    use_donchian_exit_gate=use_donchian_exit_gate,\n",
    "    ma_crossover_signal_weight=ma_crossover_signal_weight,\n",
    "    donchian_signal_weight=donchian_signal_weight,\n",
    "    weighted_signal_ewm_window=weighted_signal_ewm_window,\n",
    "    rolling_r2_window=rolling_r2_window,\n",
    "    lower_r_sqr_limit=lower_r_sqr_limit,\n",
    "    upper_r_sqr_limit=upper_r_sqr_limit,\n",
    "    r2_smooth_window=r2_smooth_window,\n",
    "    r2_confirm_days=r2_confirm_days,\n",
    "    log_std_window=log_std_window,\n",
    "    coef_of_variation_window=coef_of_variation_window,\n",
    "    vol_of_vol_z_score_window=vol_of_vol_z_score_window,\n",
    "    vol_of_vol_p_min=vol_of_vol_p_min,\n",
    "    r2_strong_threshold=r2_strong_threshold,\n",
    "    use_activation=use_activation,\n",
    "    tanh_activation_constant_dict=tanh_activation_constant_dict,\n",
    "    moving_avg_type=moving_avg_type,\n",
    "    long_only=False,\n",
    "    price_or_returns_calc=price_or_returns_calc,\n",
    "    initial_capital=df_portfolio_positions['total_balance_fiat'].sum(),#initial_capital,\n",
    "    rolling_cov_window=rolling_cov_window,\n",
    "    volatility_window=volatility_window,\n",
    "    rolling_atr_window=rolling_atr_window,\n",
    "    atr_multiplier=atr_multiplier,\n",
    "    transaction_cost_est=transaction_cost_est,\n",
    "    passive_trade_rate=passive_trade_rate,\n",
    "    notional_threshold_pct=notional_threshold_pct,\n",
    "    cooldown_counter_threshold=cooldown_counter_threshold,\n",
    "    use_coinbase_data=use_coinbase_data,\n",
    "    use_saved_files=False,\n",
    "    saved_file_end_date=None,\n",
    "    rolling_sharpe_window=rolling_sharpe_window,\n",
    "    cash_buffer_percentage=cash_buffer_percentage,\n",
    "    annualized_target_volatility=annualized_target_volatility,\n",
    "    annual_trading_days=annual_trading_days,\n",
    "    use_specific_start_date=True,\n",
    "    signal_start_date=start_date,\n",
    "    sleeve_budgets=sleeve_budgets,\n",
    "    risk_max_iterations=risk_max_iterations,\n",
    "    risk_sleeve_budget_tolerance=risk_sleeve_budget_tolerance,\n",
    "    risk_optimizer_step=risk_optimizer_step,\n",
    "    risk_min_signal=risk_min_signal,\n",
    "    sleeve_risk_mode=sleeve_risk_mode\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837c3b2a-1b7c-4c64-9aa1-68f826c4466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- 2) cut warmup -----\n",
    "df_expanded_universe = df_expanded_universe[df_expanded_universe.index >= pd.Timestamp(start_date)]\n",
    "\n",
    "# ----- 3) add asset-level + portfolio returns -----\n",
    "df_expanded_universe = perf.calculate_asset_level_returns(df_expanded_universe, end_date, ticker_list)\n",
    "\n",
    "# ----- 4) portfolio-level metrics -----\n",
    "port_metrics = calculate_risk_and_performance_metrics(\n",
    "    df_expanded_universe,\n",
    "    strategy_daily_return_col=\"portfolio_daily_pct_returns\",\n",
    "    strategy_trade_count_col=\"count_of_positions\",\n",
    "    include_transaction_costs_and_fees=False,\n",
    "    transaction_cost_est=transaction_cost_est,\n",
    "    passive_trade_rate=passive_trade_rate,\n",
    "    annual_trading_days=annual_trading_days,\n",
    ")\n",
    "port_metrics.update({\n",
    "    \"w_core\": sleeve_budgets['L1_Core']['weight'],\n",
    "    \"w_alt\":  sleeve_budgets['L1_Alt']['weight'],\n",
    "    \"w_ai\":   sleeve_budgets['AI']['weight'],\n",
    "})\n",
    "\n",
    "# ----- 5) sleeve-level metrics -----\n",
    "sleeves_to_tickers = {}\n",
    "for k, v in sleeve_budgets.items():\n",
    "    sleeves_to_tickers[k] = v['tickers']\n",
    "\n",
    "target_risk_budget = {\n",
    "    \"L1_Core\": float(np.round(sleeve_budgets['L1_Core']['weight'], 2)),\n",
    "    \"L1_Alt\":  float(np.round(sleeve_budgets['L1_Alt']['weight'], 2)),\n",
    "    \"AI\":      float(np.round(sleeve_budgets['AI']['weight'], 2)),\n",
    "}\n",
    "df_sleeves = add_sleeve_series(\n",
    "    df_expanded_universe,\n",
    "    sleeves=sleeves_to_tickers,\n",
    "    target_risk_budget=target_risk_budget,\n",
    "    budget_band=0.20,\n",
    "    strategy_trade_count_col=\"count_of_positions\",\n",
    ")\n",
    "\n",
    "sleeve_metrics = summarize_sleeves_with_user_metrics(\n",
    "    df_sleeves,\n",
    "    sleeves=sleeves_to_tickers,\n",
    "    target_risk_budget=target_risk_budget,\n",
    "    include_transaction_costs_and_fees=False,\n",
    "    transaction_cost_est=transaction_cost_est,\n",
    "    passive_trade_rate=passive_trade_rate,\n",
    "    annual_rf=0.05,\n",
    "    annual_trading_days=annual_trading_days,\n",
    ")\n",
    "\n",
    "# tag the run weights on the sleeve table too\n",
    "sleeve_metrics[\"w_core\"] = sleeve_budgets['L1_Core']['weight']\n",
    "sleeve_metrics[\"w_alt\"]  = sleeve_budgets['L1_Alt']['weight']\n",
    "sleeve_metrics[\"w_ai\"]   = sleeve_budgets['AI']['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa422cdb-c800-45ed-a1b5-24d4afe0c005",
   "metadata": {},
   "outputs": [],
   "source": [
    "port_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dd3206-030d-4e0c-b5ca-38a412d9279a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleeve_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3d0330-a5e6-4425-b119-b97c24a27d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "raw_signal_cols = [f'{t}_final_weighted_additive_signal' for t in ticker_list]\n",
    "date_cond = df_expanded_universe.index > pd.Timestamp('2025-09-01')\n",
    "\n",
    "cmap = plt.get_cmap(\"turbo\")  # strong, high-contrast colors\n",
    "colors = cmap(np.linspace(0, 1, len(raw_signal_cols)))\n",
    "\n",
    "df_expanded_universe[raw_signal_cols].plot(figsize=(15,10), grid=True, color=colors, linewidth=1.5)\n",
    "df_expanded_universe.loc[date_cond, raw_signal_cols].plot(figsize=(15,10), grid=True, color=colors, linewidth=1.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e872a15a-15ff-47fc-a4ec-99f6b241d5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Signal after Regime Filtering and Before Volatility Adjusting\n",
    "final_signal_cols = [f'{ticker}_final_signal' for ticker in ticker_list]\n",
    "date_cond = (df_expanded_universe.index > pd.Timestamp('2025-09-01'))\n",
    "\n",
    "cmap = plt.get_cmap(\"turbo\")  # strong, high-contrast colors\n",
    "colors = cmap(np.linspace(0, 1, len(final_signal_cols)))\n",
    "\n",
    "df_expanded_universe[final_signal_cols].plot(figsize=(15,10), grid=True, color=colors, linewidth=1.5)\n",
    "df_expanded_universe.loc[date_cond, final_signal_cols].plot(figsize=(15,10), grid=True, color=colors, linewidth=1.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8b75e3-b0d8-4ace-bd87-655c3c7ebdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Signal after Volatility Adjusting\n",
    "vol_adj_signal_cols = [f'{ticker}_vol_adjusted_trend_signal' for ticker in ticker_list]\n",
    "date_cond = (df_expanded_universe.index > pd.Timestamp('2025-09-01'))\n",
    "\n",
    "cmap = plt.get_cmap(\"turbo\")  # strong, high-contrast colors\n",
    "colors = cmap(np.linspace(0, 1, len(final_signal_cols)))\n",
    "\n",
    "df_expanded_universe[vol_adj_signal_cols].plot(figsize=(15,10), grid=True, color=colors, linewidth=1.5)\n",
    "df_expanded_universe.loc[date_cond, vol_adj_signal_cols].plot(figsize=(15,10), grid=True, color=colors, linewidth=1.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1ab611-9b5f-414f-b2a3-b51c74eb600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Signal After Scaling for Cash, Risk Budgets and Target Volatility\n",
    "target_vol_signal_cols = [f'{ticker}_target_vol_normalized_weight' for ticker in ticker_list]\n",
    "date_cond = (df_expanded_universe.index > pd.Timestamp('2025-09-01'))\n",
    "df_expanded_universe[target_vol_signal_cols].plot(figsize=(15,10), grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094891f9-2885-4446-b39f-2fe2bfc8dfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Signal After Scaling for Cash, Risk Budgets and Target Volatility\n",
    "target_notional_cols = [f'{ticker}_target_notional' for ticker in ticker_list]\n",
    "date_cond = (df_expanded_universe.index > pd.Timestamp('2025-09-01'))\n",
    "# df_expanded_universe[target_notional_cols].plot(figsize=(15,10), grid=True)\n",
    "\n",
    "\n",
    "cmap = plt.get_cmap(\"turbo\")  # strong, high-contrast colors\n",
    "colors = cmap(np.linspace(0, 1, len(final_signal_cols)))\n",
    "\n",
    "df_expanded_universe[target_notional_cols].plot(figsize=(15,10), grid=True, color=colors, linewidth=1.5)\n",
    "df_expanded_universe.loc[date_cond, target_notional_cols].plot(figsize=(15,10), grid=True, color=colors, linewidth=1.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bd8922-6460-4714-a1c4-cef03bf0a983",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = cn.get_coinbase_rest_api_client(portfolio_name=portfolio_name)\n",
    "current_positions = cn.get_current_positions_from_portfolio(client, ticker_list=ticker_list,\n",
    "                                                            portfolio_name=portfolio_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963cbc22-79b8-4f3e-934f-bf08b18e69e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f13dc27-8c72-4ff6-a4ca-ac676b9a7c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_equity, available_cash = cn.get_live_portfolio_equity_and_cash(client=client,\n",
    "                                                                         portfolio_name=portfolio_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72a658d-7e45-4335-a359-4938af7d7dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_equity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5d3e7b-a667-45e3-a8cf-eb0435408a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_cash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a66403-29f6-426a-93f8-abbdf800a6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_universe.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc756403-12b0-40f9-989a-2a57a93b9f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.000813*51.500137 * np.sqrt(365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46263faa-3465-469b-9f63-c48a53b88336",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtz_cols = [x for x in df_expanded_universe.columns if 'XTZ-USD' in x]\n",
    "df_expanded_universe[xtz_cols].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5f9aea-eed9-40fd-925d-254d65ef7137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8920bd86-a484-4923-ae40-4dada4ba3adf",
   "metadata": {},
   "source": [
    "## Debug Prod Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f2f81f9-7b41-4bed-9af7-a63490f8a960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from typing import Iterable\n",
    "import argparse\n",
    "import json\n",
    "import traceback\n",
    "import itertools\n",
    "import ast\n",
    "from strategy_signal.trend_following_signal import (\n",
    "    get_trend_donchian_signal_for_portfolio_with_rolling_r_sqr_vol_of_vol\n",
    ")\n",
    "from portfolio.strategy_performance import (calculate_sharpe_ratio, calculate_calmar_ratio, calculate_CAGR, calculate_risk_and_performance_metrics,\n",
    "                                          calculate_compounded_cumulative_returns, estimate_fee_per_trade, rolling_sharpe_ratio)\n",
    "from utils import coinbase_utils as cn\n",
    "from portfolio import strategy_performance as perf\n",
    "from sizing import position_sizing_binary_utils as size_bin\n",
    "from sizing import position_sizing_continuous_utils as size_cont\n",
    "from utils import stop_loss_cooldown_state as state\n",
    "from strategy_signal import trend_following_signal as tf\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import uuid\n",
    "# from trend_following_email_summary_v020 import send_summary_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a2de25d-3c64-4840-b415-f67592f3c3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib.util\n",
    "from pathlib import Path\n",
    "\n",
    "strategy_path = Path(\"/Users/adheerchauhan/Documents/git/trend_following/live_strategy/trend_following_strategy_v0.2.0-live/trend_following_v0.2.0-live.py\").resolve()\n",
    "sys.path.insert(0, str(strategy_path.parent))\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"trend_following_v0_2_0_live\", strategy_path)\n",
    "mod = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(mod)\n",
    "\n",
    "# now access functions/classes\n",
    "# mod.some_function(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3d381aa-c4ea-4398-8f6b-569af9e7ceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_DIR = Path(\"/Users/adheerchauhan/Documents/live_strategy_logs/trend_following_v0_2_0-live\")\n",
    "STATE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "COOLDOWN_STATE_FILE = STATE_DIR / \"stop_loss_breach_cooldown_state.json\"\n",
    "COOLDOWN_LOG_FILE   = STATE_DIR / \"stop_loss_breach_cooldown_log.jsonl\"\n",
    "DONE_FLAG_DIR       = STATE_DIR / \"done_flags\"\n",
    "RUN_LOG             = STATE_DIR / \"live_run.log\"\n",
    "\n",
    "# Ensure subdirectories exist\n",
    "DONE_FLAG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# JSONL log files\n",
    "LIVE_ERRORS_LOG       = STATE_DIR / \"live_errors.jsonl\"\n",
    "HEARTBEAT_LOG         = STATE_DIR / \"heartbeat.jsonl\"\n",
    "DESIRED_TRADES_LOG    = STATE_DIR / \"desired_trades_log.jsonl\"\n",
    "ORDER_BUILD_LOG       = STATE_DIR / \"order_build_log.jsonl\"\n",
    "ORDER_SUBMIT_LOG      = STATE_DIR / \"order_submit_log.jsonl\"\n",
    "DUST_BUILD_LOG        = STATE_DIR / \"dust_build_log.jsonl\"\n",
    "DUST_SUBMIT_LOG       = STATE_DIR / \"dust_submit_log.jsonl\"\n",
    "STOP_UPDATE_LOG       = STATE_DIR / \"stop_update_log.jsonl\"\n",
    "DAILY_SUMMARY_DIR = STATE_DIR / \"daily_summaries\"\n",
    "DAILY_SUMMARY_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CURRENT_RUN_ID = None\n",
    "\n",
    "def new_run_id(now_utc=None) -> str:\n",
    "    now_utc = now_utc or utc_now()\n",
    "    return now_utc.strftime(\"%Y-%m-%dT%H%M%SZ\") + \"-\" + uuid.uuid4().hex[:8]\n",
    "\n",
    "def set_run_id(run_id: str):\n",
    "    global CURRENT_RUN_ID\n",
    "    CURRENT_RUN_ID = run_id\n",
    "\n",
    "def daily_summary_path(day) -> Path:\n",
    "    return DAILY_SUMMARY_DIR / f\"daily_summary_{day.isoformat()}.json\"\n",
    "\n",
    "\n",
    "def utc_now():\n",
    "    return datetime.now(timezone.utc)\n",
    "\n",
    "\n",
    "def _utc_ts(d):\n",
    "    \"\"\"UTC tz-aware Timestamp (00:00Z if 'd' is a date).\"\"\"\n",
    "    ts = pd.Timestamp(d)\n",
    "    return ts.tz_localize('UTC') if ts.tzinfo is None else ts.tz_convert('UTC')\n",
    "\n",
    "\n",
    "def utc_now_iso():\n",
    "    return datetime.now(timezone.utc).isoformat()\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--force-run\", action=\"store_true\")\n",
    "    ap.add_argument(\"--run-at-utc-hour\", type=int, default=0)\n",
    "    ap.add_argument(\"--gate-minutes\", type=int, default=5)\n",
    "    ap.add_argument(\"--dry-run\", action=\"store_true\")\n",
    "\n",
    "    return ap.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908412d7-dcea-4370-9fbf-c20bad6d6097",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = mod.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1002e58-7eff-4e0c-8a26-307776dcb040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = parse_args()\n",
    "now = utc_now()\n",
    "today = now.date()\n",
    "\n",
    "# Generate Run Id for the run and log start time\n",
    "run_id = new_run_id(now)\n",
    "set_run_id(run_id)\n",
    "started_at = utc_now_iso()\n",
    "run_errors = []\n",
    "stop_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "509b4372-2744-456d-a7df-1138ae481cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/adheerchauhan/Documents/git/trend_following/live_strategy/trend_following_strategy_v0.2.0-live/config/trend_strategy_config_v0.2.0.yaml\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "cfg = load_prod_strategy_config(strategy_version='v0.2.0')\n",
    "portfolio_name = cfg['portfolio']['name']\n",
    "ticker_list = cfg['universe']['tickers']\n",
    "sleeve_budgets = cfg['universe']['sleeves']\n",
    "min_trade_notional_abs = cfg['execution_and_costs']['min_trade_notional_abs']\n",
    "transaction_cost_est = cfg['execution_and_costs']['transaction_cost_est']\n",
    "passive_trade_rate = cfg['execution_and_costs']['passive_trade_rate']\n",
    "highest_high_window = cfg['risk_and_sizing']['highest_high_window']\n",
    "rolling_atr_window = cfg['risk_and_sizing']['rolling_atr_window']\n",
    "atr_multiplier = cfg['risk_and_sizing']['atr_multiplier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "947e49db-b430-4ded-8c38-1b6b36c02656",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get Sleeve Budgets\n",
    "sleeve_budgets = cfg['universe']['sleeves']\n",
    "ticker_to_sleeve = {}\n",
    "for sleeve in sleeve_budgets.keys():\n",
    "    sleeve_tickers = sleeve_budgets[sleeve]['tickers']\n",
    "    for ticker in sleeve_tickers:\n",
    "        ticker_to_sleeve[ticker] = sleeve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e20e87b-69b0-439a-9460-52c1804d300b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = cn.get_coinbase_rest_api_client(portfolio_name=portfolio_name)\n",
    "_ = cn.get_portfolio_uuid(client, portfolio_name=portfolio_name)  # validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "729e4aea-67d1-4fd0-a7a4-be840e9ae15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "252e894d-a453-4a26-a9d0-6dbbb142ff58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2026, 1, 16)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86f1b599-a215-4127-a2aa-c82ba598b85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Volatility Adjusted Trend Signal!!\n",
      "Covariance Matrix Time: 2026-01-15 23:15:51.097614\n",
      "Start Time: 2026-01-15 23:15:51.128596\n",
      "Get Portfolio Equity and Cash Time: 2026-01-15 23:15:51.235816\n",
      "Get Current Positions Time: 2026-01-15 23:15:51.597100\n",
      "Target Volatility Position Sizing Time: 2026-01-15 23:16:08.070419\n"
     ]
    }
   ],
   "source": [
    "df, desired_positions, current_positions = mod.get_desired_trades_by_ticker(client, cfg, date=today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1f087a5-e783-42da-83b7-d6ce9972c7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BTC-USD': {'new_trade_notional': 0,\n",
       "  'trade_fees': 0,\n",
       "  'reason': 'below_threshold'},\n",
       " 'ETH-USD': {'new_trade_notional': 0,\n",
       "  'trade_fees': 0,\n",
       "  'reason': 'below_threshold'},\n",
       " 'SOL-USD': {'new_trade_notional': 0,\n",
       "  'trade_fees': 0,\n",
       "  'reason': 'below_threshold'},\n",
       " 'ADA-USD': {'new_trade_notional': 0,\n",
       "  'trade_fees': 0,\n",
       "  'reason': 'below_threshold'},\n",
       " 'AVAX-USD': {'new_trade_notional': 0,\n",
       "  'trade_fees': 0,\n",
       "  'reason': 'below_threshold'},\n",
       " 'ICP-USD': {'new_trade_notional': 0,\n",
       "  'trade_fees': 0,\n",
       "  'reason': 'below_threshold'},\n",
       " 'CRO-USD': {'new_trade_notional': 0,\n",
       "  'trade_fees': 0,\n",
       "  'reason': 'below_threshold'},\n",
       " 'XTZ-USD': {'new_trade_notional': 0,\n",
       "  'trade_fees': 0,\n",
       "  'reason': 'below_threshold'},\n",
       " 'FIL-USD': {'new_trade_notional': 0,\n",
       "  'trade_fees': 0,\n",
       "  'reason': 'below_threshold'},\n",
       " 'LINK-USD': {'new_trade_notional': 0,\n",
       "  'trade_fees': 0,\n",
       "  'reason': 'below_threshold'},\n",
       " 'FET-USD': {'new_trade_notional': 0.0,\n",
       "  'trade_fees': 0.0,\n",
       "  'reason': 'cooldown_active'},\n",
       " 'GRT-USD': {'new_trade_notional': 0,\n",
       "  'trade_fees': 0,\n",
       "  'reason': 'below_threshold'},\n",
       " 'OXT-USD': {'new_trade_notional': 0,\n",
       "  'trade_fees': 0,\n",
       "  'reason': 'below_threshold'},\n",
       " 'KRL-USD': {'new_trade_notional': 0,\n",
       "  'trade_fees': 0,\n",
       "  'reason': 'below_threshold'}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb16601-63b5-4957-95d2-b163ab431070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f1cfb92-b29c-4479-aebe-075baa4293a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTC-USD_final_signal</th>\n",
       "      <th>ETH-USD_final_signal</th>\n",
       "      <th>SOL-USD_final_signal</th>\n",
       "      <th>ADA-USD_final_signal</th>\n",
       "      <th>AVAX-USD_final_signal</th>\n",
       "      <th>ICP-USD_final_signal</th>\n",
       "      <th>CRO-USD_final_signal</th>\n",
       "      <th>XTZ-USD_final_signal</th>\n",
       "      <th>FIL-USD_final_signal</th>\n",
       "      <th>LINK-USD_final_signal</th>\n",
       "      <th>FET-USD_final_signal</th>\n",
       "      <th>GRT-USD_final_signal</th>\n",
       "      <th>OXT-USD_final_signal</th>\n",
       "      <th>KRL-USD_final_signal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2026-01-12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            BTC-USD_final_signal  ETH-USD_final_signal  SOL-USD_final_signal  \\\n",
       "date                                                                           \n",
       "2026-01-12                   0.0                   0.0                   0.0   \n",
       "2026-01-13                   0.0                   0.0                   0.0   \n",
       "2026-01-14                   0.0                   0.0                   0.0   \n",
       "2026-01-15                   0.0                   0.0                   0.0   \n",
       "2026-01-16                   0.0                   0.0                   0.0   \n",
       "\n",
       "            ADA-USD_final_signal  AVAX-USD_final_signal  ICP-USD_final_signal  \\\n",
       "date                                                                            \n",
       "2026-01-12                   0.0                    0.0                   0.0   \n",
       "2026-01-13                   0.0                    0.0                   0.0   \n",
       "2026-01-14                   0.0                    0.0                   0.0   \n",
       "2026-01-15                   0.0                    0.0                   0.0   \n",
       "2026-01-16                   0.0                    0.0                   0.0   \n",
       "\n",
       "            CRO-USD_final_signal  XTZ-USD_final_signal  FIL-USD_final_signal  \\\n",
       "date                                                                           \n",
       "2026-01-12                   0.0              0.003159                   0.0   \n",
       "2026-01-13                   0.0              0.003208                   0.0   \n",
       "2026-01-14                   0.0              0.002660                   0.0   \n",
       "2026-01-15                   0.0              0.001786                   0.0   \n",
       "2026-01-16                   0.0              0.001114                   0.0   \n",
       "\n",
       "            LINK-USD_final_signal  FET-USD_final_signal  GRT-USD_final_signal  \\\n",
       "date                                                                            \n",
       "2026-01-12                    0.0              0.000554                   0.0   \n",
       "2026-01-13                    0.0              0.000401                   0.0   \n",
       "2026-01-14                    0.0              0.000271                   0.0   \n",
       "2026-01-15                    0.0              0.000167                   0.0   \n",
       "2026-01-16                    0.0              0.000095                   0.0   \n",
       "\n",
       "            OXT-USD_final_signal  KRL-USD_final_signal  \n",
       "date                                                    \n",
       "2026-01-12                   0.0                   0.0  \n",
       "2026-01-13                   0.0                   0.0  \n",
       "2026-01-14                   0.0                   0.0  \n",
       "2026-01-15                   0.0                   0.0  \n",
       "2026-01-16                   0.0                   0.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_cols = [f'{ticker}_final_signal' for ticker in ticker_list]\n",
    "df[signal_cols].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e7f2a52-187e-4c0d-ba64-62c50aac2582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BTC-USD_target_notional</th>\n",
       "      <th>ETH-USD_target_notional</th>\n",
       "      <th>SOL-USD_target_notional</th>\n",
       "      <th>ADA-USD_target_notional</th>\n",
       "      <th>AVAX-USD_target_notional</th>\n",
       "      <th>ICP-USD_target_notional</th>\n",
       "      <th>CRO-USD_target_notional</th>\n",
       "      <th>XTZ-USD_target_notional</th>\n",
       "      <th>FIL-USD_target_notional</th>\n",
       "      <th>LINK-USD_target_notional</th>\n",
       "      <th>FET-USD_target_notional</th>\n",
       "      <th>GRT-USD_target_notional</th>\n",
       "      <th>OXT-USD_target_notional</th>\n",
       "      <th>KRL-USD_target_notional</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2026-01-12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026-01-16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>355.720561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>496.650234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            BTC-USD_target_notional  ETH-USD_target_notional  \\\n",
       "date                                                           \n",
       "2026-01-12                      0.0                      0.0   \n",
       "2026-01-13                      0.0                      0.0   \n",
       "2026-01-14                      0.0                      0.0   \n",
       "2026-01-15                      0.0                      0.0   \n",
       "2026-01-16                      0.0                      0.0   \n",
       "\n",
       "            SOL-USD_target_notional  ADA-USD_target_notional  \\\n",
       "date                                                           \n",
       "2026-01-12                      0.0                      0.0   \n",
       "2026-01-13                      0.0                      0.0   \n",
       "2026-01-14                      0.0                      0.0   \n",
       "2026-01-15                      0.0                      0.0   \n",
       "2026-01-16                      0.0                      0.0   \n",
       "\n",
       "            AVAX-USD_target_notional  ICP-USD_target_notional  \\\n",
       "date                                                            \n",
       "2026-01-12                       0.0                      0.0   \n",
       "2026-01-13                       0.0                      0.0   \n",
       "2026-01-14                       0.0                      0.0   \n",
       "2026-01-15                       0.0                      0.0   \n",
       "2026-01-16                       0.0                      0.0   \n",
       "\n",
       "            CRO-USD_target_notional  XTZ-USD_target_notional  \\\n",
       "date                                                           \n",
       "2026-01-12                      0.0                 0.000000   \n",
       "2026-01-13                      0.0                 0.000000   \n",
       "2026-01-14                      0.0                 0.000000   \n",
       "2026-01-15                      0.0                 0.000000   \n",
       "2026-01-16                      0.0               355.720561   \n",
       "\n",
       "            FIL-USD_target_notional  LINK-USD_target_notional  \\\n",
       "date                                                            \n",
       "2026-01-12                      0.0                       0.0   \n",
       "2026-01-13                      0.0                       0.0   \n",
       "2026-01-14                      0.0                       0.0   \n",
       "2026-01-15                      0.0                       0.0   \n",
       "2026-01-16                      0.0                       0.0   \n",
       "\n",
       "            FET-USD_target_notional  GRT-USD_target_notional  \\\n",
       "date                                                           \n",
       "2026-01-12                 0.000000                      0.0   \n",
       "2026-01-13                 0.000000                      0.0   \n",
       "2026-01-14                 0.000000                      0.0   \n",
       "2026-01-15                 0.000000                      0.0   \n",
       "2026-01-16               496.650234                      0.0   \n",
       "\n",
       "            OXT-USD_target_notional  KRL-USD_target_notional  \n",
       "date                                                          \n",
       "2026-01-12                      0.0                      0.0  \n",
       "2026-01-13                      0.0                      0.0  \n",
       "2026-01-14                      0.0                      0.0  \n",
       "2026-01-15                      0.0                      0.0  \n",
       "2026-01-16                      0.0                      0.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_notional_cols = [f'{ticker}_target_notional' for ticker in ticker_list]\n",
    "df[target_notional_cols].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d95b133-6c0f-4461-a98f-e23660013e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    total_buys = sum(1 for t, d in desired_positions.items() if float(d.get(\"new_trade_notional\", 0.0)) > 0)\n",
    "    total_sells = sum(1 for t, d in desired_positions.items() if float(d.get(\"new_trade_notional\", 0.0)) < 0)\n",
    "    total_zero = sum(\n",
    "        1 for t, d in desired_positions.items() if abs(float(d.get(\"new_trade_notional\", 0.0))) < 1e-9)\n",
    "except Exception:\n",
    "    total_buys = total_sells = total_zero = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2281a79-8dd6-4fc1-823e-65c11998866f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "print(total_buys)\n",
    "print(total_sells)\n",
    "print(total_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "40541e84-96ff-4785-a776-6b125285c74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rebalance_orders = mod.build_rebalance_orders(desired_positions=desired_positions,\n",
    "                                              date=today, current_positions=current_positions,\n",
    "                                              client=client, order_type='market', limit_price_buffer=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "37c1f39e-57da-4629-b141-81126549473b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rebalance_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ccd924b-8dff-4da3-bd2b-a28d6d70876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cancel any open STOP orders before submitting SELL rebalance orders.\n",
    "# Stops typically reserve base units, making Available=0 and causing SELLs to fail.\n",
    "sell_products = sorted(\n",
    "    {o.get(\"product_id\") for o in (rebalance_orders or []) if str(o.get(\"side\", \"\")).upper() == \"SELL\"})\n",
    "for product_id in sell_products:\n",
    "    if not product_id:\n",
    "        continue\n",
    "    cancel_info = mod.cancel_open_stop_orders_for_product(client, product_id, stage=\"pre_rebalance_sell\",\n",
    "                                                      allow_live=True)\n",
    "    mod.write_jsonl(STOP_UPDATE_LOG, {\"ts\": utc_now_iso(), \"stage\": \"pre_rebalance_sell_cancel\", **cancel_info})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c08a4c2e-1973-4524-88a0-50b80b3c8d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sell_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "542baa71-53f9-47f4-8012-1e7748ad6a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rebalance_orders:\n",
    "    # preview_flag = bool(args.dry_run)\n",
    "    preview_flag = False\n",
    "    try:\n",
    "        resp = mod.submit_daily_rebalance_orders(client, rebalance_orders, preview=preview_flag)\n",
    "        mod.write_jsonl(ORDER_SUBMIT_LOG, {\n",
    "            \"ts\": utc_now_iso(),\n",
    "            \"stage\": \"rebalance_submit\",\n",
    "            \"preview\": preview_flag,\n",
    "            \"orders_count\": len(rebalance_orders),\n",
    "            \"response\": cn._as_dict(resp) if 'resp' in locals() else None\n",
    "        })\n",
    "    except Exception as e:\n",
    "        err = {\"ts\": utc_now_iso(), \"where\": \"submit_daily_rebalance_orders\",\n",
    "               \"preview\": preview_flag, \"error\": str(e)}\n",
    "        mod.write_jsonl(LIVE_ERRORS_LOG, err)\n",
    "        run_errors.append(err)\n",
    "        print(f\"[warn] rebalance submit failed: {e}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aa8b4e25-f8a2-44f0-bbfd-e35591cda7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_orders = cn.list_open_stop_orders(client, product_id='XTZ-USD') or []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cdf25c4a-8505-4521-b127-cd47ea5e0927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f7ef87-d426-4e73-98bb-6433a28c860c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055191b7-c6a9-4394-beba-65a8b89cf6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# product_id = 'XTZ-USD'\n",
    "# cancel_info = cancel_open_stop_orders_for_product(client, product_id, stage=\"pre_rebalance_sell\", allow_live=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1168ff8-1718-441d-85f1-bb33dc879037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cancel_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73269c70-2e17-4fb3-af09-7d9246bf4b46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4f351e15-6999-4fbf-aba0-47702ec4b0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dust_close_orders = mod.build_dust_close_orders(\n",
    "    client=client, df=df, date=today, ticker_list=ticker_list,\n",
    "    min_trade_notional_abs=min_trade_notional_abs,\n",
    "    max_cost_usd=0.05,               # don't spend >$0.05 to clean dust\n",
    "    transaction_cost_est=transaction_cost_est,\n",
    "    passive_trade_rate=passive_trade_rate,\n",
    "    use_ioc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9024b865-caeb-4000-a8ed-c44a7ac638f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dust_close_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9de4fd08-8ce8-4387-90a8-0547529d35a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dust_sell_products = sorted(\n",
    "    {o.get(\"product_id\") for o in (dust_close_orders or []) if str(o.get(\"side\", \"\")).upper() == \"SELL\"})\n",
    "for product_id in dust_sell_products:\n",
    "    if not product_id:\n",
    "        continue\n",
    "    cancel_info = mod.cancel_open_stop_orders_for_product(client, product_id, stage=\"pre_dust_sell\",\n",
    "                                                      allow_live=(not bool(args.dry_run)))\n",
    "    write_jsonl(STOP_UPDATE_LOG, {\"ts\": utc_now_iso(), \"stage\": \"pre_dust_sell_cancel\", **cancel_info})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1ecd75fc-5e4d-44e1-90c8-5910c516aec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dust_sell_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c2c6ddf3-d354-4ecb-b118-9af41d2e8166",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dust_close_orders:\n",
    "    # preview_flag = bool(args.dry_run)\n",
    "    preview_flag = False\n",
    "    try:\n",
    "        resp = mod.submit_dust_close_orders(client=client, orders=dust_close_orders, preview=preview_flag)\n",
    "        mod.write_jsonl(DUST_SUBMIT_LOG, {\n",
    "            \"ts\": utc_now_iso(),\n",
    "            \"stage\": \"dust_submit\",\n",
    "            \"preview\": preview_flag,\n",
    "            \"orders_count\": len(dust_close_orders),\n",
    "            \"response\": cn._as_dict(resp) if 'resp' in locals() else None\n",
    "        })\n",
    "    except Exception as e:\n",
    "        err = {\"ts\": utc_now_iso(), \"where\": \"submit_dust_close_orders\",\n",
    "               \"preview\": preview_flag, \"error\": str(e)}\n",
    "        mod.write_jsonl(LIVE_ERRORS_LOG, err)\n",
    "        run_errors.append(err)\n",
    "        print(f\"[warn] dust submit failed: {e}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97956728-18d2-483a-a516-1c76b3a9c9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "89df8760-c03b-4556-8304-4053396a401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = cn.get_coinbase_rest_api_client(portfolio_name=portfolio_name)\n",
    "df = mod.refresh_df_actual_position_sizes_from_portfolio(client, df, today, ticker_list, portfolio_name)\n",
    "\n",
    "# If we fully exited any product today, make sure any lingering stop orders are cancelled.\n",
    "sold_products = set()\n",
    "sold_products |= {o.get(\"product_id\") for o in (rebalance_orders or []) if\n",
    "                  str(o.get(\"side\", \"\")).upper() == \"SELL\"}\n",
    "sold_products |= {o.get(\"product_id\") for o in (dust_close_orders or []) if\n",
    "                  str(o.get(\"side\", \"\")).upper() == \"SELL\"}\n",
    "sold_products = {p for p in sold_products if p}\n",
    "\n",
    "if sold_products:\n",
    "    try:\n",
    "        post_pos = cn.get_current_positions_from_portfolio(client, list(sold_products), portfolio_name) or {}\n",
    "    except Exception:\n",
    "        post_pos = {}\n",
    "    for product_id in sorted(sold_products):\n",
    "        qty = float((post_pos.get(product_id) or {}).get(\"ticker_qty\", 0.0) or 0.0)\n",
    "        if qty <= 0:\n",
    "            cancel_info = mod.cancel_open_stop_orders_for_product(\n",
    "                client, product_id, stage=\"post_exit_cleanup\", allow_live=True\n",
    "            )\n",
    "            mod.write_jsonl(STOP_UPDATE_LOG,\n",
    "                        {\"ts\": utc_now_iso(), \"stage\": \"post_exit_stop_cancel\", **cancel_info})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "021748f9-7539-4f8a-84b7-7e017c27003d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_map = cn.get_current_positions_from_portfolio(client, ticker_list, portfolio_name) or {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d91133e6-839c-48a5-b9f6-fcb05b1744b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BTC-USD': {'ticker_qty': 0,\n",
       "  'ticker_mid_price': 95522.005,\n",
       "  'ticker_current_notional': 0.0},\n",
       " 'ETH-USD': {'ticker_qty': 0,\n",
       "  'ticker_mid_price': 3302.0150000000003,\n",
       "  'ticker_current_notional': 0.0},\n",
       " 'SOL-USD': {'ticker_qty': 0,\n",
       "  'ticker_mid_price': 142.335,\n",
       "  'ticker_current_notional': 0.0},\n",
       " 'ADA-USD': {'ticker_qty': 0,\n",
       "  'ticker_mid_price': 0.39225,\n",
       "  'ticker_current_notional': 0.0},\n",
       " 'AVAX-USD': {'ticker_qty': 0,\n",
       "  'ticker_mid_price': 13.774999999999999,\n",
       "  'ticker_current_notional': 0.0},\n",
       " 'ICP-USD': {'ticker_qty': 0,\n",
       "  'ticker_mid_price': 4.4765,\n",
       "  'ticker_current_notional': 0.0},\n",
       " 'CRO-USD': {'ticker_qty': 0,\n",
       "  'ticker_mid_price': 0.10038,\n",
       "  'ticker_current_notional': 0.0},\n",
       " 'XTZ-USD': {'ticker_qty': 625.27,\n",
       "  'ticker_mid_price': 0.5734999999999999,\n",
       "  'ticker_current_notional': 358.5923449999999},\n",
       " 'FIL-USD': {'ticker_qty': 0,\n",
       "  'ticker_mid_price': 1.5365,\n",
       "  'ticker_current_notional': 0.0},\n",
       " 'LINK-USD': {'ticker_qty': 0,\n",
       "  'ticker_mid_price': 13.716000000000001,\n",
       "  'ticker_current_notional': 0.0},\n",
       " 'FET-USD': {'ticker_qty': 0,\n",
       "  'ticker_mid_price': 0.2754,\n",
       "  'ticker_current_notional': 0.0},\n",
       " 'GRT-USD': {'ticker_qty': 0,\n",
       "  'ticker_mid_price': 0.04085,\n",
       "  'ticker_current_notional': 0.0},\n",
       " 'OXT-USD': {'ticker_qty': 0,\n",
       "  'ticker_mid_price': 0.0246,\n",
       "  'ticker_current_notional': 0.0},\n",
       " 'KRL-USD': {'ticker_qty': 0,\n",
       "  'ticker_mid_price': 0.191,\n",
       "  'ticker_current_notional': 0.0}}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "47bc4db2-6866-4c6b-8bc5-d49e951c15c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in ticker_list:\n",
    "    try:\n",
    "        stop_loss_dict = mod.update_trailing_stop_chandelier(\n",
    "            client=client, df=df, ticker=ticker, date=today, portfolio_name=portfolio_name,\n",
    "            highest_high_window=highest_high_window,\n",
    "            rolling_atr_window=rolling_atr_window,\n",
    "            atr_multiplier=atr_multiplier,\n",
    "            # stop_loss_replace_threshold_ticks=1,\n",
    "            client_id_prefix=\"stop-\",\n",
    "            buffer_bps=0.005\n",
    "        )\n",
    "        stop_results[ticker] = stop_loss_dict or {\"ok\": True, \"action\": \"none\"}\n",
    "        mod.write_jsonl(STOP_UPDATE_LOG, {\n",
    "            \"ts\": utc_now_iso(),\n",
    "            \"ticker\": ticker,\n",
    "            **(stop_loss_dict or {})\n",
    "        })\n",
    "    except Exception as e:\n",
    "        err = {\"ts\": utc_now_iso(), \"where\": \"update_trailing_stop_chandelier\",\n",
    "               \"ticker\": ticker, \"error\": str(e)}\n",
    "        mod.write_jsonl(LIVE_ERRORS_LOG, err)\n",
    "        run_errors.append(err)\n",
    "        stop_results[ticker] = {\"ok\": False, \"error\": str(e)}\n",
    "        print(f\"[warn] update_trailing_stop_chandelier({ticker}) failed: {e}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c3450a-4b7f-4804-8f62-3be551a06a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d821b2-1bfd-453a-9d6e-f37ed8bde99e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f99036d0-81bf-4dc5-a2ac-073b0ccf3e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BTC-USD': {'ok': True,\n",
       "  'action': 'skip',\n",
       "  'reason': 'no_position',\n",
       "  'cancelled': 0},\n",
       " 'ETH-USD': {'ok': True,\n",
       "  'action': 'skip',\n",
       "  'reason': 'no_position',\n",
       "  'cancelled': 0},\n",
       " 'SOL-USD': {'ok': True,\n",
       "  'action': 'skip',\n",
       "  'reason': 'no_position',\n",
       "  'cancelled': 0},\n",
       " 'ADA-USD': {'ok': True,\n",
       "  'action': 'skip',\n",
       "  'reason': 'no_position',\n",
       "  'cancelled': 0},\n",
       " 'AVAX-USD': {'ok': True,\n",
       "  'action': 'skip',\n",
       "  'reason': 'no_position',\n",
       "  'cancelled': 0},\n",
       " 'ICP-USD': {'ok': True,\n",
       "  'action': 'skip',\n",
       "  'reason': 'no_position',\n",
       "  'cancelled': 0},\n",
       " 'CRO-USD': {'ok': True,\n",
       "  'action': 'skip',\n",
       "  'reason': 'no_position',\n",
       "  'cancelled': 0},\n",
       " 'XTZ-USD': {'ok': True,\n",
       "  'action': 'placed',\n",
       "  'cancelled': 0,\n",
       "  'client_order_id': 'stop-XTZ-USD-20260116-551',\n",
       "  'new_order_id': '19502675-04c2-4cd2-b669-afcfbc68eebc',\n",
       "  'desired_stop': 0.551,\n",
       "  'pos_qty': 625.27,\n",
       "  'size_for_stop': 625.27,\n",
       "  'mid_px': 0.5734999999999999},\n",
       " 'FIL-USD': {'ok': True,\n",
       "  'action': 'skip',\n",
       "  'reason': 'no_position',\n",
       "  'cancelled': 0},\n",
       " 'LINK-USD': {'ok': True,\n",
       "  'action': 'skip',\n",
       "  'reason': 'no_position',\n",
       "  'cancelled': 0},\n",
       " 'FET-USD': {'ok': True,\n",
       "  'action': 'skip',\n",
       "  'reason': 'no_position',\n",
       "  'cancelled': 0},\n",
       " 'GRT-USD': {'ok': True,\n",
       "  'action': 'skip',\n",
       "  'reason': 'no_position',\n",
       "  'cancelled': 0},\n",
       " 'OXT-USD': {'ok': True,\n",
       "  'action': 'skip',\n",
       "  'reason': 'no_position',\n",
       "  'cancelled': 0},\n",
       " 'KRL-USD': {'ok': True,\n",
       "  'action': 'skip',\n",
       "  'reason': 'no_position',\n",
       "  'cancelled': 0}}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## FIX THIS\n",
    "stop_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6a3b9ab8-5e5e-4edc-97ba-2c57d4afcbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = 'XTZ-USD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "80d50a8f-3f7a-4060-a21c-ed5317cfb5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is None or df.empty:\n",
    "    print({\"ok\": False, \"action\": \"skip\", \"reason\": \"df_required_for_chandelier_stop\"})\n",
    "\n",
    "# Normalize df index for indicator computation\n",
    "if not isinstance(df.index, pd.DatetimeIndex):\n",
    "    df.index = pd.to_datetime(df.index, errors=\"coerce\", utc=True).tz_localize(None)\n",
    "elif df.index.tz is not None:\n",
    "    df.index = df.index.tz_localize(None)\n",
    "df.index = df.index.normalize()\n",
    "df = df.sort_index()\n",
    "\n",
    "target = pd.Timestamp(date).normalize()\n",
    "if target not in df.index:\n",
    "    idx = df.index\n",
    "    pos = idx.searchsorted(target, side=\"right\") - 1\n",
    "    if pos < 0:\n",
    "        print({\"ok\": False, \"action\": \"skip\", \"reason\": f\"date {target.date()} before first data {idx[0].date()}\"})\n",
    "    date = idx[pos]\n",
    "else:\n",
    "    date = target\n",
    "\n",
    "# --- live specs (increments/mins) ---\n",
    "specs = cn.get_product_meta(client, product_id=ticker)\n",
    "tick = float(specs[\"price_increment\"])\n",
    "base_inc = float(specs[\"base_increment\"])\n",
    "quote_min = float(specs.get(\"quote_min_size\") or 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6334811e-c096-479b-bae6-4e0bac69fd9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_increment': 0.01,\n",
       " 'quote_increment': 0.001,\n",
       " 'base_min_size': 0.01,\n",
       " 'quote_min_size': 1.0,\n",
       " 'price_increment': 0.001}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b0bd268c-1370-4083-ab61-7f394775c7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2026-01-16 00:00:00')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b2b3cf93-0147-4a83-8f8d-d427367cc330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- compute today's desired stop from historical data ---\n",
    "stop_today = float(\n",
    "    mod.chandelier_stop_long(\n",
    "        date,\n",
    "        ticker,\n",
    "        highest_high_window,\n",
    "        rolling_atr_window,\n",
    "        atr_multiplier,\n",
    "    )\n",
    ")\n",
    "desired_stop = cn.round_to_increment(stop_today, tick)\n",
    "\n",
    "# --- pull LIVE qty + mid price ---\n",
    "pos_map = (cn.get_current_positions_from_portfolio(client, [ticker], portfolio_name) or {}).get(ticker, {}) or {}\n",
    "pos_qty = float(pos_map.get(\"ticker_qty\", 0.0) or 0.0)\n",
    "mid_px = float(pos_map.get(\"ticker_mid_price\", 0.0) or 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a0af0b21-9bf4-4323-9fa3-20d53a18c9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ticker_qty': 625.27,\n",
       " 'ticker_mid_price': 0.5725,\n",
       " 'ticker_current_notional': 357.967075}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2ba77eff-65c6-4f72-b56a-05e89a0465a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.551"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "34776790-867b-4eaa-8137-39c0a5ea01e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: cancel all existing STRATEGY stops for this ticker\n",
    "def _cancel_strategy_stops():\n",
    "    cancelled = 0\n",
    "    open_stops = cn.list_open_stop_orders(client, product_id=ticker) or []\n",
    "    for o in open_stops:\n",
    "        coid = str(o.get(\"client_order_id\") or \"\")\n",
    "        if client_id_prefix and not coid.startswith(client_id_prefix):\n",
    "            continue\n",
    "        oid = o.get(\"order_id\")\n",
    "        if oid:\n",
    "            cn.cancel_order_by_id(client, order_id=oid)\n",
    "            cancelled += 1\n",
    "    return cancelled\n",
    "\n",
    "# --- if no position: cancel stops and exit ---\n",
    "if pos_qty <= 0:\n",
    "    try:\n",
    "        cancelled = _cancel_strategy_stops()\n",
    "    except Exception as e:\n",
    "        print({\"ok\": False, \"action\": \"cancel_failed\", \"reason\": \"no_position\", \"error\": str(e)})\n",
    "\n",
    "    # record only (optional)\n",
    "    df.loc[date, f\"{ticker}_stop_loss\"] = float(desired_stop)\n",
    "    print({\"ok\": True, \"action\": \"cancelled\" if cancelled else \"skip\", \"reason\": \"no_position\", \"cancelled\": cancelled})\n",
    "\n",
    "if not (np.isfinite(mid_px) and mid_px > 0):\n",
    "    print({\"ok\": False, \"action\": \"skip\", \"reason\": \"no_live_mid_price\", \"pos_qty\": float(pos_qty)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9babcfb9-5514-4450-a5d6-cc327a9351ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625.27"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_qty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9b5357bc-7c34-464e-bd6e-2ab28d506eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- cancel existing stops FIRST (simple rule: one stop total) ---\n",
    "try:\n",
    "    cancelled = _cancel_strategy_stops()\n",
    "except Exception as e:\n",
    "    # still continue; we may place a new stop anyway\n",
    "    cancelled = None\n",
    "    print(f\"[warn] cancel stops failed for {ticker}: {e}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a7e440ee-3e1d-495d-b506-aee233fee5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "46896c32-bc06-4a1a-86e4-c5be16a4ae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- size new stop off LIVE qty ---\n",
    "size_for_stop = cn.round_down(pos_qty, base_inc)\n",
    "if size_for_stop <= 0:\n",
    "    df.loc[date, f\"{ticker}_stop_loss\"] = float(desired_stop)\n",
    "    print({\n",
    "        \"ok\": False,\n",
    "        \"action\": \"no_change\",\n",
    "        \"reason\": \"size_rounds_to_zero\",\n",
    "        \"pos_qty\": float(pos_qty),\n",
    "        \"base_increment\": float(base_inc),\n",
    "        \"cancelled\": cancelled,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8772c47e-ac08-43bd-8f40-71950d2656c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625.27"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_for_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b8ce6de9-5aa2-4357-aef1-4979e40eb010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- enforce quote min notional using LIVE mid ---\n",
    "if quote_min and (size_for_stop * mid_px) < quote_min:\n",
    "    # try rounding up (do not exceed position qty)\n",
    "    size_up = cn.round_up(quote_min / mid_px, base_inc)\n",
    "    if size_up <= pos_qty:\n",
    "        size_for_stop = size_up\n",
    "\n",
    "    if (size_for_stop * mid_px) < quote_min:\n",
    "        df.loc[date, f\"{ticker}_stop_loss\"] = float(desired_stop)\n",
    "        print({\n",
    "            \"ok\": False,\n",
    "            \"action\": \"no_change\",\n",
    "            \"reason\": \"below_quote_min_size\",\n",
    "            \"quote_min_size\": float(quote_min),\n",
    "            \"mid_px\": float(mid_px),\n",
    "            \"size_for_stop\": float(size_for_stop),\n",
    "            \"pos_qty\": float(pos_qty),\n",
    "            \"cancelled\": cancelled,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1e84b912-e52d-419f-a21c-42647fea759f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'size_up' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[117], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m size_up\n",
      "\u001b[0;31mNameError\u001b[0m: name 'size_up' is not defined"
     ]
    }
   ],
   "source": [
    "size_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1f0d6e88-fd30-41e9-841d-f01182061e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1cc28279-b0f1-4231-a4ae-05e675e372eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id_prefix=\"stop-\"\n",
    "buffer_bps = 50\n",
    "\n",
    "# --- build deterministic client_order_id ---\n",
    "client_order_id = f\"{client_id_prefix}{ticker}-{date:%Y%m%d}-{int(round(desired_stop / tick))}\"\n",
    "\n",
    "# --- preview new stop ---\n",
    "pv = cn.place_stop_limit_order(\n",
    "    client=client,\n",
    "    product_id=ticker,\n",
    "    side=\"SELL\",\n",
    "    stop_price=float(desired_stop),\n",
    "    size=float(size_for_stop),\n",
    "    client_order_id=client_order_id,\n",
    "    buffer_bps=buffer_bps,\n",
    "    preview=True,\n",
    "    price_increment=specs[\"price_increment\"],\n",
    "    base_increment=specs[\"base_increment\"],\n",
    "    quote_min_size=specs.get(\"quote_min_size\"),\n",
    ")\n",
    "pv_d = cn._as_dict(pv)\n",
    "errs = pv_d.get(\"errs\") or []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0babdffc-f5bb-4875-9028-65a0c3c670a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'order_total': '353.36258672',\n",
       " 'commission_total': '4.29185328',\n",
       " 'errs': [],\n",
       " 'warning': [],\n",
       " 'quote_size': '357.65444',\n",
       " 'base_size': '625.27',\n",
       " 'best_bid': '0.572',\n",
       " 'best_ask': '0.573',\n",
       " 'is_max': False,\n",
       " 'order_margin_total': '0',\n",
       " 'leverage': '0',\n",
       " 'long_leverage': '0',\n",
       " 'short_leverage': '0',\n",
       " 'slippage': '0',\n",
       " 'preview_id': 'ca215c8e-f2e0-4410-bfb6-35a19f45f949',\n",
       " 'current_liquidation_buffer': '0',\n",
       " 'projected_liquidation_buffer': '0',\n",
       " 'max_leverage': '',\n",
       " 'pnl_configuration': None,\n",
       " 'twap_bucket_metadata': None,\n",
       " 'position_notional_limit': '',\n",
       " 'max_notional_at_requested_leverage': '',\n",
       " 'margin_ratio_data': {'current_margin_ratio': '0',\n",
       "  'projected_margin_ratio': '0'},\n",
       " 'commission_detail_total': {'total_commission': '4.29185328',\n",
       "  'gst_commission': '0',\n",
       "  'withholding_commission': '0',\n",
       "  'client_commission': '4.29185328',\n",
       "  'venue_commission': '0',\n",
       "  'regulatory_commission': '0',\n",
       "  'clearing_commission': '0'},\n",
       " 'scaled_metadata': None,\n",
       " 'compliance_limit_data': None,\n",
       " 'equity_order_metadata': None,\n",
       " 'est_average_filled_price': '0.572',\n",
       " 'prediction_order_metadata': None,\n",
       " 'predicted_liquidation_price': '0'}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pv_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ce06c6f5-7a4d-4dd8-a931-b1c181d70656",
   "metadata": {},
   "outputs": [],
   "source": [
    "if errs:\n",
    "    # IMPORTANT: you just cancelled stops. If preview fails, you risk leaving it unprotected.\n",
    "    # Minimal safe behavior: report loudly so you can intervene; optionally restore previous stop if you track it.\n",
    "    df.loc[date, f\"{ticker}_stop_loss\"] = float(desired_stop)\n",
    "    print({\n",
    "        \"ok\": False,\n",
    "        \"action\": \"no_change\",\n",
    "        \"reason\": \"preview_error_after_cancel\",\n",
    "        \"preview_errors\": errs,\n",
    "        \"desired_stop\": float(desired_stop),\n",
    "        \"pos_qty\": float(pos_qty),\n",
    "        \"size_for_stop\": float(size_for_stop),\n",
    "        \"mid_px\": float(mid_px),\n",
    "        \"cancelled\": cancelled,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0306097-b347-4223-989b-36987688832d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6ca6e3a4-7521-45f1-8fbb-850c263be42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- place live stop (single stop) ---\n",
    "cr = cn.place_stop_limit_order(\n",
    "    client=client,\n",
    "    product_id=ticker,\n",
    "    side=\"SELL\",\n",
    "    stop_price=float(desired_stop),\n",
    "    size=float(size_for_stop),\n",
    "    client_order_id=client_order_id,\n",
    "    buffer_bps=buffer_bps,\n",
    "    preview=False,\n",
    "    price_increment=specs[\"price_increment\"],\n",
    "    base_increment=specs[\"base_increment\"],\n",
    "    quote_min_size=specs.get(\"quote_min_size\"),\n",
    ")\n",
    "cr_d = cn._as_dict(cr)\n",
    "\n",
    "# record only\n",
    "df.loc[date, f\"{ticker}_stop_loss\"] = float(desired_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f60fa4e9-8f29-402a-b287-e376943a72ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': True,\n",
       " 'response': {'order_id': '19502675-04c2-4cd2-b669-afcfbc68eebc',\n",
       "  'product_id': 'XTZ-USD',\n",
       "  'side': 'SELL',\n",
       "  'client_order_id': 'stop-XTZ-USD-20260116-551',\n",
       "  'attached_order_id': ''},\n",
       " 'order_configuration': {'stop_limit_stop_limit_gtc': {'base_size': '625.27',\n",
       "   'limit_price': '0.548',\n",
       "   'stop_price': '0.551',\n",
       "   'stop_direction': 'STOP_DIRECTION_STOP_DOWN',\n",
       "   'reduce_only': False}}}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "83a2c4dc-e2ca-49a4-bfe7-c44a6ee325e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_stops = cn.list_open_stop_orders(client, product_id=ticker) or []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "bf809e0a-e9e2-402c-a5ca-8809a6d1a9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "046d5870-db41-441e-8018-63bf46ff7aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cn.place_stop_limit_order\n",
    "product_id = 'XTZ-USD'\n",
    "side=\"SELL\"\n",
    "stop_price=float(desired_stop)\n",
    "size=float(size_for_stop)\n",
    "client_order_id=client_order_id\n",
    "buffer_bps=buffer_bps\n",
    "preview=False\n",
    "price_increment=specs[\"price_increment\"]\n",
    "base_increment=specs[\"base_increment\"]\n",
    "quote_min_size=specs.get(\"quote_min_size\")\n",
    "side = side.upper()\n",
    "buf = float(buffer_bps) / 10_000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7a891da9-e263-42e1-9470-4a87c4d98a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ced3030a-968a-4c36-ba9d-6bb42204493a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELL'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "badba69f-660f-48ca-969b-e31da26866c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directional rounding for prices\n",
    "if side == \"SELL\":\n",
    "    sp = cn.round_up(float(stop_price), float(price_increment))\n",
    "    lp = cn.round_down(sp * (1.0 - buf), float(price_increment))\n",
    "    stop_dir = \"STOP_DIRECTION_STOP_DOWN\"\n",
    "elif side == \"BUY\":\n",
    "    sp = cn.round_down(float(stop_price), float(price_increment))\n",
    "    lp = cn.round_up(sp * (1.0 + buf), float(price_increment))\n",
    "    stop_dir = \"STOP_DIRECTION_STOP_UP\"\n",
    "else:\n",
    "    raise ValueError(\"side must be 'BUY' or 'SELL'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "3950ee62-0e62-4980-b11a-a1e5b4febcfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'STOP_DIRECTION_STOP_DOWN'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "0c547f4f-b5e4-48db-a151-31776d9680f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base size rounding (↓) and optional min notional enforcement\n",
    "sz = cn.round_down(float(size), float(base_increment))\n",
    "if quote_min_size:\n",
    "    # ensure price*size >= quote_min_size\n",
    "    if sp * sz < float(quote_min_size):\n",
    "        needed = float(quote_min_size) / sp\n",
    "        # bump up, then round down to base_increment (to avoid exceeding increments)\n",
    "        sz = round_down(needed, float(base_increment))\n",
    "\n",
    "order_configuration = {\n",
    "    \"stop_limit_stop_limit_gtc\": {\n",
    "        \"base_size\":     f\"{sz}\",\n",
    "        \"limit_price\":   f\"{lp}\",\n",
    "        \"stop_price\":    f\"{sp}\",\n",
    "        \"stop_direction\": stop_dir,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5466fa16-fecd-4a89-9006-a336ddb9303a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stop_limit_stop_limit_gtc': {'base_size': '625.27',\n",
       "  'limit_price': '0.548',\n",
       "  'stop_price': '0.551',\n",
       "  'stop_direction': 'STOP_DIRECTION_STOP_DOWN'}}"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "76ca4f41-0941-46ac-a573-cb71c3ff2884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'order_total': '368.18898896', 'commission_total': '4.47193104', 'errs': [], 'warning': [], 'quote_size': '372.66092', 'base_size': '625.27', 'best_bid': '0.596', 'best_ask': '0.597', 'is_max': False, 'order_margin_total': '0', 'leverage': '0', 'long_leverage': '0', 'short_leverage': '0', 'slippage': '0', 'preview_id': '595240c3-8efe-4e75-902c-9fb50fb3b091', 'current_liquidation_buffer': '0', 'projected_liquidation_buffer': '0', 'max_leverage': '', 'pnl_configuration': None, 'twap_bucket_metadata': None, 'position_notional_limit': '', 'max_notional_at_requested_leverage': '', 'margin_ratio_data': {'current_margin_ratio': '0', 'projected_margin_ratio': '0'}, 'commission_detail_total': {'total_commission': '4.47193104', 'gst_commission': '0', 'withholding_commission': '0', 'client_commission': '4.47193104', 'venue_commission': '0', 'regulatory_commission': '0', 'clearing_commission': '0'}, 'scaled_metadata': None, 'compliance_limit_data': None, 'equity_order_metadata': None, 'est_average_filled_price': '0.596', 'prediction_order_metadata': None, 'predicted_liquidation_price': '0'}\n"
     ]
    }
   ],
   "source": [
    "# if preview:\n",
    "    # NOTE: preview must NOT include client_order_id\n",
    "print(client.preview_order(\n",
    "    product_id=product_id,\n",
    "    side=side,\n",
    "    order_configuration=order_configuration,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "53e9cc58-a9a9-4d14-b21e-f9f4995073ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Live placement: include client_order_id\n",
    "live_stop_order =  client.create_order(\n",
    "    client_order_id=client_order_id,\n",
    "    product_id=product_id,\n",
    "    side=side,\n",
    "    order_configuration=order_configuration,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "88ace339-7664-4c86-9ed8-4b618494267a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': True, 'response': {'order_id': '19502675-04c2-4cd2-b669-afcfbc68eebc', 'product_id': 'XTZ-USD', 'side': 'SELL', 'client_order_id': 'stop-XTZ-USD-20260116-551', 'attached_order_id': ''}, 'order_configuration': {'stop_limit_stop_limit_gtc': {'base_size': '625.27', 'limit_price': '0.548', 'stop_price': '0.551', 'stop_direction': 'STOP_DIRECTION_STOP_DOWN', 'reduce_only': False}}}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "live_stop_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "2b5d335a-a214-4bd5-ac1e-99e6e5e5da75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'order': {'order_id': '19502675-04c2-4cd2-b669-afcfbc68eebc', 'product_id': 'XTZ-USD', 'user_id': '745aae95-4dd9-5888-ab3d-39d549d91a29', 'order_configuration': {'stop_limit_stop_limit_gtc': {'base_size': '1503.23', 'limit_price': '0.548', 'stop_price': '0.551', 'stop_direction': 'STOP_DIRECTION_STOP_DOWN', 'reduce_only': False}}, 'side': 'SELL', 'client_order_id': 'stop-XTZ-USD-20260116-551', 'status': 'CANCELLED', 'time_in_force': 'GOOD_UNTIL_CANCELLED', 'created_time': '2026-01-16T00:01:01.243018Z', 'completion_percentage': '0', 'filled_size': '0', 'average_filled_price': '0', 'fee': '', 'number_of_fills': '0', 'filled_value': '0', 'pending_cancel': False, 'size_in_quote': False, 'total_fees': '0', 'size_inclusive_of_fees': False, 'total_value_after_fees': '0', 'trigger_status': 'STOP_PENDING', 'order_type': 'STOP_LIMIT', 'reject_reason': 'REJECT_REASON_UNSPECIFIED', 'settled': False, 'product_type': 'SPOT', 'reject_message': '', 'cancel_message': 'User requested cancel', 'order_placement_source': 'RETAIL_ADVANCED', 'outstanding_hold_amount': '0', 'is_liquidation': False, 'last_fill_time': None, 'edit_history': [], 'leverage': '', 'margin_type': 'UNKNOWN_MARGIN_TYPE', 'retail_portfolio_id': '4cceea8c-1577-493c-a238-1443e9f31a0d', 'originating_order_id': '', 'attached_order_id': '', 'attached_order_configuration': None, 'current_pending_replace': None, 'commission_detail_total': {'total_commission': '0', 'gst_commission': '0', 'withholding_commission': '0', 'client_commission': '0', 'venue_commission': '', 'regulatory_commission': '', 'clearing_commission': ''}, 'workable_size': '', 'workable_size_completion_pct': '', 'product_details': None, 'cost_basis_method': 'COST_BASIS_METHOD_UNSPECIFIED', 'displayed_order_config': 'UNKNOWN_DISPLAYED_ORDER_CONFIG', 'equity_trading_session': 'UNKNOWN_EQUITY_TRADING_SESSION', 'prediction_side': 'PREDICTION_SIDE_UNKNOWN', 'last_update_time': '2026-01-16T00:01:01.243018Z'}}\n"
     ]
    }
   ],
   "source": [
    "oid = \"19502675-04c2-4cd2-b669-afcfbc68eebc\"\n",
    "od = client.get_order(order_id=oid)   # name may differ: get_order(order_id=...)\n",
    "print(cn._as_dict(od))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "876802b8-88d5-4494-8e39-3855acca7cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_stops = cn.list_open_stop_orders(client, product_id=ticker) or []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "c74e25bd-bcdb-40af-8a5c-da72ae7031df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'order_id': '893cf1d3-3cd7-4410-96a0-3a00cdce27cb',\n",
       "  'client_order_id': '86482147-ba8c-4ee4-889e-28f77ae91b65',\n",
       "  'product_id': 'XTZ-USD',\n",
       "  'side': 'SELL',\n",
       "  'type': 'STOP_LIMIT',\n",
       "  'stop_price': 0.551,\n",
       "  'created_at': '2026-01-16T13:02:07.253703Z'}]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "b24b5bf2-d2f7-4ef9-8b7b-37a16037fcb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'order': {'order_id': '893cf1d3-3cd7-4410-96a0-3a00cdce27cb', 'product_id': 'XTZ-USD', 'user_id': '745aae95-4dd9-5888-ab3d-39d549d91a29', 'order_configuration': {'stop_limit_stop_limit_gtc': {'base_size': '625.27', 'limit_price': '0.548', 'stop_price': '0.551', 'stop_direction': 'STOP_DIRECTION_STOP_DOWN', 'reduce_only': False}}, 'side': 'SELL', 'client_order_id': '86482147-ba8c-4ee4-889e-28f77ae91b65', 'status': 'OPEN', 'time_in_force': 'GOOD_UNTIL_CANCELLED', 'created_time': '2026-01-16T13:02:07.253703Z', 'completion_percentage': '0', 'filled_size': '0', 'average_filled_price': '0', 'fee': '', 'number_of_fills': '0', 'filled_value': '0', 'pending_cancel': False, 'size_in_quote': False, 'total_fees': '0', 'size_inclusive_of_fees': False, 'total_value_after_fees': '338.53618448', 'trigger_status': 'STOP_PENDING', 'order_type': 'STOP_LIMIT', 'reject_reason': 'REJECT_REASON_UNSPECIFIED', 'settled': False, 'product_type': 'SPOT', 'reject_message': '', 'cancel_message': '', 'order_placement_source': 'RETAIL_ADVANCED', 'outstanding_hold_amount': '625.27', 'is_liquidation': False, 'last_fill_time': None, 'edit_history': [], 'leverage': '', 'margin_type': 'UNKNOWN_MARGIN_TYPE', 'retail_portfolio_id': '4cceea8c-1577-493c-a238-1443e9f31a0d', 'originating_order_id': '', 'attached_order_id': '', 'attached_order_configuration': None, 'current_pending_replace': None, 'commission_detail_total': {'total_commission': '0', 'gst_commission': '0', 'withholding_commission': '0', 'client_commission': '0', 'venue_commission': '', 'regulatory_commission': '', 'clearing_commission': ''}, 'workable_size': '', 'workable_size_completion_pct': '', 'product_details': None, 'cost_basis_method': 'COST_BASIS_METHOD_UNSPECIFIED', 'displayed_order_config': 'UNKNOWN_DISPLAYED_ORDER_CONFIG', 'equity_trading_session': 'UNKNOWN_EQUITY_TRADING_SESSION', 'prediction_side': 'PREDICTION_SIDE_UNKNOWN', 'last_update_time': '2026-01-16T13:02:07.253703Z'}}\n"
     ]
    }
   ],
   "source": [
    "oid = \"893cf1d3-3cd7-4410-96a0-3a00cdce27cb\"\n",
    "od = client.get_order(order_id=oid)   # name may differ: get_order(order_id=...)\n",
    "print(cn._as_dict(od))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043fdc38-a58b-48fc-bfed-6851ba662d84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd43947-39fa-4702-b14f-abccb9d1c09f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f7e18d-b83a-460a-a8ad-d37c2ab1586b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab86edaa-d045-4afc-8312-39e718647206",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = 'XTZ-USD'\n",
    "pos_map = (cn.get_current_positions_from_portfolio(client, [ticker], portfolio_name) or {}).get(ticker, {})\n",
    "pos_size = float(pos_map.get('ticker_qty', 0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3eab64-13d9-47be-a7d3-41e528ea2320",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79126f60-5377-4bd4-af96-75319b23e022",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bb1f44-7176-4632-948b-1cf1363d4f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4f39a4-7fb7-4435-8862-1cd08916be65",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_map = (cn.get_current_positions_from_portfolio(client, ['XTZ-USD'], portfolio_name) or {}).get(ticker, {})\n",
    "pos_size = float(pos_map.get('ticker_qty', 0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e511fd49-9174-4615-997a-4613e6c2b6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c330877-f557-4529-908b-226043142e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156a99fa-fbe8-4852-a195-e5408aa5dcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_loss_dict = mod.update_trailing_stop_chandelier(\n",
    "    client=client, df=df, ticker='XTZ-USD', date=today,\n",
    "    highest_high_window=highest_high_window,\n",
    "    rolling_atr_window=rolling_atr_window,\n",
    "    atr_multiplier=atr_multiplier,\n",
    "    stop_loss_replace_threshold_ticks=1,\n",
    "    client_id_prefix=\"stop-\",\n",
    "    limit_price_buffer=0.005\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8856a446-a3da-483d-992b-49f55477bfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b1ba77-3bbe-469b-afe5-3235758fcf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a6be7a-8367-4084-90b4-4953f99ca9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker='XTZ-USD'\n",
    "stop_today = float(mod.chandelier_stop_long(date, ticker, highest_high_window, rolling_atr_window, atr_multiplier))\n",
    "stop_prev = df.get(f'{ticker}_stop_loss', pd.Series(index=df.index, dtype=float)).shift(1).loc[date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7249e7fb-245c-4dc0-9666-0e2f0d081315",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7149b16a-f85a-44cd-aaed-885f0711eb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_stop_loss = cn.get_open_stop_price(client, product_id='XTZ-USD', client_id_prefix='stop-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e20716f-d17b-4570-965f-45a3ea667943",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_stop_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99116776-67d8-4be4-8a54-228a97f62c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abceba6-9b45-4a29-b97e-0398de0ee809",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6136b40d-03bb-48a8-a02a-d006717411de",
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_at = utc_now_iso()\n",
    "\n",
    "# Write the authoritative daily snapshot\n",
    "summary_path = mod.write_daily_summary(\n",
    "    cfg=cfg,\n",
    "    day=today,\n",
    "    run_id=CURRENT_RUN_ID or \"unknown\",  # or your run_id variable if you have it\n",
    "    dry_run=False,#bool(args.dry_run),\n",
    "    started_at=started_at,\n",
    "    completed_at=completed_at,\n",
    "    df=df,\n",
    "    ticker_list=ticker_list,\n",
    "    ticker_to_sleeve=ticker_to_sleeve,\n",
    "    desired_positions=desired_positions,\n",
    "    current_positions=current_positions,\n",
    "    rebalance_orders=rebalance_orders,\n",
    "    dust_orders=dust_close_orders,\n",
    "    stop_results=stop_results,\n",
    "    errors=run_errors,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c63570-a7ac-4e6a-93be-10266cb09249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send summary email (ideally read daily_summary_YYYY-MM-DD.json)\n",
    "try:\n",
    "    ok, msg = send_summary_email(STATE_DIR, today)  # see email tweak below\n",
    "    log_event(\"email_sent\", ok=bool(ok), msg=str(msg))\n",
    "    print(f\"[email] summary: {ok} ({msg})\", flush=True)\n",
    "except Exception as e:\n",
    "    # don’t let email failure crash the run; log it\n",
    "    err = {\"ts\": utc_now_iso(), \"where\": \"send_summary_email\", \"error\": str(e)}\n",
    "    mod.write_jsonl(LIVE_ERRORS_LOG, err)\n",
    "    run_errors.append(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032f1e72-a9e2-4cf5-9bef-54c4ba070c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545c6e12-d233-48ae-9324-12f9359b0b40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c59b660-c67c-4a8f-a058-62880d0fdbcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa9203d-4bc1-47b8-928d-a397fee0bde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Strategy Inputs\n",
    "ticker_list = cfg['universe']['tickers']\n",
    "initial_capital = cfg['run']['initial_capital']\n",
    "rolling_cov_window = cfg['risk_and_sizing']['rolling_cov_window']\n",
    "rolling_atr_window = cfg['risk_and_sizing']['rolling_atr_window']\n",
    "atr_multiplier = cfg['risk_and_sizing']['atr_multiplier']\n",
    "highest_high_window = cfg['risk_and_sizing']['highest_high_window']\n",
    "cash_buffer_percentage = cfg['risk_and_sizing']['cash_buffer_percentage']\n",
    "annualized_target_volatility = cfg['risk_and_sizing']['annualized_target_volatility']\n",
    "risk_min_signal = float(cfg['risk_and_sizing'].get('risk_min_signal', 1e-4))\n",
    "sleeve_risk_mode = str(cfg['risk_and_sizing'].get('sleeve_risk_mode', 'cap')).strip().lower()\n",
    "risk_sleeve_budget_tolerance = float(cfg['risk_and_sizing'].get('risk_sleeve_budget_tolerance', 1e-5))\n",
    "risk_optimizer_step = float(cfg['risk_and_sizing'].get('risk_optimizer_step', 0.5))\n",
    "risk_max_iterations = int(cfg['risk_and_sizing'].get('risk_max_iterations', 100))\n",
    "\n",
    "transaction_cost_est = cfg['execution_and_costs']['transaction_cost_est']\n",
    "passive_trade_rate = cfg['execution_and_costs']['passive_trade_rate']\n",
    "notional_threshold_pct = cfg['execution_and_costs']['notional_threshold_pct']\n",
    "min_trade_notional_abs = cfg['execution_and_costs']['min_trade_notional_abs']\n",
    "cooldown_counter_threshold = cfg['execution_and_costs']['cooldown_counter_threshold']\n",
    "annual_trading_days = cfg['run']['annual_trading_days']\n",
    "portfolio_name = cfg['portfolio']['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533d64cf-cac5-41b6-8bf5-ee8202174eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get Sleeve Budgets\n",
    "sleeve_budgets = cfg['universe']['sleeves']\n",
    "ticker_to_sleeve = {}\n",
    "for sleeve in sleeve_budgets.keys():\n",
    "    print(sleeve)\n",
    "    sleeve_tickers = sleeve_budgets[sleeve]['tickers']\n",
    "    for ticker in sleeve_tickers:\n",
    "        ticker_to_sleeve[ticker] = sleeve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e390b75b-2608-42f8-bc9b-53faee284cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_strategy_trend_signal(cfg):\n",
    "    end_date = utc_now().date()\n",
    "    start_date = end_date - pd.Timedelta(days=cfg['run']['warmup_days'])\n",
    "\n",
    "    # Build kwargs directly from cfg sections\n",
    "    sig_kwargs = {\n",
    "        # Dates\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "\n",
    "        # Universe\n",
    "        \"ticker_list\": cfg[\"universe\"][\"tickers\"],\n",
    "\n",
    "        # Moving Average Signal\n",
    "        \"fast_mavg\": cfg[\"signals\"][\"moving_average\"][\"fast_mavg\"],\n",
    "        \"slow_mavg\": cfg[\"signals\"][\"moving_average\"][\"slow_mavg\"],\n",
    "        \"mavg_stepsize\": cfg[\"signals\"][\"moving_average\"][\"mavg_stepsize\"],\n",
    "        \"mavg_z_score_window\": cfg[\"signals\"][\"moving_average\"][\"mavg_z_score_window\"],\n",
    "\n",
    "        # Donchain Channel Signal\n",
    "        \"entry_rolling_donchian_window\": cfg[\"signals\"][\"donchian\"][\"entry_rolling_donchian_window\"],\n",
    "        \"exit_rolling_donchian_window\": cfg[\"signals\"][\"donchian\"][\"exit_rolling_donchian_window\"],\n",
    "        \"use_donchian_exit_gate\": cfg[\"signals\"][\"donchian\"][\"use_donchian_exit_gate\"],\n",
    "\n",
    "        # Signal Weights\n",
    "        \"ma_crossover_signal_weight\": cfg[\"signals\"][\"weighting\"][\"ma_crossover_signal_weight\"],\n",
    "        \"donchian_signal_weight\": cfg[\"signals\"][\"weighting\"][\"donchian_signal_weight\"],\n",
    "        \"weighted_signal_ewm_window\": cfg[\"signals\"][\"weighting\"][\"weighted_signal_ewm_window\"],\n",
    "        \"rolling_r2_window\": cfg[\"signals\"][\"filters\"][\"rolling_r2\"][\"rolling_r2_window\"],\n",
    "\n",
    "        # Rolling R Squared Filter\n",
    "        \"lower_r_sqr_limit\": cfg[\"signals\"][\"filters\"][\"rolling_r2\"][\"lower_r_sqr_limit\"],\n",
    "        \"upper_r_sqr_limit\": cfg[\"signals\"][\"filters\"][\"rolling_r2\"][\"upper_r_sqr_limit\"],\n",
    "        \"r2_smooth_window\": cfg[\"signals\"][\"filters\"][\"rolling_r2\"][\"r2_smooth_window\"],\n",
    "        \"r2_confirm_days\": cfg[\"signals\"][\"filters\"][\"rolling_r2\"][\"r2_confirm_days\"],\n",
    "\n",
    "        # Vol of Vol Filter\n",
    "        \"log_std_window\": cfg[\"signals\"][\"filters\"][\"vol_of_vol\"][\"log_std_window\"],\n",
    "        \"coef_of_variation_window\": cfg[\"signals\"][\"filters\"][\"vol_of_vol\"][\"coef_of_variation_window\"],\n",
    "        \"vol_of_vol_z_score_window\": cfg[\"signals\"][\"filters\"][\"vol_of_vol\"][\"vol_of_vol_z_score_window\"],\n",
    "        \"vol_of_vol_p_min\": cfg[\"signals\"][\"filters\"][\"vol_of_vol\"][\"vol_of_vol_p_min\"],\n",
    "        \"r2_strong_threshold\": cfg[\"signals\"][\"filters\"][\"rolling_r2\"][\"r2_strong_threshold\"],\n",
    "\n",
    "        # Signal & Data Parameters\n",
    "        \"use_activation\": cfg[\"signals\"][\"activation\"][\"use_activation\"],\n",
    "        \"tanh_activation_constant_dict\": cfg[\"signals\"][\"activation\"][\"tanh_activation_constant_dict\"],\n",
    "        \"moving_avg_type\": cfg[\"data\"][\"moving_avg_type\"],\n",
    "        \"long_only\": cfg[\"run\"][\"long_only\"],\n",
    "        \"price_or_returns_calc\": cfg[\"data\"][\"price_or_returns_calc\"],\n",
    "        \"use_coinbase_data\": cfg[\"data\"][\"use_coinbase_data\"],\n",
    "        \"use_saved_files\": False,\n",
    "        \"saved_file_end_date\": None  # cfg[\"data\"][\"saved_file_end_date\"]\n",
    "    }\n",
    "\n",
    "    df_trend = get_trend_donchian_signal_for_portfolio_with_rolling_r_sqr_vol_of_vol(**sig_kwargs)\n",
    "\n",
    "    print('Generating Volatility Adjusted Trend Signal!!')\n",
    "    ## Get Volatility Adjusted Trend Signal\n",
    "    df_signal = size_cont.get_volatility_adjusted_trend_signal_continuous(df_trend,\n",
    "                                                                          ticker_list=cfg['universe']['tickers'],\n",
    "                                                                          volatility_window=cfg['risk_and_sizing'][\n",
    "                                                                              'volatility_window'],\n",
    "                                                                          annual_trading_days=cfg['run'][\n",
    "                                                                              'annual_trading_days'])\n",
    "\n",
    "    return df_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839ee535-d2ae-4299-9a18-1235ca0c404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_strategy_trend_signal(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0382642-6d0f-423c-b1ca-6bf1ecc6963c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Ensure df has a normalized, tz-naive DatetimeIndex ---\n",
    "if not isinstance(df.index, pd.DatetimeIndex):\n",
    "    df.index = pd.to_datetime(df.index, errors=\"coerce\", utc=True).tz_localize(None)\n",
    "elif df.index.tz is not None:\n",
    "    df.index = df.index.tz_localize(None)\n",
    "df.index = df.index.normalize()\n",
    "df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7178c0f7-d9ba-43be-9bb9-af870181c9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the covariance matrix for tickers in the portfolio\n",
    "returns_cols = [f'{ticker}_t_1_close_pct_returns' for ticker in ticker_list]\n",
    "cov_matrix = df[returns_cols].rolling(rolling_cov_window).cov(pairwise=True).dropna()\n",
    "\n",
    "## Delete rows prior to the first available date of the covariance matrix\n",
    "cov_matrix_start_date = cov_matrix.index.get_level_values(0).min()\n",
    "df = df[df.index >= cov_matrix_start_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38b52fe-79f1-4dfb-9327-7e432ab1fd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get Portfolio Positions and Cash\n",
    "print(f'Start Time: {datetime.now()}')\n",
    "## Create Coinbase Client & Portfolio UUID\n",
    "# client = cn.get_coinbase_rest_api_client(portfolio_name=portfolio_name)\n",
    "portfolio_uuid = cn.get_portfolio_uuid(client, portfolio_name=portfolio_name)\n",
    "\n",
    "print(f'Get Portfolio Equity and Cash Time: {datetime.now()}')\n",
    "## Get Live Portfolio Equity\n",
    "portfolio_equity, available_cash = cn.get_live_portfolio_equity_and_cash(client=client,\n",
    "                                                                         portfolio_name=portfolio_name)\n",
    "\n",
    "print(f'Get Current Positions Time: {datetime.now()}')\n",
    "## Get Current Positions using Mid-Price\n",
    "## TODO: CHECK TO SEE IF THE MID-PRICE BEING CAPTURED IS ACCURATE FROM COINBASE\n",
    "current_positions = cn.get_current_positions_from_portfolio(client, ticker_list=ticker_list,\n",
    "                                                            portfolio_name=portfolio_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f75b62-6b67-497e-8ee8-4e5852fd9e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refresh_cooldowns_from_stop_fills(\n",
    "    client,\n",
    "    tickers: Iterable[str],\n",
    "    today_date,\n",
    "    state_file: Path,\n",
    "    log_file: Path,\n",
    "    get_stop_fills_fn=cn.get_stop_fills,         # inject coinbase_utils.get_stop_fills\n",
    "    cooldown_counter_threshold: int = 7,\n",
    "    lookback_days: int = 10,   # scan recent window for safety\n",
    "    effective_recent_days: int = 2  # treat fills in last N days as trigger (covers “not obvious for 4–5 days” in time series)\n",
    "):\n",
    "    \"\"\"\n",
    "    - Pull STOP fills over a lookback window.\n",
    "    - If any fill is within the last 'effective_recent_days' (e.g., yesterday/today), start/refresh cooldown.\n",
    "    \"\"\"\n",
    "    fills_start = today_date - timedelta(days=lookback_days)\n",
    "    recent_cutoff = today_date - timedelta(days=effective_recent_days - 1)  # e.g., if N=2, cutoff is (today - 1)\n",
    "\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            fills = get_stop_fills_fn(\n",
    "                client=client,\n",
    "                product_id=ticker,\n",
    "                start=fills_start,\n",
    "                end=today_date,\n",
    "                client_id_prefix=\"stop-\"\n",
    "            )\n",
    "            print(fills)\n",
    "            # 'fills' is [(ts, price), ...] sorted ascending\n",
    "            for ts, px in reversed(fills):\n",
    "                # recent STOP fill ⇒ start cooldown dated to fill date\n",
    "                if ts.date() >= recent_cutoff:\n",
    "                    print('date > recent_cutoff')\n",
    "                    state.start_cooldown(\n",
    "                        state_path=state_file,\n",
    "                        ticker=ticker,\n",
    "                        breach_date=ts.date(),\n",
    "                        cooldown_counter_threshold=cooldown_counter_threshold,\n",
    "                        note=f\"stop_fill@{px}\",\n",
    "                        log_path=log_file\n",
    "                    )\n",
    "                    break  # only the most recent fill matters\n",
    "        except Exception as e:\n",
    "            print(f\"[warn] refresh_cooldowns_from_stop_fills({ticker}) failed: {e}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d798609-4662-490d-b461-e01989deda7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Refresh cooldowns from actual STOP fills (robust source of truth) ------\n",
    "refresh_cooldowns_from_stop_fills(\n",
    "    client=client,\n",
    "    tickers=ticker_list,\n",
    "    today_date=date,\n",
    "    state_file=COOLDOWN_STATE_FILE,\n",
    "    log_file=COOLDOWN_LOG_FILE,\n",
    "    get_stop_fills_fn=cn.get_stop_fills,  # your function\n",
    "    cooldown_counter_threshold=cooldown_counter_threshold,\n",
    "    lookback_days=10,\n",
    "    effective_recent_days=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f12346-57da-4e41-8c15-6be1e976a8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_cols(df: pd.DataFrame, col_defaults: dict) -> pd.DataFrame:\n",
    "    missing = {c: v for c, v in col_defaults.items() if c not in df.columns}\n",
    "    if not missing:\n",
    "        return df\n",
    "    # One concat = far fewer block insertions\n",
    "    add = pd.DataFrame(missing, index=df.index)\n",
    "    df = pd.concat([df, add], axis=1)\n",
    "    return df\n",
    "    \n",
    "## Identify Daily Positions starting from day 2\n",
    "# previous_date = df.index[df.index.get_loc(date) - 1]\n",
    "# --- Resolve today's row and the previous trading day robustly ---\n",
    "date_ts = pd.Timestamp(date).normalize()\n",
    "idx = df.index\n",
    "\n",
    "# first index position >= date_ts\n",
    "cur_pos = idx.searchsorted(date_ts, side=\"left\")\n",
    "if cur_pos >= len(idx):\n",
    "    raise ValueError(f\"{date_ts.date()} is after last available data ({idx[-1].date()})\")\n",
    "# previous trading day MUST exist to seed T-1\n",
    "prev_pos = cur_pos - 1\n",
    "if prev_pos < 0:\n",
    "    raise ValueError(f\"Not enough history before {date_ts.date()} to seed previous day\")\n",
    "\n",
    "date = idx[cur_pos]  # trading day used for 'today'\n",
    "previous_date = idx[prev_pos]  # trading day used for T-1\n",
    "\n",
    "col_defaults = {}\n",
    "for ticker in ticker_list:\n",
    "    col_defaults.update({\n",
    "        f'{ticker}_new_position_notional': 0.0,\n",
    "        f'{ticker}_open_position_size': 0.0,\n",
    "        f'{ticker}_open_position_notional': 0.0,\n",
    "        f'{ticker}_actual_position_size': 0.0,\n",
    "        f'{ticker}_actual_position_notional': 0.0,\n",
    "        f'{ticker}_short_sale_proceeds': 0.0,\n",
    "        f'{ticker}_new_position_entry_exit_price': 0.0,\n",
    "        f'{ticker}_target_vol_normalized_weight': 0.0,\n",
    "        f'{ticker}_target_notional': 0.0,\n",
    "        f'{ticker}_target_size': 0.0,\n",
    "        f'{ticker}_cash_shrink_factor': 0.0,\n",
    "        f'{ticker}_stop_loss': 0.0,\n",
    "        f'{ticker}_stopout_flag': False,\n",
    "        f'{ticker}_cooldown_counter': 0.0,\n",
    "        f'{ticker}_sleeve_risk_multiplier': 1.0,\n",
    "        f'{ticker}_sleeve_risk_adj_weights': 0.0,\n",
    "        f'{ticker}_event': pd.Series(pd.NA, index=df.index, dtype=\"string\"),\n",
    "    })\n",
    "\n",
    "df = ensure_cols(df, col_defaults)\n",
    "ord_cols = size_bin.reorder_columns_by_ticker(df.columns, ticker_list)\n",
    "df = df[ord_cols]\n",
    "\n",
    "## Portfolio Level Cash and Positions are all set to 0\n",
    "df['daily_portfolio_volatility'] = 0.0\n",
    "df['available_cash'] = 0.0\n",
    "df['count_of_positions'] = 0.0\n",
    "df['total_actual_position_notional'] = 0.0\n",
    "df['total_target_notional'] = 0.0\n",
    "df['total_portfolio_value'] = 0.0\n",
    "df['total_portfolio_value_upper_limit'] = 0.0\n",
    "df['target_vol_scaling_factor'] = 1.0\n",
    "df['cash_scaling_factor'] = 1.0\n",
    "df['cash_shrink_factor'] = 1.0\n",
    "df['final_scaling_factor'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ad4386-c9d2-41e8-bdd0-2dcc47366077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_true_range_live(date, ticker, rolling_atr_window=20):\n",
    "    end_date = date\n",
    "    start_date = date - pd.Timedelta(days=(rolling_atr_window + 200))\n",
    "    df = cn.save_historical_crypto_prices_from_coinbase(ticker=ticker, user_start_date=True, start_date=start_date,\n",
    "                                                        end_date=end_date, save_to_file=False,\n",
    "                                                        portfolio_name='Trend Following')\n",
    "\n",
    "    # Make sure index is UTC tz-aware and sorted\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        df.index = pd.to_datetime(df.index, utc=True)\n",
    "    elif df.index.tz is None:\n",
    "        df.index = df.index.tz_localize('UTC')\n",
    "    else:\n",
    "        df.index = df.index.tz_convert('UTC')\n",
    "    df = df.sort_index()\n",
    "\n",
    "    df.columns = [f'{ticker}_{x}' for x in df.columns]\n",
    "\n",
    "    ## Get T-1 Close Price\n",
    "    df[f'{ticker}_t_1_close'] = df[f'{ticker}_close'].shift(1)\n",
    "\n",
    "    # Calculate the True Range (TR) and Average True Range (ATR)\n",
    "    df[f'{ticker}_high-low'] = df[f'{ticker}_high'] - df[f'{ticker}_low']\n",
    "    df[f'{ticker}_high-close'] = np.abs(df[f'{ticker}_high'] - df[f'{ticker}_close'].shift(1))\n",
    "    df[f'{ticker}_low-close'] = np.abs(df[f'{ticker}_low'] - df[f'{ticker}_close'].shift(1))\n",
    "    df[f'{ticker}_true_range_price'] = df[\n",
    "        [f'{ticker}_high-low', f'{ticker}_high-close', f'{ticker}_low-close']].max(axis=1)\n",
    "    df[f'{ticker}_{rolling_atr_window}_avg_true_range_price'] = df[f'{ticker}_true_range_price'].ewm(\n",
    "        span=rolling_atr_window, adjust=False).mean()\n",
    "\n",
    "    ## Shift by 1 to avoid look-ahead bias\n",
    "    df[f'{ticker}_{rolling_atr_window}_avg_true_range_price'] = df[\n",
    "        f'{ticker}_{rolling_atr_window}_avg_true_range_price'].shift(1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def chandelier_stop_long(date, ticker, highest_high_window, rolling_atr_window, atr_multiplier):\n",
    "    ## Get Average True Range\n",
    "    df_atr = calculate_average_true_range_live(date=date, ticker=ticker, rolling_atr_window=rolling_atr_window)\n",
    "    key = _utc_ts(date).floor('D')\n",
    "    atr_col = f'{ticker}_{rolling_atr_window}_avg_true_range_price'\n",
    "    high_col = f'{ticker}_high'\n",
    "\n",
    "    # As-of ATR and highest high (safe if 'key' isn’t present yet)\n",
    "    atr_series = df_atr[atr_col].loc[:key]\n",
    "    if atr_series.empty:\n",
    "        raise ValueError(f\"No ATR data on or before {key} for {ticker}.\")\n",
    "    atr = float(atr_series.iloc[-1])\n",
    "\n",
    "    ## Get the Highest High from previous date\n",
    "    highest_high_t_1_series = df_atr[high_col].rolling(highest_high_window).max().shift(1).loc[:key]\n",
    "    if highest_high_t_1_series.empty:\n",
    "        raise ValueError(f\"No price data on or before {key} for {ticker}.\")\n",
    "    highest_high_t_1 = float(highest_high_t_1_series.iloc[-1])\n",
    "    chandelier_stop = highest_high_t_1 - atr_multiplier * atr\n",
    "\n",
    "    return chandelier_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c56834-bcca-4cd0-8c73-ccae63a9d0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helpers ----------------------------------------------------------------\n",
    "def _long_stop_for_today(date, ticker, highest_high_window, rolling_atr_window, atr_multiplier):\n",
    "    \"\"\"Chandelier stop (long) for *today*, computed from live ATR & T-1 highest high.\"\"\"\n",
    "    return float(chandelier_stop_long(\n",
    "        date=date,\n",
    "        ticker=ticker,\n",
    "        highest_high_window=highest_high_window,\n",
    "        rolling_atr_window=rolling_atr_window,\n",
    "        atr_multiplier=atr_multiplier\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50737894-e5a6-4c6d-94a6-8026decdd2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed state (+ carry over T-1 actuals, open notionals, and any existing stop levels)\n",
    "## Assign Live Cash and Positions\n",
    "for ticker in ticker_list:\n",
    "    # Actuals as of T-1\n",
    "    df.loc[previous_date, f'{ticker}_actual_position_notional'] = current_positions[ticker][\n",
    "        'ticker_current_notional']\n",
    "    df.loc[previous_date, f'{ticker}_actual_position_size'] = current_positions[ticker]['ticker_qty']\n",
    "\n",
    "    # Open Positions at T\n",
    "    df.loc[date, f'{ticker}_open_position_notional'] = current_positions[ticker]['ticker_current_notional']\n",
    "    df.loc[date, f'{ticker}_open_position_size'] = current_positions[ticker]['ticker_qty']\n",
    "\n",
    "    # Carry Forward any Open Stop Loss Positions from T-1\n",
    "    open_stop_loss = cn.get_open_stop_price(client, product_id=ticker, client_id_prefix='stop-')\n",
    "    df.loc[previous_date, f'{ticker}_stop_loss'] = np.where(pd.isna(open_stop_loss), 0.0,\n",
    "                                                            float(open_stop_loss)).item()\n",
    "\n",
    "    # Pull in updated Stop Loss Values for Today\n",
    "    df.loc[date, f'{ticker}_stop_loss'] = _long_stop_for_today(date, ticker, highest_high_window,\n",
    "                                                               rolling_atr_window, atr_multiplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0de8a58-a8c2-4dba-8e34-502f1ea973e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45d8f23-c976-462e-85a2-976770d2dc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbed3880-c39d-45d8-b858-4d6af3f8785b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c1ca6f-e3b5-4d34-85c9-35d7242e5292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_volatility_position_sizing_with_risk_multiplier_sleeve_weights_opt(\n",
    "        df, cov_matrix, date, ticker_list,\n",
    "        daily_target_volatility,\n",
    "        total_portfolio_value_upper_limit,\n",
    "        ticker_to_sleeve, sleeve_budgets,\n",
    "        risk_max_iterations, risk_sleeve_budget_tolerance,\n",
    "        risk_optimizer_step, risk_min_signal, sleeve_risk_mode\n",
    "):\n",
    "    ## Scale weights of positions to ensure the portfolio is in line with the target volatility\n",
    "    unscaled_weight_cols = [f'{ticker}_vol_adjusted_trend_signal' for ticker in ticker_list]\n",
    "    scaled_weight_cols = [f'{ticker}_target_vol_normalized_weight' for ticker in ticker_list]\n",
    "    target_notional_cols = [f'{ticker}_target_notional' for ticker in ticker_list]\n",
    "    t_1_price_cols = [f'{ticker}_t_1_close' for ticker in ticker_list]\n",
    "    returns_cols = [f'{ticker}_t_1_close_pct_returns' for ticker in ticker_list]\n",
    "    sleeve_risk_multiplier_cols = [f'{ticker}_sleeve_risk_multiplier' for ticker in ticker_list]\n",
    "    sleeve_risk_adj_cols = [f'{ticker}_sleeve_risk_adj_weights' for ticker in ticker_list]\n",
    "\n",
    "    if date not in df.index or date not in cov_matrix.index:\n",
    "        raise ValueError(f\"Date {date} not found in DataFrame or covariance matrix index.\")\n",
    "\n",
    "    ## Iterate through each day and get the unscaled weights and calculate the daily covariance matrix\n",
    "    daily_weights = df.loc[date, unscaled_weight_cols].values\n",
    "    daily_cov_matrix = cov_matrix.loc[date].loc[returns_cols, returns_cols].values\n",
    "\n",
    "    ## Apply the Sleeve Risk Adjusted Multiplier to the Daily Weights\n",
    "    if ticker_to_sleeve is not None and sleeve_budgets is not None:\n",
    "        rb_weights, sleeve_risk_multiplier = risk_budget_by_sleeve_optimized_by_signal(\n",
    "            signals=daily_weights,\n",
    "            daily_cov_matrix=daily_cov_matrix,\n",
    "            ticker_list=ticker_list,\n",
    "            ticker_to_sleeve=ticker_to_sleeve,\n",
    "            sleeve_budgets=sleeve_budgets,\n",
    "            max_iter=risk_max_iterations,\n",
    "            tol=risk_sleeve_budget_tolerance,\n",
    "            step=risk_optimizer_step,\n",
    "            min_signal_eps=risk_min_signal,\n",
    "            mode=sleeve_risk_mode\n",
    "        )\n",
    "        sleeve_risk_multiplier = np.array(\n",
    "            [float(sleeve_risk_multiplier.get(ticker_to_sleeve[t], 1.0)) for t in ticker_list],\n",
    "            dtype=float\n",
    "        )\n",
    "    else:\n",
    "        rb_weights = daily_weights.copy()\n",
    "        sleeve_risk_multiplier = np.ones(len(ticker_list))\n",
    "    rb_weights = np.asarray(rb_weights, dtype=float)\n",
    "    rb_weights = np.clip(rb_weights, 0.0, None)\n",
    "    sleeve_risk_multiplier = np.asarray(sleeve_risk_multiplier, dtype=float)\n",
    "    df.loc[date, sleeve_risk_adj_cols] = rb_weights\n",
    "    df.loc[date, sleeve_risk_multiplier_cols] = sleeve_risk_multiplier\n",
    "\n",
    "    ## If all weights are zero, we can just zero out and return\n",
    "    if np.allclose(rb_weights, 0):\n",
    "        df.loc[date, scaled_weight_cols] = 0.0\n",
    "        df.loc[date, target_notional_cols] = 0.0\n",
    "        df.loc[date, 'daily_portfolio_volatility'] = 0.0\n",
    "        df.loc[date, 'target_vol_scaling_factor'] = 0.0\n",
    "        df.loc[date, 'cash_scaling_factor'] = 1.0\n",
    "        df.loc[date, 'final_scaling_factor'] = 0.0\n",
    "        df.loc[date, 'total_target_notional'] = 0.0\n",
    "        return df\n",
    "\n",
    "    ## Calculate the portfolio volatility based on the new weights\n",
    "    daily_portfolio_volatility = size_bin.calculate_portfolio_volatility(rb_weights, daily_cov_matrix)\n",
    "    df.loc[date, 'daily_portfolio_volatility'] = daily_portfolio_volatility\n",
    "    if daily_portfolio_volatility > 0:\n",
    "        vol_scaling_factor = daily_target_volatility / daily_portfolio_volatility\n",
    "    else:\n",
    "        vol_scaling_factor = 0\n",
    "\n",
    "    ## Apply Scaling Factor with No Leverage\n",
    "    gross_weight_sum = np.sum(np.abs(rb_weights))\n",
    "    cash_scaling_factor = 1.0 / np.maximum(gross_weight_sum, 1e-12)  # ∑ w ≤ 1  (long‑only)\n",
    "    final_scaling_factor = min(vol_scaling_factor, cash_scaling_factor)\n",
    "\n",
    "    df.loc[date, 'target_vol_scaling_factor'] = vol_scaling_factor\n",
    "    df.loc[date, 'cash_scaling_factor'] = cash_scaling_factor\n",
    "    df.loc[date, 'final_scaling_factor'] = final_scaling_factor\n",
    "\n",
    "    # Scale the weights to target volatility\n",
    "    scaled_weights = rb_weights * final_scaling_factor\n",
    "    df.loc[date, scaled_weight_cols] = scaled_weights\n",
    "\n",
    "    ## Calculate the target notional and size\n",
    "    target_notionals = scaled_weights * total_portfolio_value_upper_limit\n",
    "    df.loc[date, target_notional_cols] = target_notionals\n",
    "    target_sizes = target_notionals / df.loc[date, t_1_price_cols].values\n",
    "\n",
    "    for i, ticker in enumerate(ticker_list):\n",
    "        df.loc[date, f'{ticker}_target_size'] = target_sizes[i]\n",
    "\n",
    "    total_target_notional = target_notionals.sum()\n",
    "    df.loc[date, 'total_target_notional'] = total_target_notional\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ffa481-69d0-45ad-9187-6edbeaf31739",
   "metadata": {},
   "outputs": [],
   "source": [
    "from strategy_signal.trend_following_expanded_universe import risk_budget_by_sleeve_optimized_by_signal\n",
    "\n",
    "## Portfolio Aggregates for today\n",
    "# Update Available Cash based on cash in Coinbase portfolio\n",
    "df.loc[date, 'available_cash'] = available_cash\n",
    "\n",
    "# Calculate Total Portfolio Value from Portfolio Positions\n",
    "short_sale_proceeds_cols = [f'{ticker}_short_sale_proceeds' for ticker in ticker_list]\n",
    "open_position_notional_cols = [f'{ticker}_open_position_notional' for ticker in ticker_list]\n",
    "df.loc[date, 'total_actual_position_notional'] = df[open_position_notional_cols].loc[date].sum()\n",
    "total_portfolio_value = (df.loc[date, 'available_cash'] +\n",
    "                         df.loc[date, short_sale_proceeds_cols].sum() +\n",
    "                         df.loc[date, 'total_actual_position_notional'])\n",
    "df.loc[date, 'total_portfolio_value'] = total_portfolio_value\n",
    "\n",
    "# Update Total Portfolio Value Upper Limit based on the Total Portfolio Value\n",
    "total_portfolio_value_upper_limit = (df.loc[date, 'total_portfolio_value'] *\n",
    "                                     (1 - cash_buffer_percentage))\n",
    "df.loc[date, 'total_portfolio_value_upper_limit'] = total_portfolio_value_upper_limit\n",
    "\n",
    "# --- 3) Target notionals via target-vol sizing -------------------------------\n",
    "print(f'Target Volatility Position Sizing Time: {datetime.now()}')\n",
    "\n",
    "## Derive the Daily Target Portfolio Volatility\n",
    "daily_target_volatility = annualized_target_volatility / np.sqrt(annual_trading_days)\n",
    "\n",
    "## TODO: THIS NEEDS TO CHANGE TO ACCOUNT FOR THE RISK MULTIPLIER\n",
    "## Calculate the target notional by ticker\n",
    "df = get_target_volatility_position_sizing_with_risk_multiplier_sleeve_weights_opt(\n",
    "    df, cov_matrix, date, ticker_list, daily_target_volatility, total_portfolio_value_upper_limit,\n",
    "    ticker_to_sleeve, sleeve_budgets, risk_max_iterations, risk_sleeve_budget_tolerance,\n",
    "    risk_optimizer_step, risk_min_signal, sleeve_risk_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f493fdd7-aeb0-420b-bc5e-7e65209b0c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_notional_cols = [f'{ticker}_target_notional' for ticker in ticker_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e3170e-3658-4b8f-8298-97daa3709bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[target_notional_cols].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe9918c-07b1-4daf-a1f1-a8383966202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fet_cols = [x for x in df.columns if 'FET-USD' in x]\n",
    "df[fet_cols].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9589be4-c9b2-4350-8057-56b41d70042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtz_cols = [x for x in df.columns if 'XTZ-USD' in x]\n",
    "df[xtz_cols].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fffec6-726f-4aa4-be5c-326e0240912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4796f0-e5c6-439c-88fe-e834c2cdcbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _entry_allowed_long(curr_price, stop_today, eps=0.0):\n",
    "    \"\"\"\n",
    "    Gate for NEW/ADDED long risk:\n",
    "    - allow only if current price is strictly above today's stop (plus optional eps).\n",
    "    \"\"\"\n",
    "    return np.isfinite(curr_price) and np.isfinite(stop_today) and (curr_price > stop_today * (1 + eps))\n",
    "\n",
    "def get_desired_trades_from_target_notional(df, date, ticker_list, current_positions, transaction_cost_est,\n",
    "                                            passive_trade_rate, notional_threshold_pct,\n",
    "                                            total_portfolio_value, cash_buffer_percentage, min_trade_notional_abs,\n",
    "                                            cooldown_counter_threshold):\n",
    "    # --- 4) Build desired trades with STOP-GATE for new/added longs --------------\n",
    "    ## Get Desired Trades based on Target Notionals and Current Notional Values by Ticker\n",
    "    desired_positions = {}\n",
    "    cash_debit = 0.0  # buys + fees\n",
    "    cash_credit = 0.0  # sells - fees\n",
    "    available_cash_for_trading = df.loc[date, 'available_cash'] * (1 - cash_buffer_percentage)\n",
    "\n",
    "    ## Estimated Transaction Costs and Fees\n",
    "    est_fees = (transaction_cost_est + perf.estimate_fee_per_trade(passive_trade_rate))\n",
    "\n",
    "    for ticker in ticker_list:\n",
    "        ## Calculate the cash need from all new target positions\n",
    "        target_notional = df.loc[date, f'{ticker}_target_notional']\n",
    "        current_notional = df.loc[date, f'{ticker}_open_position_notional']\n",
    "        new_trade_notional = target_notional - current_notional\n",
    "        trade_fees = abs(new_trade_notional) * est_fees\n",
    "        mid_px = float(current_positions[ticker]['ticker_mid_price'])\n",
    "\n",
    "        ## Calculate notional difference to determine if a trade is warranted\n",
    "        portfolio_equity_trade_threshold = notional_threshold_pct * total_portfolio_value\n",
    "        notional_threshold = notional_threshold_pct * abs(target_notional)\n",
    "        notional_floors_list = [\n",
    "            portfolio_equity_trade_threshold, notional_threshold, min_trade_notional_abs\n",
    "        ]\n",
    "        notional_floor = max(notional_floors_list)\n",
    "\n",
    "        # --- STOP-GATE: block NEW/ADDED long exposure if stop is breached/invalid ---\n",
    "        # We only gate when the delta adds long dollar risk (delta > 0).\n",
    "        if new_trade_notional > 0:\n",
    "            cooldown_active, days_left = state.is_in_cooldown(COOLDOWN_STATE_FILE, ticker, today=date)\n",
    "            if cooldown_active:\n",
    "                df.loc[date, f'{ticker}_stopout_flag'] = True\n",
    "                df.loc[date, f'{ticker}_cooldown_counter'] = float(days_left)\n",
    "                df.loc[date, f'{ticker}_event'] = f'cooldown_active({int(days_left)}d_left)'\n",
    "                desired_positions[ticker] = {'new_trade_notional': 0.0,\n",
    "                                             'trade_fees': 0.0,\n",
    "                                             'reason': 'cooldown_active'}\n",
    "                continue\n",
    "\n",
    "            stop_today = df.loc[date, f'{ticker}_stop_loss']  # _long_stop_for_today(ticker)\n",
    "            print(f'Ticker: {ticker}, Ticker Mid Price: {mid_px}, Stop Loss Price: {stop_today}')\n",
    "            if not _entry_allowed_long(curr_price=mid_px, stop_today=stop_today, eps=0.0):\n",
    "                # Block the buy; keep delta at zero but still record the stop for transparency.\n",
    "                df.loc[date, f'{ticker}_stopout_flag'] = True\n",
    "                df.loc[date, f'{ticker}_event'] = 'Stop Breached'\n",
    "                # df.loc[date, f'{ticker}_stop_loss']    = float(stop_today)\n",
    "                # Start cooldown (and log it); buys will be blocked from now on.\n",
    "                state.start_cooldown(\n",
    "                    state_path=COOLDOWN_STATE_FILE,\n",
    "                    ticker=ticker,\n",
    "                    breach_date=date,\n",
    "                    cooldown_counter_threshold=cooldown_counter_threshold,\n",
    "                    note=f\"gate_block@{mid_px}\",\n",
    "                    log_path=COOLDOWN_LOG_FILE\n",
    "                )\n",
    "                _, days_left = state.is_in_cooldown(COOLDOWN_STATE_FILE, ticker, today=date)\n",
    "                df.loc[date, f'{ticker}_cooldown_counter'] = float(days_left)\n",
    "                desired_positions[ticker] = {'new_trade_notional': 0.0,\n",
    "                                             'trade_fees': 0.0,\n",
    "                                             'reason': 'stop_breached'}\n",
    "                continue\n",
    "            else:\n",
    "                df.loc[date, f'{ticker}_stopout_flag'] = False\n",
    "                df.loc[date, f'{ticker}_stop_loss'] = float(stop_today)\n",
    "                df.loc[date, f'{ticker}_cooldown_counter'] = 0.0\n",
    "        # For sells or flat, we don’t block: let risk come off if needed.\n",
    "\n",
    "        if abs(new_trade_notional) > notional_floor:\n",
    "            desired_positions[ticker] = {'new_trade_notional': new_trade_notional,\n",
    "                                         'trade_fees': trade_fees,\n",
    "                                         'reason': 'threshold_pass'}\n",
    "        else:\n",
    "            desired_positions[ticker] = {'new_trade_notional': 0,\n",
    "                                         'trade_fees': 0,\n",
    "                                         'reason': 'below_threshold'}\n",
    "\n",
    "        if new_trade_notional >= 0:\n",
    "            ## Buys\n",
    "            cash_debit = cash_debit + new_trade_notional\n",
    "        else:\n",
    "            ## Sells\n",
    "            net_trade_notional = new_trade_notional + trade_fees\n",
    "            cash_credit = cash_credit + abs(net_trade_notional)\n",
    "\n",
    "    ## Calculate Cash Shrink Factor for the portfolio for the day\n",
    "    net_cash_need = cash_debit - cash_credit\n",
    "    if net_cash_need > available_cash_for_trading + 1e-6:\n",
    "        cash_shrink_factor = available_cash_for_trading / net_cash_need  # 0 < shrink < 1\n",
    "    else:\n",
    "        cash_shrink_factor = 1.0\n",
    "\n",
    "    df.loc[date, f'cash_shrink_factor'] = cash_shrink_factor\n",
    "\n",
    "    ## Apply Cash Shrink Factor to Desired Positions for Buys Only\n",
    "    for ticker in ticker_list:\n",
    "        if desired_positions[ticker]['new_trade_notional'] > 0:\n",
    "            desired_positions[ticker]['new_trade_notional'] = desired_positions[ticker][\n",
    "                                                                  'new_trade_notional'] * cash_shrink_factor\n",
    "            desired_positions[ticker]['trade_fees'] = desired_positions[ticker]['trade_fees'] * cash_shrink_factor\n",
    "\n",
    "        ## In the backtesting engine, new position notional is net of fees but this is not the case in\n",
    "        ## the live strategy setup\n",
    "        df.loc[date, f'{ticker}_new_position_notional'] = desired_positions[ticker]['new_trade_notional']\n",
    "        df.loc[date, f'{ticker}_new_position_size'] = desired_positions[ticker]['new_trade_notional'] / \\\n",
    "                                                      current_positions[ticker]['ticker_mid_price']\n",
    "        df.loc[date, f'{ticker}_actual_position_notional'] = df.loc[date, f'{ticker}_new_position_notional'] + \\\n",
    "                                                             df.loc[date, f'{ticker}_open_position_notional']\n",
    "        df.loc[date, f'{ticker}_actual_position_size'] = df.loc[date, f'{ticker}_actual_position_notional'] / \\\n",
    "                                                         current_positions[ticker]['ticker_mid_price']\n",
    "\n",
    "    return df, desired_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267ff772-1d66-4647-aceb-b373a1d11d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LINE CAUSING AN ERROR\n",
    "df, desired_positions = get_desired_trades_from_target_notional(df, date, ticker_list, current_positions,\n",
    "                                                                    transaction_cost_est, passive_trade_rate,\n",
    "                                                                    notional_threshold_pct,\n",
    "                                                                    total_portfolio_value, cash_buffer_percentage,\n",
    "                                                                    min_trade_notional_abs, cooldown_counter_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bf1161-1f42-4811-b255-3ad82623c391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4) Build desired trades with STOP-GATE for new/added longs --------------\n",
    "## Get Desired Trades based on Target Notionals and Current Notional Values by Ticker\n",
    "desired_positions = {}\n",
    "cash_debit = 0.0  # buys + fees\n",
    "cash_credit = 0.0  # sells - fees\n",
    "available_cash_for_trading = df.loc[date, 'available_cash'] * (1 - cash_buffer_percentage)\n",
    "\n",
    "## Estimated Transaction Costs and Fees\n",
    "est_fees = (transaction_cost_est + perf.estimate_fee_per_trade(passive_trade_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af41606f-3869-4009-b5ff-397eddaaaea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple, Optional\n",
    "# ---------- state file I/O ----------\n",
    "def load_state(path: Path) -> dict:\n",
    "    if not path.exists():\n",
    "        return {}\n",
    "    try:\n",
    "        with open(path, \"r\") as f:\n",
    "            content = f.read().strip()\n",
    "            if not content:  # empty file\n",
    "                return {}\n",
    "            return json.loads(content)\n",
    "    except json.JSONDecodeError:\n",
    "        # optionally quarantine the bad file so it doesn't keep breaking runs\n",
    "        try:\n",
    "            bad = path.with_suffix(\".corrupt-\" + datetime.now(timezone.utc).strftime(\"%Y%m%dT%H%M%SZ\"))\n",
    "            os.replace(path, bad)\n",
    "            print(f\"[warn] State file was invalid JSON. Moved to: {bad}\")\n",
    "        except Exception:\n",
    "            # if we can't move it, just ignore and continue with empty state\n",
    "            pass\n",
    "        return {}\n",
    "\n",
    "def is_in_cooldown(state_path: Path, ticker: str, today) -> Tuple[bool, int]:\n",
    "    \"\"\"Return (active, days_remaining). days_remaining >= 0 while active.\"\"\"\n",
    "    state = load_state(state_path)\n",
    "    rec = state.get(ticker)\n",
    "    if not rec:\n",
    "        return False, 0\n",
    "    today_d = _as_utc_date(today)\n",
    "    until_d = _from_iso_date(rec[\"cooldown_until\"])\n",
    "    if today_d < until_d:\n",
    "        return True, (until_d - today_d).days\n",
    "    return False, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaf830b-cdea-4ba4-9334-983606e70b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _entry_allowed_long(curr_price, stop_today, eps=0.0):\n",
    "    \"\"\"\n",
    "    Gate for NEW/ADDED long risk:\n",
    "    - allow only if current price is strictly above today's stop (plus optional eps).\n",
    "    \"\"\"\n",
    "    return np.isfinite(curr_price) and np.isfinite(stop_today) and (curr_price > stop_today * (1 + eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897d28b6-51a4-4094-b1f5-2a9d4fe9328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date as date_cls\n",
    "\n",
    "DEFAULT_COOLDOWN_DAYS = 7\n",
    "\n",
    "def _as_utc_date(x):\n",
    "    \"\"\"\n",
    "    Return a *date* in UTC terms.\n",
    "    - If x is tz-aware: convert to UTC then take .date()\n",
    "    - If x is tz-naive (your current setup): just take .date()\n",
    "      (because you already pass normalized midnight timestamps / trading-day anchors)\n",
    "    \"\"\"\n",
    "    if x is None:\n",
    "        return None\n",
    "\n",
    "    # If it's already a python date (not datetime), keep it\n",
    "    if isinstance(x, date_cls) and not hasattr(x, \"hour\"):\n",
    "        return x\n",
    "\n",
    "    ts = pd.Timestamp(x)\n",
    "\n",
    "    if ts.tz is None:\n",
    "        # tz-naive: can't tz_convert; treat as already \"day label\"\n",
    "        return ts.date()\n",
    "\n",
    "    return ts.tz_convert(\"UTC\").date()\n",
    "\n",
    "def start_cooldown(\n",
    "    state_path: Path,\n",
    "    ticker: str,\n",
    "    breach_date,\n",
    "    cooldown_counter_threshold: int = DEFAULT_COOLDOWN_DAYS,\n",
    "    note: str = \"\",\n",
    "    log_path: Optional[Path] = None\n",
    ") -> dict:\n",
    "    \"\"\"Start/refresh cooldown from breach_date (UTC date).\"\"\"\n",
    "    state = state.load_state(state_path)\n",
    "    bdate = _as_utc_date(breach_date)\n",
    "    until = bdate + timedelta(days=cooldown_counter_threshold)  # buys allowed on/after 'until'\n",
    "    rec = {\n",
    "        \"last_breach_date\": _iso_date(bdate),\n",
    "        \"cooldown_until\":   _iso_date(until),\n",
    "        \"note\":             note or \"stop_breached\"\n",
    "    }\n",
    "    state[ticker] = rec\n",
    "    state.save_state(state_path, state)\n",
    "\n",
    "    if log_path:\n",
    "        state.append_event_log(log_path, {\n",
    "            \"ts\": datetime.now(timezone.utc).isoformat(),\n",
    "            \"ticker\": ticker,\n",
    "            \"event\": \"start_cooldown\",\n",
    "            \"breach_date\": state._iso_date(bdate),\n",
    "            \"cooldown_until\": state._iso_date(until),\n",
    "            \"note\": note,\n",
    "        })\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5f30f6-cc63-4f66-8e3a-91275b0ccb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import stop_loss_cooldown_state as state\n",
    "\n",
    "for ticker in ticker_list:\n",
    "    print(ticker)\n",
    "    ## Calculate the cash need from all new target positions\n",
    "    target_notional = df.loc[date, f'{ticker}_target_notional']\n",
    "    current_notional = df.loc[date, f'{ticker}_open_position_notional']\n",
    "    new_trade_notional = target_notional - current_notional\n",
    "    trade_fees = abs(new_trade_notional) * est_fees\n",
    "    mid_px = float(current_positions[ticker]['ticker_mid_price'])\n",
    "\n",
    "    ## Calculate notional difference to determine if a trade is warranted\n",
    "    portfolio_equity_trade_threshold = notional_threshold_pct * total_portfolio_value\n",
    "    notional_threshold = notional_threshold_pct * abs(target_notional)\n",
    "    notional_floors_list = [\n",
    "        portfolio_equity_trade_threshold, notional_threshold, min_trade_notional_abs\n",
    "    ]\n",
    "    notional_floor = max(notional_floors_list)\n",
    "\n",
    "    # --- STOP-GATE: block NEW/ADDED long exposure if stop is breached/invalid ---\n",
    "    # We only gate when the delta adds long dollar risk (delta > 0).\n",
    "    if new_trade_notional > 0:\n",
    "        cooldown_active, days_left = state.is_in_cooldown(COOLDOWN_STATE_FILE, ticker, today=date)\n",
    "        if cooldown_active:\n",
    "            df.loc[date, f'{ticker}_stopout_flag'] = True\n",
    "            df.loc[date, f'{ticker}_cooldown_counter'] = float(days_left)\n",
    "            df.loc[date, f'{ticker}_event'] = f'cooldown_active({int(days_left)}d_left)'\n",
    "            desired_positions[ticker] = {'new_trade_notional': 0.0,\n",
    "                                         'trade_fees': 0.0,\n",
    "                                         'reason': 'cooldown_active'}\n",
    "            continue\n",
    "\n",
    "        stop_today = df.loc[date, f'{ticker}_stop_loss']  # _long_stop_for_today(ticker)\n",
    "        print(f'Ticker: {ticker}, Ticker Mid Price: {mid_px}, Stop Loss Price: {stop_today}')\n",
    "        if not _entry_allowed_long(curr_price=mid_px, stop_today=stop_today, eps=0.0):\n",
    "            # Block the buy; keep delta at zero but still record the stop for transparency.\n",
    "            df.loc[date, f'{ticker}_stopout_flag'] = True\n",
    "            df.loc[date, f'{ticker}_event'] = 'Stop Breached'\n",
    "            # df.loc[date, f'{ticker}_stop_loss']    = float(stop_today)\n",
    "            # Start cooldown (and log it); buys will be blocked from now on.\n",
    "            state.start_cooldown(\n",
    "                state_path=COOLDOWN_STATE_FILE,\n",
    "                ticker=ticker,\n",
    "                breach_date=date,\n",
    "                cooldown_counter_threshold=cooldown_counter_threshold,\n",
    "                note=f\"gate_block@{mid_px}\",\n",
    "                log_path=COOLDOWN_LOG_FILE\n",
    "            )\n",
    "            _, days_left = state.is_in_cooldown(COOLDOWN_STATE_FILE, ticker, today=date)\n",
    "            df.loc[date, f'{ticker}_cooldown_counter'] = float(days_left)\n",
    "            desired_positions[ticker] = {'new_trade_notional': 0.0,\n",
    "                                         'trade_fees': 0.0,\n",
    "                                         'reason': 'stop_breached'}\n",
    "            continue\n",
    "        else:\n",
    "            df.loc[date, f'{ticker}_stopout_flag'] = False\n",
    "            df.loc[date, f'{ticker}_stop_loss'] = float(stop_today)\n",
    "            df.loc[date, f'{ticker}_cooldown_counter'] = 0.0\n",
    "    # For sells or flat, we don’t block: let risk come off if needed.\n",
    "\n",
    "    if abs(new_trade_notional) > notional_floor:\n",
    "        desired_positions[ticker] = {'new_trade_notional': new_trade_notional,\n",
    "                                     'trade_fees': trade_fees,\n",
    "                                     'reason': 'threshold_pass'}\n",
    "    else:\n",
    "        desired_positions[ticker] = {'new_trade_notional': 0,\n",
    "                                     'trade_fees': 0,\n",
    "                                     'reason': 'below_threshold'}\n",
    "\n",
    "    if new_trade_notional >= 0:\n",
    "        ## Buys\n",
    "        cash_debit = cash_debit + new_trade_notional\n",
    "    else:\n",
    "        ## Sells\n",
    "        net_trade_notional = new_trade_notional + trade_fees\n",
    "        cash_credit = cash_credit + abs(net_trade_notional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136f6677-c90f-422b-8296-79e2cad7045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_cooldown(\n",
    "    state_path: Path,\n",
    "    ticker: str,\n",
    "    breach_date,\n",
    "    cooldown_counter_threshold: int = DEFAULT_COOLDOWN_DAYS,\n",
    "    note: str = \"\",\n",
    "    log_path: Optional[Path] = None\n",
    ") -> dict:\n",
    "    \"\"\"Start/refresh cooldown from breach_date (UTC date).\"\"\"\n",
    "    state = load_state(state_path)\n",
    "    bdate = _as_utc_date(breach_date)\n",
    "    until = bdate + timedelta(days=cooldown_counter_threshold)  # buys allowed on/after 'until'\n",
    "    rec = {\n",
    "        \"last_breach_date\": _iso_date(bdate),\n",
    "        \"cooldown_until\":   _iso_date(until),\n",
    "        \"note\":             note or \"stop_breached\"\n",
    "    }\n",
    "    state[ticker] = rec\n",
    "    save_state(state_path, state)\n",
    "\n",
    "    if log_path:\n",
    "        append_event_log(log_path, {\n",
    "            \"ts\": datetime.now(timezone.utc).isoformat(),\n",
    "            \"ticker\": ticker,\n",
    "            \"event\": \"start_cooldown\",\n",
    "            \"breach_date\": _iso_date(bdate),\n",
    "            \"cooldown_until\": _iso_date(until),\n",
    "            \"note\": note,\n",
    "        })\n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a0d481-1914-44fc-ab4a-b2c055b37212",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_path = load_state(COOLDOWN_STATE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0e47d6-df06-4c87-99f1-76392d5c9319",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74626ed-a218-41e0-ad98-ba32f8e1c331",
   "metadata": {},
   "outputs": [],
   "source": [
    "bdate = state._as_utc_date(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83edffef-ccf5-4d6e-a5b7-a5ca059061ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eabacc-deda-4d59-870d-11b22b4afeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(date, datetime):\n",
    "    print('True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cbaf65-b4d2-4d2e-8c03-bee6365d9c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "date.astimezone(timezone.utc)#.date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2948bf-eee3-4f01-89db-8c7275172a51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d4e956-c713-4c54-b52d-4b991261d71b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86c9027-9822-45e3-8cc7-8eb373db8c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afd3036-ee9a-4791-a9dc-a25eb2e27704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d47764-f433-4dea-b3f2-669277853304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352c0068-f88c-4979-abfe-b78a352f908c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a2d035-8f7d-4e52-873c-8629afdf9c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe090e2-a407-4fd1-9a0d-5fbc9af9bd9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a0ad8a-97f4-455b-b50e-0f4a743edadc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f084ed-6591-4192-bd12-c8bc84bc5219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f66828-d892-4eb4-8ff7-fefe15a13c04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bec5fb-8cb7-4321-8897-05698605ec89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bab014-690e-4656-8858-6ed77ccf64f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fda7ab9-a609-4f14-88b2-885383e5f494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdb4edf-cd12-4b15-a3cd-ca5cc6945ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
