{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5ab0428-e682-4aca-a2de-1d2e4eb4a764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary modules\n",
    "import os\n",
    "import sys\n",
    "import os, sys\n",
    "# from .../research/notebooks -> go up two levels to repo root\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.insert(0, repo_root)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as mtick\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score \n",
    "import pandas_datareader as pdr\n",
    "import math\n",
    "import datetime\n",
    "from datetime import datetime, timezone\n",
    "import itertools\n",
    "import ast\n",
    "import yfinance as yf\n",
    "import seaborn as sn\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from IPython.display import display, HTML\n",
    "from strategy_signal.trend_following_signal import (\n",
    "    apply_jupyter_fullscreen_css, get_trend_donchian_signal_for_portfolio_with_rolling_r_sqr_vol_of_vol\n",
    ")\n",
    "from portfolio.strategy_performance import (calculate_sharpe_ratio, calculate_calmar_ratio, calculate_CAGR, calculate_risk_and_performance_metrics,\n",
    "                                          calculate_compounded_cumulative_returns, estimate_fee_per_trade, rolling_sharpe_ratio)\n",
    "from utils import coinbase_utils as cn\n",
    "from portfolio import strategy_performance as perf\n",
    "from sizing import position_sizing_binary_utils as size_bin\n",
    "from sizing import position_sizing_continuous_utils as size_cont\n",
    "from strategy_signal import trend_following_signal as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6ab66ec-71a1-4154-8214-15a9bdb19f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'sizing.position_sizing_continuous_utils' from '/Users/adheerchauhan/Documents/git/trend_following/sizing/position_sizing_continuous_utils.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(cn)\n",
    "importlib.reload(perf)\n",
    "importlib.reload(tf)\n",
    "importlib.reload(size_bin)\n",
    "importlib.reload(size_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2b61ec8-6a51-436c-8b5a-94fc3da431ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>:root {\n",
       "    --jp-notebook-max-width: 100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('Display.max_rows', None)\n",
    "pd.set_option('Display.max_columns',None)\n",
    "apply_jupyter_fullscreen_css()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20b4568-bcc4-4cb7-a4fd-2fea43cb8c1b",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a4bb0a5-fad5-4fa7-a600-1644f2aa71ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Config file for the strategy\n",
    "def load_prod_strategy_config(strategy_version='v0.1.0'):\n",
    "    nb_cwd = Path.cwd()  # git/trend_following/research/notebooks\n",
    "    config_path = (\n",
    "            nb_cwd.parents[1]  # -> git/trend_following\n",
    "            / \"live_strategy\"\n",
    "            / f\"trend_following_strategy_{strategy_version}-live\"\n",
    "            / \"config\"\n",
    "            / f\"trend_strategy_config_{strategy_version}.yaml\"\n",
    "    )\n",
    "\n",
    "    print(config_path)  # sanity check\n",
    "    print(config_path.exists())  # should be True\n",
    "\n",
    "    with open(config_path, \"r\") as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44b0b7b6-faa0-418b-bd11-9827ab86de3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def print_strategy_params():\n",
    "    \"\"\"\n",
    "    Pretty-print the strategyâ€™s configuration values, with a blank line\n",
    "    separating each logical section.\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- Define sections (title is just for dev readability) --------------\n",
    "    sections = [\n",
    "        (\"Dates & universe\", OrderedDict([\n",
    "            (\"start_date\",      start_date),\n",
    "            (\"end_date\",        end_date),\n",
    "            (\"warm_up_days\",    WARMUP_DAYS),\n",
    "            (\"ticker_list\",     ticker_list),\n",
    "        ])),\n",
    "\n",
    "        (\"Moving-average / trend\", OrderedDict([\n",
    "            (\"fast_mavg\",                  fast_mavg),\n",
    "            (\"slow_mavg\",                  slow_mavg),\n",
    "            (\"mavg_stepsize\",              mavg_stepsize),\n",
    "            (\"mavg_z_score_window\",        mavg_z_score_window),\n",
    "            (\"moving_avg_type\",            moving_avg_type),\n",
    "            (\"ma_crossover_signal_weight\", ma_crossover_signal_weight),\n",
    "        ])),\n",
    "\n",
    "        (\"Donchian channel\", OrderedDict([\n",
    "            (\"entry_rolling_donchian_window\", entry_rolling_donchian_window),\n",
    "            (\"exit_rolling_donchian_window\", exit_rolling_donchian_window),\n",
    "            (\"use_donchian_exit_gate\", use_donchian_exit_gate),\n",
    "            (\"donchian_signal_weight\",  donchian_signal_weight),\n",
    "        ])),\n",
    "\n",
    "        (\"Volatility & risk\", OrderedDict([\n",
    "            (\"volatility_window\",            volatility_window),\n",
    "            (\"annualized_target_volatility\", annualized_target_volatility),\n",
    "            (\"rolling_cov_window\",           rolling_cov_window),\n",
    "            (\"rolling_atr_window\",           rolling_atr_window),\n",
    "            (\"atr_multiplier\",               atr_multiplier),\n",
    "            (\"log_std_window\",               log_std_window),\n",
    "            (\"coef_of_variation_window\",     coef_of_variation_window),\n",
    "            (\"vol_of_vol_z_score_window\",    vol_of_vol_z_score_window),\n",
    "            (\"vol_of_vol_p_min\",             vol_of_vol_p_min),\n",
    "            (\"r2_strong_threshold\",          r2_strong_threshold)\n",
    "        ])),\n",
    "\n",
    "        (\"Signal gating / quality\", OrderedDict([\n",
    "            (\"lower_r_sqr_limit\",             lower_r_sqr_limit),\n",
    "            (\"upper_r_sqr_limit\",             upper_r_sqr_limit),\n",
    "            (\"rolling_r2_window\",             rolling_r2_window),\n",
    "            (\"r2_smooth_window\",              r2_smooth_window),\n",
    "            (\"r2_confirm_days\",               r2_confirm_days),\n",
    "            (\"rolling_sharpe_window\",         rolling_sharpe_window),\n",
    "            (\"use_activation\",                use_activation),\n",
    "            (\"tanh_activation_constant_dict\", tanh_activation_constant_dict),\n",
    "            (\"weighted_signal_ewm_window\",    weighted_signal_ewm_window)\n",
    "        ])),\n",
    "\n",
    "        (\"Trading toggles & thresholds\", OrderedDict([\n",
    "            (\"long_only\",                  long_only),\n",
    "            (\"use_coinbase_data\",          use_coinbase_data),\n",
    "            (\"use_saved_files\",            use_saved_files),\n",
    "            (\"saved_file_end_date\",        saved_file_end_date),\n",
    "            (\"use_specific_start_date\",    use_specific_start_date),\n",
    "            (\"signal_start_date\",          signal_start_date),\n",
    "            (\"price_or_returns_calc\",      price_or_returns_calc),\n",
    "            (\"notional_threshold_pct\",     notional_threshold_pct),\n",
    "            (\"cooldown_counter_threshold\", cooldown_counter_threshold),\n",
    "            (\"warmup_days\",                WARMUP_DAYS)\n",
    "        ])),\n",
    "\n",
    "        (\"Capital & execution\", OrderedDict([\n",
    "            (\"initial_capital\",        initial_capital),\n",
    "            (\"cash_buffer_percentage\", cash_buffer_percentage),\n",
    "            (\"transaction_cost_est\",   transaction_cost_est),\n",
    "            (\"passive_trade_rate\",     passive_trade_rate),\n",
    "            (\"annual_trading_days\",    annual_trading_days),\n",
    "        ])),\n",
    "    ]\n",
    "\n",
    "    # ---- Compute width for neat alignment ---------------------------------\n",
    "    longest_key = max(len(k) for _, sec in sections for k in sec)\n",
    "\n",
    "    print(\"\\nStrategy Parameters\\n\" + \"-\" * (longest_key + 30))\n",
    "    for _, sec in sections:\n",
    "        for k, v in sec.items():\n",
    "            print(f\"{k:<{longest_key}} : {v}\")\n",
    "        print()  # blank line between sections\n",
    "    print(\"-\" * (longest_key + 30) + \"\\n\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Example usage (uncomment after your own parameter definitions are in scope)\n",
    "# ---------------------------------------------------------------------------\n",
    "# if __name__ == \"__main__\":\n",
    "#     print_strategy_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee97eb76-1d13-404f-8f42-871f118e8c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_signal_performance(df_1, df_2, ticker):\n",
    "\n",
    "    fig = plt.figure(figsize=(20,12))\n",
    "    layout = (2,2)\n",
    "    signal_ax = plt.subplot2grid(layout, (0,0))\n",
    "    price_ax = signal_ax.twinx()\n",
    "    equity_curve_ax = plt.subplot2grid(layout, (0,1))\n",
    "    sharpe_ax = plt.subplot2grid(layout, (1,0))\n",
    "    portfolio_value_ax = plt.subplot2grid(layout, (1,1))\n",
    "\n",
    "    _ = signal_ax.plot(df_1.index, df_1[f'{ticker}_final_signal'], label='Orig Signal', alpha=0.9)\n",
    "    _ = signal_ax.plot(df_2.index, df_2[f'{ticker}_final_signal'], label='New Signal', alpha=0.9)\n",
    "    _ = price_ax.plot(df_1.index, df_2[f'{ticker}_open'], label='Price', alpha=0.7, linestyle='--', color='magenta')\n",
    "    _ = signal_ax.set_title(f'Orignal Signal vs New Signal')\n",
    "    _ = signal_ax.set_ylabel('Signal')\n",
    "    _ = signal_ax.set_xlabel('Date')\n",
    "    _ = signal_ax.legend(loc='upper left')\n",
    "    _ = signal_ax.grid()\n",
    "\n",
    "    _ = equity_curve_ax.plot(df_1.index, df_1[f'equity_curve'], label='Orig Signal', alpha=0.9)\n",
    "    _ = equity_curve_ax.plot(df_2.index, df_2[f'equity_curve'], label='New Signal', alpha=0.9)\n",
    "    _ = equity_curve_ax.set_title(f'Equity Curve')\n",
    "    _ = equity_curve_ax.set_ylabel('Equity Curve')\n",
    "    _ = equity_curve_ax.set_xlabel('Date')\n",
    "    _ = equity_curve_ax.legend(loc='upper left')\n",
    "    _ = equity_curve_ax.grid()\n",
    "\n",
    "    _ = sharpe_ax.plot(df_1.index, df_1[f'portfolio_rolling_sharpe_50'], label='Orig Signal', alpha=0.9)\n",
    "    _ = sharpe_ax.plot(df_2.index, df_2[f'portfolio_rolling_sharpe_50'], label='New Signal', alpha=0.9)\n",
    "    _ = sharpe_ax.set_title(f'Rolling Sharpe')\n",
    "    _ = sharpe_ax.set_ylabel(f'Rolling Sharpe')\n",
    "    _ = sharpe_ax.set_xlabel('Date')\n",
    "    _ = sharpe_ax.legend(loc='upper left')\n",
    "    _ = sharpe_ax.grid()\n",
    "\n",
    "    _ = portfolio_value_ax.plot(df_1.index, df_1[f'total_portfolio_value'], label='Orig Signal', alpha=0.9)\n",
    "    _ = portfolio_value_ax.plot(df_2.index, df_2[f'total_portfolio_value'], label='New Signal', alpha=0.9)\n",
    "    _ = portfolio_value_ax.set_title(f'Total Portfolio Value')\n",
    "    _ = portfolio_value_ax.set_ylabel('Portfolio Value')\n",
    "    _ = portfolio_value_ax.set_xlabel('Date')\n",
    "    _ = portfolio_value_ax.legend(loc='upper left')\n",
    "    _ = portfolio_value_ax.grid()\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc838933-1547-4cff-b20a-d471c81383e7",
   "metadata": {},
   "source": [
    "## Signal Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11b232df-7e4c-4983-a3de-43e7b41ce174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/adheerchauhan/Documents/git/trend_following/live_strategy/trend_following_strategy_v0.1.0-live/config/trend_strategy_config_v0.1.0.yaml\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "cfg = load_prod_strategy_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cc430b3-cae0-41ab-80ab-01d50a666f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'portfolio': {'exchange': 'Coinbase Advanced', 'name': 'Trend Following'},\n",
       " 'run': {'start_date': '2022-04-01',\n",
       "  'end_date': '2025-07-31',\n",
       "  'use_specific_start_date': True,\n",
       "  'signal_start_date': '2022-04-01',\n",
       "  'warmup_days': 300,\n",
       "  'long_only': True,\n",
       "  'annual_trading_days': 365,\n",
       "  'initial_capital': 15000},\n",
       " 'universe': {'tickers': ['BTC-USD',\n",
       "   'ETH-USD',\n",
       "   'SOL-USD',\n",
       "   'ADA-USD',\n",
       "   'AVAX-USD']},\n",
       " 'data': {'use_coinbase_data': True,\n",
       "  'use_saved_files': True,\n",
       "  'saved_file_end_date': '2025-07-31',\n",
       "  'price_or_returns_calc': 'price',\n",
       "  'moving_avg_type': 'exponential'},\n",
       " 'signals': {'moving_average': {'fast_mavg': 20,\n",
       "   'slow_mavg': 200,\n",
       "   'mavg_stepsize': 8,\n",
       "   'mavg_z_score_window': 126},\n",
       "  'donchian': {'entry_rolling_donchian_window': 56,\n",
       "   'exit_rolling_donchian_window': 28,\n",
       "   'use_donchian_exit_gate': False},\n",
       "  'weighting': {'ma_crossover_signal_weight': 0.85,\n",
       "   'donchian_signal_weight': 0.15,\n",
       "   'weighted_signal_ewm_window': 4},\n",
       "  'activation': {'use_activation': False,\n",
       "   'tanh_activation_constant_dict': None},\n",
       "  'filters': {'rolling_r2': {'rolling_r2_window': 100,\n",
       "    'lower_r_sqr_limit': 0.45,\n",
       "    'upper_r_sqr_limit': 0.9,\n",
       "    'r2_smooth_window': 3,\n",
       "    'r2_confirm_days': 0,\n",
       "    'r2_strong_threshold': 0.75},\n",
       "   'vol_of_vol': {'log_std_window': 14,\n",
       "    'coef_of_variation_window': 20,\n",
       "    'vol_of_vol_z_score_window': 126,\n",
       "    'vol_of_vol_p_min': 0.1}}},\n",
       " 'risk_and_sizing': {'annualized_target_volatility': 0.45,\n",
       "  'volatility_window': 30,\n",
       "  'rolling_cov_window': 30,\n",
       "  'rolling_atr_window': 20,\n",
       "  'atr_multiplier': 1.75,\n",
       "  'stop_loss_strategy': 'Chandelier',\n",
       "  'highest_high_window': 56,\n",
       "  'rolling_sharpe_window': 50,\n",
       "  'cash_buffer_percentage': 0.15},\n",
       " 'execution_and_costs': {'transaction_cost_est': 0.001,\n",
       "  'passive_trade_rate': 0.05,\n",
       "  'notional_threshold_pct': 0.1,\n",
       "  'min_trade_notional_abs': 10,\n",
       "  'cooldown_counter_threshold': 7}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44cd4e82-74ff-4a94-8372-2a0b3d991adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# assume cfg is already loaded from YAML as shown in your message\n",
    "\n",
    "# --- Prod Configuration (from cfg) ---\n",
    "\n",
    "# portfolio\n",
    "exchange = cfg['portfolio']['exchange']\n",
    "portfolio_name = cfg['portfolio']['name']\n",
    "\n",
    "start_date  = pd.Timestamp(cfg['run']['start_date']).date()\n",
    "end_date    = pd.Timestamp(cfg['run']['end_date']).date()\n",
    "use_specific_start_date = bool(cfg['run']['use_specific_start_date'])\n",
    "signal_start_date       = pd.Timestamp(cfg['run']['signal_start_date']).date()\n",
    "warmup_days = int(cfg['run']['warmup_days'])\n",
    "long_only = cfg['run']['long_only']\n",
    "annual_trading_days    = int(cfg['run']['annual_trading_days'])\n",
    "initial_capital        = float(cfg['run']['initial_capital'])\n",
    "\n",
    "# universe\n",
    "ticker_list = list(cfg['universe']['tickers'])\n",
    "\n",
    "# data\n",
    "use_coinbase_data      = bool(cfg['data']['use_coinbase_data'])\n",
    "use_saved_files        = bool(cfg['data']['use_saved_files'])\n",
    "saved_file_end_date    = str(cfg['data']['saved_file_end_date'])\n",
    "price_or_returns_calc    = str(cfg['data']['price_or_returns_calc'])\n",
    "moving_avg_type    = str(cfg['data']['moving_avg_type'])\n",
    "\n",
    "# signals.moving_average\n",
    "fast_mavg        = int(cfg['signals']['moving_average']['fast_mavg'])\n",
    "slow_mavg        = int(cfg['signals']['moving_average']['slow_mavg'])\n",
    "mavg_stepsize    = int(cfg['signals']['moving_average']['mavg_stepsize'])\n",
    "mavg_z_score_window = int(cfg['signals']['moving_average']['mavg_z_score_window'])\n",
    "\n",
    "# signals.donchian\n",
    "entry_rolling_donchian_window = int(cfg['signals']['donchian']['entry_rolling_donchian_window'])\n",
    "exit_rolling_donchian_window  = int(cfg['signals']['donchian']['exit_rolling_donchian_window'])\n",
    "use_donchian_exit_gate        = bool(cfg['signals']['donchian']['use_donchian_exit_gate'])\n",
    "\n",
    "# signals.weighting\n",
    "ma_crossover_signal_weight = float(cfg['signals']['weighting']['ma_crossover_signal_weight'])\n",
    "donchian_signal_weight     = float(cfg['signals']['weighting']['donchian_signal_weight'])\n",
    "weighted_signal_ewm_window = int(cfg['signals']['weighting']['weighted_signal_ewm_window'])  # (new config but same value)\n",
    "\n",
    "# signals.filters.rolling_r2\n",
    "rolling_r2_window   = int(cfg['signals']['filters']['rolling_r2']['rolling_r2_window'])\n",
    "lower_r_sqr_limit   = float(cfg['signals']['filters']['rolling_r2']['lower_r_sqr_limit'])\n",
    "upper_r_sqr_limit   = float(cfg['signals']['filters']['rolling_r2']['upper_r_sqr_limit'])\n",
    "r2_smooth_window    = int(cfg['signals']['filters']['rolling_r2']['r2_smooth_window'])\n",
    "r2_confirm_days     = int(cfg['signals']['filters']['rolling_r2']['r2_confirm_days'])\n",
    "r2_strong_threshold = float(cfg['signals']['filters']['rolling_r2']['r2_strong_threshold'])\n",
    "\n",
    "# signals.filters.vol_of_vol\n",
    "log_std_window            = int(cfg['signals']['filters']['vol_of_vol']['log_std_window'])\n",
    "coef_of_variation_window  = int(cfg['signals']['filters']['vol_of_vol']['coef_of_variation_window'])\n",
    "vol_of_vol_z_score_window = int(cfg['signals']['filters']['vol_of_vol']['vol_of_vol_z_score_window'])\n",
    "vol_of_vol_p_min          = float(cfg['signals']['filters']['vol_of_vol']['vol_of_vol_p_min'])\n",
    "\n",
    "# signals.activation\n",
    "use_activation              = bool(cfg['signals']['activation']['use_activation'])\n",
    "tanh_activation_constant_dict = cfg['signals']['activation']['tanh_activation_constant_dict']  # likely None\n",
    "\n",
    "# risk_and_sizing\n",
    "annualized_target_volatility = float(cfg['risk_and_sizing']['annualized_target_volatility'])\n",
    "volatility_window      = int(cfg['risk_and_sizing']['volatility_window'])\n",
    "rolling_cov_window     = int(cfg['risk_and_sizing']['rolling_cov_window'])\n",
    "rolling_atr_window     = int(cfg['risk_and_sizing']['rolling_atr_window'])\n",
    "atr_multiplier         = float(cfg['risk_and_sizing']['atr_multiplier'])\n",
    "stop_loss_strategy     = str(cfg['risk_and_sizing']['stop_loss_strategy'])\n",
    "highest_high_window    = int(cfg['risk_and_sizing']['highest_high_window'])\n",
    "rolling_sharpe_window    = int(cfg['risk_and_sizing']['rolling_sharpe_window'])\n",
    "cash_buffer_percentage = float(cfg['risk_and_sizing']['cash_buffer_percentage'])\n",
    "\n",
    "# execution_and_costs\n",
    "transaction_cost_est   = float(cfg['execution_and_costs']['transaction_cost_est'])\n",
    "passive_trade_rate     = float(cfg['execution_and_costs']['passive_trade_rate'])\n",
    "notional_threshold_pct = float(cfg['execution_and_costs']['notional_threshold_pct'])\n",
    "min_trade_notional_abs = float(cfg['execution_and_costs']['min_trade_notional_abs'])\n",
    "cooldown_counter_threshold = int(cfg['execution_and_costs']['cooldown_counter_threshold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ca4573-1726-4e67-82b3-fb7bb5dc8f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_saved_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cde3fe-1a16-453f-ac4f-30899c0fca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_prod_config = tf.apply_target_volatility_position_sizing_continuous_strategy_with_rolling_r_sqr_vol_of_vol(\n",
    "    start_date=start_date - pd.Timedelta(days=warmup_days), end_date=end_date, ticker_list=ticker_list, fast_mavg=fast_mavg, slow_mavg=slow_mavg, mavg_stepsize=mavg_stepsize, mavg_z_score_window=mavg_z_score_window, \n",
    "    entry_rolling_donchian_window=entry_rolling_donchian_window, exit_rolling_donchian_window=exit_rolling_donchian_window, use_donchian_exit_gate=use_donchian_exit_gate, \n",
    "    ma_crossover_signal_weight=ma_crossover_signal_weight, donchian_signal_weight=donchian_signal_weight, weighted_signal_ewm_window=weighted_signal_ewm_window,\n",
    "    rolling_r2_window=rolling_r2_window, lower_r_sqr_limit=lower_r_sqr_limit, upper_r_sqr_limit=upper_r_sqr_limit, r2_smooth_window=r2_smooth_window, r2_confirm_days=r2_confirm_days,\n",
    "    log_std_window=log_std_window, coef_of_variation_window=coef_of_variation_window, vol_of_vol_z_score_window=vol_of_vol_z_score_window, vol_of_vol_p_min=vol_of_vol_p_min, r2_strong_threshold=r2_strong_threshold,\n",
    "    use_activation=use_activation, tanh_activation_constant_dict=tanh_activation_constant_dict,\n",
    "    moving_avg_type=moving_avg_type, long_only=long_only, price_or_returns_calc=price_or_returns_calc,\n",
    "    initial_capital=initial_capital, rolling_cov_window=rolling_cov_window, volatility_window=volatility_window,\n",
    "    rolling_atr_window=rolling_atr_window, atr_multiplier=atr_multiplier,\n",
    "    transaction_cost_est=transaction_cost_est, passive_trade_rate=passive_trade_rate,\n",
    "    notional_threshold_pct=notional_threshold_pct, cooldown_counter_threshold=cooldown_counter_threshold,\n",
    "    use_coinbase_data=use_coinbase_data, use_saved_files=use_saved_files, saved_file_end_date=saved_file_end_date, \n",
    "    rolling_sharpe_window=rolling_sharpe_window, cash_buffer_percentage=cash_buffer_percentage, annualized_target_volatility=annualized_target_volatility,\n",
    "    annual_trading_days=annual_trading_days, use_specific_start_date=use_specific_start_date, signal_start_date=start_date)\n",
    "df_final_prod_config = df_final_prod_config[df_final_prod_config.index >= pd.Timestamp(start_date)]\n",
    "\n",
    "print('Calculating In Sample Asset Returns!!')\n",
    "df_final_prod_config = perf.calculate_asset_level_returns(df_final_prod_config, end_date, ticker_list)\n",
    "\n",
    "portfolio_perf_metrics_prod_config = calculate_risk_and_performance_metrics(df_final_prod_config, strategy_daily_return_col=f'portfolio_daily_pct_returns',\n",
    "                                                                           strategy_trade_count_col=f'count_of_positions', include_transaction_costs_and_fees=False, passive_trade_rate=0.05, annual_trading_days=365, transaction_cost_est=0.001)\n",
    "portfolio_perf_metrics_prod_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa62a1d-decf-4c0f-9d35-0b50c7d25a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_perf_prod_config = {}\n",
    "for t in cfg['universe']['tickers']:\n",
    "    _ticker_perf = perf.calculate_risk_and_performance_metrics(\n",
    "        df_final_prod_config,\n",
    "        strategy_daily_return_col=f'{t}_daily_pct_returns',\n",
    "        strategy_trade_count_col=f'{t}_position_count',\n",
    "        annual_trading_days=365,\n",
    "        include_transaction_costs_and_fees=False\n",
    "    )\n",
    "    ticker_perf_prod_config[t] = _ticker_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131c71b1-28ee-4b7b-b211-077b8197884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_perf_prod_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb692a5-3b16-4c41-ac3b-0df0b96b7f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# assume cfg is already loaded from YAML as shown in your message\n",
    "\n",
    "# --- Prod Configuration (from cfg) ---\n",
    "start_date  = pd.Timestamp(cfg['run']['start_date']).date()\n",
    "end_date    = pd.Timestamp(cfg['run']['end_date']).date()\n",
    "warmup_days = int(cfg['run']['warmup_days'])\n",
    "\n",
    "# ticker_list = list(cfg['universe']['tickers'])\n",
    "ticker_list = ['BTC-USD', 'ETH-USD', 'SOL-USD', 'ADA-USD', 'AVAX-USD', 'LTC-USD', 'DOGE-USD', 'CRO-USD']\n",
    "\n",
    "# signals.moving_average\n",
    "fast_mavg        = int(cfg['signals']['moving_average']['fast_mavg'])\n",
    "slow_mavg        = int(cfg['signals']['moving_average']['slow_mavg'])\n",
    "mavg_stepsize    = int(cfg['signals']['moving_average']['mavg_stepsize'])\n",
    "mavg_z_score_window = int(cfg['signals']['moving_average']['mavg_z_score_window'])\n",
    "\n",
    "# signals.donchian\n",
    "entry_rolling_donchian_window = int(cfg['signals']['donchian']['entry_rolling_donchian_window'])\n",
    "exit_rolling_donchian_window  = int(cfg['signals']['donchian']['exit_rolling_donchian_window'])\n",
    "use_donchian_exit_gate        = bool(cfg['signals']['donchian']['use_donchian_exit_gate'])\n",
    "\n",
    "# signals.weighting\n",
    "ma_crossover_signal_weight = float(cfg['signals']['weighting']['ma_crossover_signal_weight'])\n",
    "donchian_signal_weight     = float(cfg['signals']['weighting']['donchian_signal_weight'])\n",
    "weighted_signal_ewm_window = int(cfg['signals']['weighting']['weighted_signal_ewm_window'])  # (new config but same value)\n",
    "\n",
    "# signals.filters.rolling_r2\n",
    "rolling_r2_window   = int(cfg['signals']['filters']['rolling_r2']['rolling_r2_window'])\n",
    "lower_r_sqr_limit   = float(cfg['signals']['filters']['rolling_r2']['lower_r_sqr_limit'])\n",
    "upper_r_sqr_limit   = float(cfg['signals']['filters']['rolling_r2']['upper_r_sqr_limit'])\n",
    "r2_smooth_window    = int(cfg['signals']['filters']['rolling_r2']['r2_smooth_window'])\n",
    "r2_confirm_days     = int(cfg['signals']['filters']['rolling_r2']['r2_confirm_days'])\n",
    "r2_strong_threshold = float(cfg['signals']['filters']['rolling_r2']['r2_strong_threshold'])\n",
    "\n",
    "# signals.filters.vol_of_vol\n",
    "log_std_window            = int(cfg['signals']['filters']['vol_of_vol']['log_std_window'])\n",
    "coef_of_variation_window  = int(cfg['signals']['filters']['vol_of_vol']['coef_of_variation_window'])\n",
    "vol_of_vol_z_score_window = int(cfg['signals']['filters']['vol_of_vol']['vol_of_vol_z_score_window'])\n",
    "vol_of_vol_p_min          = float(cfg['signals']['filters']['vol_of_vol']['vol_of_vol_p_min'])\n",
    "\n",
    "# signals.activation\n",
    "use_activation              = bool(cfg['signals']['activation']['use_activation'])\n",
    "tanh_activation_constant_dict = cfg['signals']['activation']['tanh_activation_constant_dict']  # likely None\n",
    "\n",
    "# data / run toggles\n",
    "moving_avg_type        = str(cfg['data']['moving_avg_type'])\n",
    "long_only              = bool(cfg['run']['long_only'])\n",
    "price_or_returns_calc  = str(cfg['data']['price_or_returns_calc'])\n",
    "\n",
    "initial_capital        = float(cfg['run']['initial_capital'])\n",
    "\n",
    "rolling_cov_window     = int(cfg['risk_and_sizing']['rolling_cov_window'])\n",
    "volatility_window      = int(cfg['risk_and_sizing']['volatility_window'])\n",
    "\n",
    "# stop loss strategy (new)\n",
    "stop_loss_strategy     = str(cfg['risk_and_sizing']['stop_loss_strategy'])\n",
    "rolling_atr_window     = int(cfg['risk_and_sizing']['rolling_atr_window'])\n",
    "atr_multiplier         = float(cfg['risk_and_sizing']['atr_multiplier'])\n",
    "highest_high_window    = int(cfg['risk_and_sizing']['highest_high_window'])\n",
    "\n",
    "# cooldown (new)\n",
    "cooldown_counter_threshold = int(cfg['execution_and_costs']['cooldown_counter_threshold'])\n",
    "\n",
    "# target vol (new value)\n",
    "annualized_target_volatility = float(cfg['risk_and_sizing']['annualized_target_volatility'])\n",
    "\n",
    "transaction_cost_est   = float(cfg['execution_and_costs']['transaction_cost_est'])\n",
    "passive_trade_rate     = float(cfg['execution_and_costs']['passive_trade_rate'])\n",
    "notional_threshold_pct = float(cfg['execution_and_costs']['notional_threshold_pct'])\n",
    "min_trade_notional_abs = float(cfg['execution_and_costs']['min_trade_notional_abs'])\n",
    "\n",
    "rolling_sharpe_window  = int(cfg['risk_and_sizing']['rolling_sharpe_window'])\n",
    "cash_buffer_percentage = float(cfg['risk_and_sizing']['cash_buffer_percentage'])\n",
    "annual_trading_days    = int(cfg['run']['annual_trading_days'])\n",
    "\n",
    "use_coinbase_data      = bool(cfg['data']['use_coinbase_data'])\n",
    "use_saved_files        = bool(cfg['data']['use_saved_files'])\n",
    "saved_file_end_date    = str(cfg['data']['saved_file_end_date'])\n",
    "\n",
    "use_specific_start_date = bool(cfg['run']['use_specific_start_date'])\n",
    "signal_start_date       = pd.Timestamp(cfg['run']['signal_start_date']).date()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe67db93-926d-4535-a367-e768ec4c4460",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871c0560-6b76-42da-ab1e-77241eb11b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_prod_config_expanded = tf.apply_target_volatility_position_sizing_continuous_strategy_with_rolling_r_sqr_vol_of_vol(\n",
    "    start_date=start_date - pd.Timedelta(days=warmup_days), end_date=end_date, ticker_list=ticker_list, fast_mavg=fast_mavg, slow_mavg=slow_mavg, mavg_stepsize=mavg_stepsize, mavg_z_score_window=mavg_z_score_window, \n",
    "    entry_rolling_donchian_window=entry_rolling_donchian_window, exit_rolling_donchian_window=exit_rolling_donchian_window, use_donchian_exit_gate=use_donchian_exit_gate, \n",
    "    ma_crossover_signal_weight=ma_crossover_signal_weight, donchian_signal_weight=donchian_signal_weight, weighted_signal_ewm_window=weighted_signal_ewm_window,\n",
    "    rolling_r2_window=rolling_r2_window, lower_r_sqr_limit=lower_r_sqr_limit, upper_r_sqr_limit=upper_r_sqr_limit, r2_smooth_window=r2_smooth_window, r2_confirm_days=r2_confirm_days,\n",
    "    log_std_window=log_std_window, coef_of_variation_window=coef_of_variation_window, vol_of_vol_z_score_window=vol_of_vol_z_score_window, vol_of_vol_p_min=vol_of_vol_p_min, r2_strong_threshold=r2_strong_threshold,\n",
    "    use_activation=use_activation, tanh_activation_constant_dict=tanh_activation_constant_dict,\n",
    "    moving_avg_type=moving_avg_type, long_only=long_only, price_or_returns_calc=price_or_returns_calc,\n",
    "    initial_capital=initial_capital, rolling_cov_window=rolling_cov_window, volatility_window=volatility_window,\n",
    "    rolling_atr_window=rolling_atr_window, atr_multiplier=atr_multiplier,\n",
    "    transaction_cost_est=transaction_cost_est, passive_trade_rate=passive_trade_rate,\n",
    "    notional_threshold_pct=notional_threshold_pct, cooldown_counter_threshold=cooldown_counter_threshold,\n",
    "    use_coinbase_data=use_coinbase_data, use_saved_files=False, saved_file_end_date=saved_file_end_date, \n",
    "    rolling_sharpe_window=rolling_sharpe_window, cash_buffer_percentage=cash_buffer_percentage, annualized_target_volatility=annualized_target_volatility,\n",
    "    annual_trading_days=annual_trading_days, use_specific_start_date=use_specific_start_date, signal_start_date=start_date)\n",
    "df_final_prod_config_expanded = df_final_prod_config_expanded[df_final_prod_config_expanded.index >= pd.Timestamp(start_date)]\n",
    "\n",
    "print('Calculating In Sample Asset Returns!!')\n",
    "df_final_prod_config_expanded = perf.calculate_asset_level_returns(df_final_prod_config_expanded, end_date, ticker_list)\n",
    "\n",
    "portfolio_perf_metrics_prod_config_expanded = calculate_risk_and_performance_metrics(df_final_prod_config_expanded, strategy_daily_return_col=f'portfolio_daily_pct_returns',\n",
    "                                                                                     strategy_trade_count_col=f'count_of_positions', include_transaction_costs_and_fees=False, passive_trade_rate=0.05, annual_trading_days=365, transaction_cost_est=0.001)\n",
    "portfolio_perf_metrics_prod_config_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ccc71b-7352-4804-8b71-cd1c0cf7c235",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_perf_prod_config_expanded = {}\n",
    "for t in ticker_list:\n",
    "    _ticker_perf = perf.calculate_risk_and_performance_metrics(\n",
    "        df_final_prod_config_expanded,\n",
    "        strategy_daily_return_col=f'{t}_daily_pct_returns',\n",
    "        strategy_trade_count_col=f'{t}_position_count',\n",
    "        annual_trading_days=365,\n",
    "        include_transaction_costs_and_fees=False\n",
    "    )\n",
    "    ticker_perf_prod_config_expanded[t] = _ticker_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905ace57-5128-4a76-8a21-ced1db354f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_perf_prod_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c79d7d3-b194-4b0c-9564-e46bd7776123",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_perf_prod_config_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a604f3e-9f44-4135-8e38-29ceeea2c4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_signal_performance(df_1=df_final_prod_config, df_2=df_final_prod_config_expanded, ticker='BTC-USD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f795c544-d78c-4ec0-868c-de92c02c1afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_prod_config_expanded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0fa868-a653-4c28-830d-183f45d5420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_prod_config_expanded['equity_curve'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6569c36e-132b-4e71-b2fc-01a107d5f392",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_signal_cols = [f'{ticker}_final_signal' for ticker in cfg['universe']['tickers']]\n",
    "df_final_prod_config[final_signal_cols].plot(figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2e15a8-60d2-4522-aa0e-b79b2ef524f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_signal_cols = [f'{ticker}_final_signal' for ticker in ticker_list]\n",
    "df_final_prod_config_expanded[final_signal_cols].plot(figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefc1adc-bbce-4531-a206-7ef6a8402f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_cols = [f'{ticker}_actual_position_notional' for ticker in cfg['universe']['tickers']]\n",
    "df_final_prod_config_expanded[return_cols].plot(figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afed687b-11f1-4b6a-8c5d-aad00fda821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_cols = [f'{ticker}_actual_position_notional' for ticker in ticker_list]\n",
    "df_final_prod_config_expanded[return_cols].plot(figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e232cc-e739-477d-912f-0587665b94a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_cols = [f'{ticker}_daily_pnl' for ticker in cfg['universe']['tickers']]\n",
    "df_final_prod_config[return_cols].plot(figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67d8137-30fa-47c6-aa53-e5e7b47ec991",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_cols = [f'{ticker}_daily_pnl' for ticker in ticker_list]\n",
    "df_final_prod_config_expanded[return_cols].plot(figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3b9ee5-d6b8-4e6f-89b3-e9a39835afea",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_cols = [f'{ticker}_daily_pct_returns' for ticker in ticker_list]\n",
    "df_final_prod_config_expanded[return_cols].plot(figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b0983e-828a-41a0-a2b3-7cc64a6056dc",
   "metadata": {},
   "source": [
    "## Get a list of all tradeable coins from Coinbase on any given day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "016b8c49-9d8f-46d4-9c20-738f43f62864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_to_dict(p):\n",
    "    # Pydantic v2\n",
    "    fn = getattr(p, \"model_dump\", None)\n",
    "    if callable(fn):\n",
    "        return fn(exclude_none=True)  # or fn() if you want Nones\n",
    "\n",
    "    # Pydantic v1\n",
    "    fn = getattr(p, \"dict\", None)\n",
    "    if callable(fn):\n",
    "        return fn()\n",
    "\n",
    "    # JSON fallbacks (v2 and v1 respectively)\n",
    "    fn = getattr(p, \"model_dump_json\", None)\n",
    "    if callable(fn):\n",
    "        return json.loads(p.model_dump_json())\n",
    "    fn = getattr(p, \"json\", None)\n",
    "    if callable(fn):\n",
    "        return json.loads(p.json())\n",
    "\n",
    "    # Last-resort: plain object\n",
    "    if hasattr(p, \"__dict__\"):\n",
    "        return {k: v for k, v in vars(p).items() if not k.startswith(\"_\")}\n",
    "\n",
    "    return {\"raw\": str(p)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20b2e518-44ca-44f3-bf72-d5d59d3a03a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get a snapshot of all the available coins to trade\n",
    "CANON_QUOTE = \"USD\"\n",
    "PRODUCTS_DIR = Path(\"/Users/adheerchauhan/Documents/git/trend_following/data_folder/universe/products\")\n",
    "PRODUCTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LIQUIDITY_DIR = Path(\"/Users/adheerchauhan/Documents/git/trend_following/data_folder/universe/liquidity\")\n",
    "LIQUIDITY_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ELIGIBLE_DIR = Path(\"/Users/adheerchauhan/Documents/git/trend_following/data_folder/universe/eligible_products\")\n",
    "ELIGIBLE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def coinbase_product_snapshot(client, asof=None, save=True):\n",
    "\n",
    "    asof = asof or datetime.now(timezone.utc).date().isoformat()\n",
    "    prod = client.get_products()['products']\n",
    "    rows = [product_to_dict(p) for p in prod]\n",
    "    df = pd.json_normalize(rows)\n",
    "\n",
    "    # optional: keep only columns you care about\n",
    "    reqd_cols = [\n",
    "        \"product_id\",\"base_currency_id\",\"quote_currency_id\",\"product_type\",\"status\",\n",
    "        \"trading_disabled\",\"is_disabled\",\"cancel_only\",\"limit_only\",\"post_only\",\"auction_mode\",\"view_only\",\n",
    "        \"base_increment\",\"quote_increment\",\"price_increment\",\"base_min_size\",\"quote_min_size\",\n",
    "        \"alias\",\"alias_to\",\"display_name\",\"product_venue\",\"new_at\",\"price\",\"approximate_quote_24h_volume\"\n",
    "    ]\n",
    "    df = df[reqd_cols]\n",
    "\n",
    "    # optional: coerce numerics\n",
    "    num_cols = [\"base_increment\",\"quote_increment\",\"price_increment\",\"base_min_size\",\"quote_min_size\",\n",
    "                \"price\",\"approximate_quote_24h_volume\"]\n",
    "    for col in num_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # Filter to USD spot & tradable\n",
    "    filt = (\n",
    "        (df[\"product_type\"] == \"SPOT\") &\n",
    "        (df[\"quote_currency_id\"] == CANON_QUOTE) &\n",
    "        (df[\"status\"] == \"online\") &\n",
    "        (~df[\"trading_disabled\"]) &\n",
    "        (~df[\"is_disabled\"]) &\n",
    "        (~df[\"view_only\"]) &\n",
    "        (~df[\"cancel_only\"]) &\n",
    "        (~df[\"auction_mode\"])\n",
    "    )\n",
    "    df = df[filt]\n",
    "\n",
    "    df[\"asof_date\"] = pd.to_datetime(asof).date()\n",
    "\n",
    "    if save:\n",
    "        out = PRODUCTS_DIR / f\"{asof}_prod.parquet\"\n",
    "        df.to_parquet(out, index=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6aa6646-187c-492a-825c-e5726d0cf85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def products_diff(prev_path, curr_path):\n",
    "    \n",
    "    prev = pd.read_parquet(prev_path)\n",
    "    curr = pd.read_parquet(curr_path)\n",
    "    prev_set = set(prev[\"ticker\"])\n",
    "    curr_set = set(curr[\"ticker\"])\n",
    "    adds = sorted(list(curr_set - prev_set))\n",
    "    drops = sorted(list(prev_set - curr_set))\n",
    "    \n",
    "    return {\"adds\": adds, \"drops\": drops}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dff708ab-2f77-4956-8e5e-7b6fcc5cbf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get OHLC data for each coin\n",
    "def get_coinbase_candle_data(client, product_id, start_date, end_date):\n",
    "    \"\"\"Return a daily OHLCV DataFrame indexed by date. Empty DF if no data.\"\"\"\n",
    "\n",
    "    start_date = pd.Timestamp(start_date)\n",
    "    end_date   = pd.Timestamp(end_date)\n",
    "    start_timestamp = int(pd.Timestamp(start_date).timestamp())\n",
    "    end_timestamp = int(pd.Timestamp(end_date).timestamp())\n",
    "\n",
    "    resp = client.get_candles(\n",
    "        product_id=product_id,\n",
    "        start=start_timestamp,\n",
    "        end=end_timestamp,\n",
    "        granularity='ONE_DAY',\n",
    "    )\n",
    "    candles = resp.candles or []\n",
    "\n",
    "    if not candles:\n",
    "        # return an empty frame with the expected schema\n",
    "        cols = ['low','high','open','close','volume']\n",
    "        return pd.DataFrame(columns=cols).astype({c:'float64' for c in cols})\n",
    "\n",
    "    rows = [{\n",
    "        'date':   c['start'],\n",
    "        'low':    float(c['low']),\n",
    "        'high':   float(c['high']),\n",
    "        'open':   float(c['open']),\n",
    "        'close':  float(c['close']),\n",
    "        'volume': float(c['volume']),\n",
    "    } for c in candles]\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df['date'] = pd.to_datetime(pd.to_numeric(df['date'], errors='coerce'), unit='s', utc=True).dt.date\n",
    "    return df.sort_values('date').set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69c47776-0298-442c-8dae-ed85809f2542",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if enough history is available and if the liquidity metrics meet all required thresholds\n",
    "def has_warmup_coverage(client, product_id: str, asof_date, warmup_days: int) -> bool:\n",
    "    \"\"\"\n",
    "    Return True if there is at least one daily candle on or before (asof - warmup_days),\n",
    "    using a tiny 1-day query window.\n",
    "    \"\"\"\n",
    "    # asof_date can be 'YYYY-MM-DD', date, or datetime\n",
    "    asof = pd.Timestamp(asof_date).date()\n",
    "\n",
    "    # boundary day at 00:00:00 UTC\n",
    "    start = asof - pd.Timedelta(days=warmup_days)\n",
    "    end   = start + pd.Timedelta(days=1)\n",
    "    start_timestamp = int(pd.Timestamp(start).timestamp())\n",
    "    end_timestamp = int(pd.Timestamp(end).timestamp())\n",
    "\n",
    "    resp = client.get_candles(\n",
    "        product_id=product_id,\n",
    "        start=start_timestamp,\n",
    "        end=end_timestamp,\n",
    "        granularity=\"ONE_DAY\",   # required enum value\n",
    "    )\n",
    "    candles = getattr(resp, \"candles\", []) or []\n",
    "    return bool(candles)\n",
    "\n",
    "\n",
    "def get_liquidity_metrics(client, product_id, asof_date, lookback_day_count=90):\n",
    "    \n",
    "    end_date = pd.Timestamp(asof_date).date()\n",
    "    start_date = end_date - pd.Timedelta(days=lookback_day_count)\n",
    "    df = get_coinbase_candle_data(client, product_id=product_id, start_date=start_date, end_date=end_date)\n",
    "    df['notional_usd'] = df['volume'] * df['close']\n",
    "    df['adv_90d_median'] = df['notional_usd'].rolling(90).median()\n",
    "    df['high_low_spread_bps'] = (df['high'] - df['low']) / ((df['high'] + df['low']) / 2) * 10000\n",
    "    df['high_low_spread_90d_median'] = df['high_low_spread_bps'].rolling(90).median()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f238e9a-372b-4603-a169-b05fcd0b75e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get liquidity metrics for all coins\n",
    "def get_liquidity_metrics_all_tickers_monthly(client, product_id_list, asof_date, lookback_day_count=90, warmup_days=300, save=True):\n",
    "\n",
    "    df_liquidity = pd.DataFrame(columns=['asof_date','product_id','adv_90d_median','high_low_spread_90d_median','warmup_days_available'])\n",
    "    \n",
    "    for product_id in product_id_list:\n",
    "        try:\n",
    "            df = get_liquidity_metrics(client, product_id, asof_date=asof_date, lookback_day_count=lookback_day_count)\n",
    "            row = {\n",
    "                'asof_date': asof_date,\n",
    "                'product_id': product_id,\n",
    "                'adv_90d_median': df.loc[pd.Timestamp(asof_date).date()]['adv_90d_median'],\n",
    "                'high_low_spread_90d_median': df.loc[pd.Timestamp(asof_date).date()]['high_low_spread_90d_median'],\n",
    "                'warmup_days_available': has_warmup_coverage(client, product_id=product_id, asof_date=asof_date, warmup_days=warmup_days)\n",
    "            }\n",
    "            df_liquidity.loc[df_liquidity.shape[0]] = row\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "    if save:\n",
    "        out = LIQUIDITY_DIR / f\"{asof_date}_liquidity.parquet\"\n",
    "        df_liquidity.to_parquet(out, index=False)\n",
    "\n",
    "    return df_liquidity\n",
    "\n",
    "## Get a list of all eligible coins from all the coins based on liquidity requirements\n",
    "def get_eligible_ticker_list_monthly(df, asof_date, median_adv_col='adv_90d_median', median_high_low_spread_col='high_low_spread_90d_median', \n",
    "                                     warmup_days_col='warmup_days_available', adv_quantile_threshold=0.60, high_low_quantile_threshold=0.60, save=True):\n",
    "\n",
    "    ## Get ADV Floor\n",
    "    adv_null_cond = (df[median_adv_col].notnull())\n",
    "    adv_usd_floor = np.quantile(df[adv_null_cond][median_adv_col], q=adv_quantile_threshold)\n",
    "\n",
    "    ## Get High-Low Spread Floor\n",
    "    high_low_null_cond = (df[median_high_low_spread_col].notnull())\n",
    "    high_low_spread_floor = np.quantile(df[high_low_null_cond][median_high_low_spread_col], q=high_low_quantile_threshold)\n",
    "\n",
    "    ## Exclude Stablecoins\n",
    "    exclusions = ['USDC-USD', 'DAI-USD', 'USDT-USD']\n",
    "\n",
    "    ## Create eligibility criteria\n",
    "    eligible_cond = (\n",
    "        (df[warmup_days_col]) &\n",
    "        (df[median_adv_col] >= adv_usd_floor) &\n",
    "        (df[median_high_low_spread_col] <= high_low_spread_floor) &\n",
    "        (~df['product_id'].isin(exclusions))\n",
    "    )\n",
    "\n",
    "    ## Create eligibility ticker list\n",
    "    df_eligible = df[eligible_cond].reset_index(drop=True)\n",
    "\n",
    "    if save:\n",
    "        out = ELIGIBLE_DIR / f\"{asof_date}_eligible.parquet\"\n",
    "        df_eligible.to_parquet(out, index=False)\n",
    "\n",
    "    return df_eligible, adv_usd_floor, high_low_spread_floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c754164c-ea28-48b5-8457-d39c9c6266e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time, random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---- worker: minimal jitter + tiny retry on 429, nothing else ----\n",
    "def _call_with_retry(fn, *args, **kwargs):\n",
    "    for i in range(2):  # at most 2 tries\n",
    "        try:\n",
    "            return fn(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            status = getattr(getattr(e, \"response\", None), \"status_code\", None)\n",
    "            if status == 429:\n",
    "                # quick backoff (200ms, then 400ms) + jitter\n",
    "                time.sleep(0.2 * (2**i) + random.uniform(0.0, 0.08))\n",
    "                continue\n",
    "            raise\n",
    "    # last attempt without catching\n",
    "    return fn(*args, **kwargs)\n",
    "\n",
    "def _one_product_liquidity(client, pid, asof_date, lookback_day_count):\n",
    "    asof_key = pd.Timestamp(asof_date).date()\n",
    "\n",
    "    # a hair of jitter so batch submissions don't land at the same millisecond\n",
    "    # (very small; won't slow total runtime noticeably)\n",
    "    time.sleep(random.uniform(0.0, 0.02))\n",
    "\n",
    "    metrics = _call_with_retry(\n",
    "        get_liquidity_metrics,\n",
    "        client=client, product_id=pid, asof_date=asof_key, lookback_day_count=lookback_day_count\n",
    "    )\n",
    "    if metrics is None or metrics.empty:\n",
    "        return None\n",
    "\n",
    "    if asof_key not in metrics.index:\n",
    "        metrics = metrics.loc[:asof_key]\n",
    "        if metrics.empty:\n",
    "            return None\n",
    "\n",
    "    row = metrics.iloc[-1]\n",
    "    adv = row.get(\"adv_90d_median\", np.nan)\n",
    "    hls = row.get(\"high_low_spread_90d_median\", np.nan)\n",
    "    if not np.isfinite(adv) or not np.isfinite(hls):\n",
    "        return None\n",
    "\n",
    "    return {\n",
    "        \"asof_date\": asof_key,\n",
    "        \"product_id\": pid,\n",
    "        \"adv_90d_median\": float(adv),\n",
    "        \"high_low_spread_90d_median\": float(hls),\n",
    "    }\n",
    "\n",
    "# ---- simple batched submit: keeps it fast but smooth ----\n",
    "def _batched(seq, n):\n",
    "    for i in range(0, len(seq), n):\n",
    "        yield seq[i:i+n]\n",
    "\n",
    "def get_liquidity_metrics_all_tickers_daily_fast(\n",
    "    client, product_id_list, asof_date,\n",
    "    lookback_day_count=90, \n",
    "    max_workers=12, batch_size=16, between_batches_sleep=0.10, save=True\n",
    "):\n",
    "    STABLECOINS = {'USDC-USD','DAI-USD','USDT-USD'}\n",
    "    # keep simple upfront pruning\n",
    "    pids = [p for p in product_id_list if p.endswith(\"-USD\") and p not in STABLECOINS]\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    # --- batched submission: prevents huge burst that causes 429 ---\n",
    "    for batch in _batched(pids, batch_size):\n",
    "        # small, short-lived pool per batch keeps scheduling overhead low\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as ex:\n",
    "            # Use executor.map for low overhead (faster than as_completed here)\n",
    "            args_iter = ((client, pid, asof_date, lookback_day_count) for pid in batch)\n",
    "            for res in ex.map(lambda a: _one_product_liquidity(*a), args_iter, chunksize=1):\n",
    "                if res:\n",
    "                    rows.append(res)\n",
    "\n",
    "        # tiny pause between bursts; tune 0.05â€“0.15s if you still see 429s\n",
    "        if between_batches_sleep:\n",
    "            time.sleep(between_batches_sleep)\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[\n",
    "        \"asof_date\",\"product_id\",\"adv_90d_median\",\"high_low_spread_90d_median\"\n",
    "    ])\n",
    "    # if save and len(df):\n",
    "    #     out = LIQUIDITY_DIR / f\"{pd.Timestamp(asof_date).date()}_liquidity.parquet\"\n",
    "    #     df.to_parquet(out, index=False)\n",
    "    return df\n",
    "\n",
    "## Get a list of all eligible coins from all the coins based on liquidity requirements\n",
    "def get_eligible_ticker_list_daily(df, asof_date, median_adv_col='adv_90d_median', median_high_low_spread_col='high_low_spread_90d_median', \n",
    "                                   adv_quantile_threshold=0.60, high_low_quantile_threshold=0.60, save=True):\n",
    "\n",
    "    ## Get ADV Floor\n",
    "    adv_null_cond = (df[median_adv_col].notnull())\n",
    "    adv_usd_floor = np.quantile(df[adv_null_cond][median_adv_col], q=adv_quantile_threshold)\n",
    "\n",
    "    ## Get High-Low Spread Floor\n",
    "    high_low_null_cond = (df[median_high_low_spread_col].notnull())\n",
    "    high_low_spread_floor = np.quantile(df[high_low_null_cond][median_high_low_spread_col], q=high_low_quantile_threshold)\n",
    "\n",
    "    ## Exclude Stablecoins\n",
    "    STABLECOINS = ['USDC-USD', 'DAI-USD', 'USDT-USD']\n",
    "\n",
    "    ## Create eligibility criteria\n",
    "    eligible_cond = (\n",
    "        (df[median_adv_col] >= adv_usd_floor) &\n",
    "        (df[median_high_low_spread_col] <= high_low_spread_floor) &\n",
    "        (~df['product_id'].isin(STABLECOINS))\n",
    "    )\n",
    "\n",
    "    ## Create eligibility ticker list\n",
    "    df_eligible = df[eligible_cond].reset_index(drop=True)\n",
    "\n",
    "    if save:\n",
    "        out = ELIGIBLE_DIR / f\"{asof_date}_eligible.parquet\"\n",
    "        df_eligible.to_parquet(out, index=False)\n",
    "\n",
    "    return df_eligible, adv_usd_floor, high_low_spread_floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eaed5db0-224b-4ddc-9927-9cc8ae2c1abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "asof_date = pd.Timestamp('2025-10-24').date()\n",
    "lookback_day_count = 90\n",
    "warmup_days = cfg['run']['warmup_days']\n",
    "client = cn.get_coinbase_rest_api_client(portfolio_name='Default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a686510-00b1-4200-a80d-c42068ff40d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products_t_1 = coinbase_product_snapshot(client, asof=pd.Timestamp('2025-10-23').date(), save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243e55e4-e278-4da4-849b-36ddf28aa698",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products = coinbase_product_snapshot(client, asof=asof_date, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d448e03c-5341-4b7b-8d63-407a34b2691a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b47af29-9b66-4f73-ab3e-b492b9d1cb42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "## Get the product snapshot, liquidity metrics and eligible ticker list on a monthly frequency from 2022-03-01 to 2025-07-31 \n",
    "lookback_day_count = 90\n",
    "warmup_days = 300\n",
    "adv_quantile = 0.60\n",
    "high_low_quantile = 0.60\n",
    "date_range = pd.date_range(start=pd.Timestamp('2022-03-01').date(), end=pd.Timestamp('2025-07-31').date(), freq='M')\n",
    "for date in date_range:\n",
    "    print(date)\n",
    "    df_products = coinbase_product_snapshot(client, asof=date.date(), save=True)\n",
    "    curr_product_list = df_products.product_id.unique().tolist()\n",
    "    df_liquidity_ticker = get_liquidity_metrics_all_tickers_monthly(client, product_id_list=curr_product_list, asof_date=date.date(),\n",
    "                                                                    lookback_day_count=lookback_day_count, warmup_days=warmup_days, save=True)\n",
    "    df_eligible, adv_usd_floor, high_low_spread_floor = get_eligible_ticker_list_monthly(df=df_liquidity_ticker, asof_date=date.date(), median_adv_col='adv_90d_median',\n",
    "                                                                                         median_high_low_spread_col='high_low_spread_90d_median', \n",
    "                                                                                         warmup_days_col='warmup_days_available',\n",
    "                                                                                         adv_quantile_threshold=adv_quantile, high_low_quantile_threshold=high_low_quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e66816-ae74-45be-a6c9-a039b1b109a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Get the product snapshot, liquidity metrics and eligible ticker list on a monthly frequency for one day\n",
    "lookback_day_count = 90\n",
    "warmup_days = 300\n",
    "adv_quantile = 0.60\n",
    "high_low_quantile = 0.60\n",
    "date_range = pd.date_range(start=pd.Timestamp('2022-03-01').date(), end=pd.Timestamp('2025-07-31').date(), freq='M')\n",
    "# for date in date_range:\n",
    "date = pd.Timestamp('2025-11-03')\n",
    "print(date)\n",
    "df_products = coinbase_product_snapshot(client, asof=date.date(), save=True)\n",
    "curr_product_list = df_products.product_id.unique().tolist()\n",
    "df_liquidity_ticker_fast = get_liquidity_metrics_all_tickers_daily_fast(client, product_id_list=curr_product_list, asof_date=date.date(),\n",
    "                                                                        lookback_day_count=lookback_day_count, max_workers=5, batch_size=12, between_batches_sleep=0.10, save=False)\n",
    "df_eligible_test, adv_usd_floor, high_low_spread_floor = get_eligible_ticker_list_daily(df=df_liquidity_ticker_fast, asof_date=date.date(), median_adv_col='adv_90d_median',\n",
    "                                                                                        median_high_low_spread_col='high_low_spread_90d_median', \n",
    "                                                                                        adv_quantile_threshold=adv_quantile, high_low_quantile_threshold=high_low_quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aff8e6-f592-40e3-b5d9-5ab3e25120c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_eligible_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235191e7-5021-4ff7-939f-3a3e2fb71b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eligible.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd654031-9862-4810-9f5f-77bc3ad4cfd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_liquidity_ticker_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99af8b77-2d77-4d7e-aa02-c22d3618dac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# assume cfg is already loaded from YAML as shown in your message\n",
    "\n",
    "# --- Prod Configuration (from cfg) ---\n",
    "start_date  = pd.Timestamp(cfg['run']['start_date']).date()\n",
    "end_date    = pd.Timestamp(cfg['run']['end_date']).date()\n",
    "warmup_days = int(cfg['run']['warmup_days'])\n",
    "\n",
    "# ticker_list = list(cfg['universe']['tickers'])\n",
    "ticker_list = ['BTC-USD', 'ETH-USD', 'SOL-USD', 'ADA-USD', 'AVAX-USD', 'LTC-USD', 'DOGE-USD', 'CRO-USD']\n",
    "\n",
    "# signals.moving_average\n",
    "fast_mavg        = int(cfg['signals']['moving_average']['fast_mavg'])\n",
    "slow_mavg        = int(cfg['signals']['moving_average']['slow_mavg'])\n",
    "mavg_stepsize    = int(cfg['signals']['moving_average']['mavg_stepsize'])\n",
    "mavg_z_score_window = int(cfg['signals']['moving_average']['mavg_z_score_window'])\n",
    "\n",
    "# signals.donchian\n",
    "entry_rolling_donchian_window = int(cfg['signals']['donchian']['entry_rolling_donchian_window'])\n",
    "exit_rolling_donchian_window  = int(cfg['signals']['donchian']['exit_rolling_donchian_window'])\n",
    "use_donchian_exit_gate        = bool(cfg['signals']['donchian']['use_donchian_exit_gate'])\n",
    "\n",
    "# signals.weighting\n",
    "ma_crossover_signal_weight = float(cfg['signals']['weighting']['ma_crossover_signal_weight'])\n",
    "donchian_signal_weight     = float(cfg['signals']['weighting']['donchian_signal_weight'])\n",
    "weighted_signal_ewm_window = int(cfg['signals']['weighting']['weighted_signal_ewm_window'])  # (new config but same value)\n",
    "\n",
    "# signals.filters.rolling_r2\n",
    "rolling_r2_window   = int(cfg['signals']['filters']['rolling_r2']['rolling_r2_window'])\n",
    "lower_r_sqr_limit   = float(cfg['signals']['filters']['rolling_r2']['lower_r_sqr_limit'])\n",
    "upper_r_sqr_limit   = float(cfg['signals']['filters']['rolling_r2']['upper_r_sqr_limit'])\n",
    "r2_smooth_window    = int(cfg['signals']['filters']['rolling_r2']['r2_smooth_window'])\n",
    "r2_confirm_days     = 2 #int(cfg['signals']['filters']['rolling_r2']['r2_confirm_days'])\n",
    "r2_strong_threshold = float(cfg['signals']['filters']['rolling_r2']['r2_strong_threshold'])\n",
    "\n",
    "# signals.filters.vol_of_vol\n",
    "log_std_window            = int(cfg['signals']['filters']['vol_of_vol']['log_std_window'])\n",
    "coef_of_variation_window  = int(cfg['signals']['filters']['vol_of_vol']['coef_of_variation_window'])\n",
    "vol_of_vol_z_score_window = int(cfg['signals']['filters']['vol_of_vol']['vol_of_vol_z_score_window'])\n",
    "vol_of_vol_p_min          = float(cfg['signals']['filters']['vol_of_vol']['vol_of_vol_p_min'])\n",
    "\n",
    "# signals.activation\n",
    "use_activation              = bool(cfg['signals']['activation']['use_activation'])\n",
    "tanh_activation_constant_dict = cfg['signals']['activation']['tanh_activation_constant_dict']  # likely None\n",
    "\n",
    "# data / run toggles\n",
    "moving_avg_type        = str(cfg['data']['moving_avg_type'])\n",
    "long_only              = bool(cfg['run']['long_only'])\n",
    "price_or_returns_calc  = str(cfg['data']['price_or_returns_calc'])\n",
    "\n",
    "initial_capital        = float(cfg['run']['initial_capital'])\n",
    "\n",
    "rolling_cov_window     = int(cfg['risk_and_sizing']['rolling_cov_window'])\n",
    "volatility_window      = int(cfg['risk_and_sizing']['volatility_window'])\n",
    "\n",
    "# stop loss strategy (new)\n",
    "stop_loss_strategy     = str(cfg['risk_and_sizing']['stop_loss_strategy'])\n",
    "rolling_atr_window     = int(cfg['risk_and_sizing']['rolling_atr_window'])\n",
    "atr_multiplier         = float(cfg['risk_and_sizing']['atr_multiplier'])\n",
    "highest_high_window    = int(cfg['risk_and_sizing']['highest_high_window'])\n",
    "\n",
    "# cooldown (new)\n",
    "cooldown_counter_threshold = int(cfg['execution_and_costs']['cooldown_counter_threshold'])\n",
    "\n",
    "# target vol (new value)\n",
    "annualized_target_volatility = float(cfg['risk_and_sizing']['annualized_target_volatility'])\n",
    "\n",
    "transaction_cost_est   = float(cfg['execution_and_costs']['transaction_cost_est'])\n",
    "passive_trade_rate     = float(cfg['execution_and_costs']['passive_trade_rate'])\n",
    "notional_threshold_pct = float(cfg['execution_and_costs']['notional_threshold_pct'])\n",
    "min_trade_notional_abs = float(cfg['execution_and_costs']['min_trade_notional_abs'])\n",
    "\n",
    "rolling_sharpe_window  = int(cfg['risk_and_sizing']['rolling_sharpe_window'])\n",
    "cash_buffer_percentage = float(cfg['risk_and_sizing']['cash_buffer_percentage'])\n",
    "annual_trading_days    = int(cfg['run']['annual_trading_days'])\n",
    "\n",
    "use_coinbase_data      = bool(cfg['data']['use_coinbase_data'])\n",
    "use_saved_files        = bool(cfg['data']['use_saved_files'])\n",
    "saved_file_end_date    = str(cfg['data']['saved_file_end_date'])\n",
    "\n",
    "use_specific_start_date = bool(cfg['run']['use_specific_start_date'])\n",
    "signal_start_date       = pd.Timestamp(cfg['run']['signal_start_date']).date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b95d973a-a778-4882-8e59-1a9a22b7c89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trend_donchian_signal_for_portfolio_with_rolling_r_sqr_vol_of_vol(\n",
    "        start_date, end_date, ticker_list, fast_mavg, slow_mavg, mavg_stepsize, mavg_z_score_window,\n",
    "        entry_rolling_donchian_window, exit_rolling_donchian_window, use_donchian_exit_gate,\n",
    "        ma_crossover_signal_weight, donchian_signal_weight, weighted_signal_ewm_window,\n",
    "        rolling_r2_window=30, lower_r_sqr_limit=0.2, upper_r_sqr_limit=0.8, r2_smooth_window=3, r2_confirm_days=0,\n",
    "        log_std_window=14, coef_of_variation_window=30, vol_of_vol_z_score_window=252, vol_of_vol_p_min=0.6,\n",
    "        r2_strong_threshold=0.8, use_activation=True, tanh_activation_constant_dict=None, moving_avg_type='exponential',\n",
    "        long_only=False, price_or_returns_calc='price', use_coinbase_data=True, use_saved_files=True,\n",
    "        saved_file_end_date='2025-07-31'):\n",
    "\n",
    "    ## Generate trend signal for all tickers\n",
    "    trend_list = []\n",
    "    date_list = cn.coinbase_start_date_by_ticker_dict\n",
    "\n",
    "    for ticker in ticker_list:\n",
    "        # Create Column Names\n",
    "        trend_continuous_signal_col = f'{ticker}_mavg_ribbon_slope'\n",
    "        trend_continuous_signal_rank_col = f'{ticker}_mavg_ribbon_rank'\n",
    "        final_signal_col = f'{ticker}_final_signal'\n",
    "        close_price_col = f'{ticker}_close'\n",
    "        open_price_col = f'{ticker}_open'\n",
    "        rolling_r2_col = f'{ticker}_rolling_r_sqr'\n",
    "        final_weighted_additive_signal_col = f'{ticker}_final_weighted_additive_signal'\n",
    "\n",
    "        # if pd.to_datetime(date_list[ticker]).date() > start_date:\n",
    "        #     run_date = pd.to_datetime(date_list[ticker]).date()\n",
    "        # else:\n",
    "        #     run_date = start_date\n",
    "\n",
    "        df_trend = tf.generate_trend_signal_with_donchian_channel_continuous_with_rolling_r_sqr_vol_of_vol(\n",
    "            start_date=start_date, end_date=end_date, ticker=ticker, fast_mavg=fast_mavg, slow_mavg=slow_mavg,\n",
    "            mavg_stepsize=mavg_stepsize, mavg_z_score_window=mavg_z_score_window,\n",
    "            entry_rolling_donchian_window=entry_rolling_donchian_window,\n",
    "            exit_rolling_donchian_window=exit_rolling_donchian_window, use_donchian_exit_gate=use_donchian_exit_gate,\n",
    "            ma_crossover_signal_weight=ma_crossover_signal_weight, donchian_signal_weight=donchian_signal_weight,\n",
    "            weighted_signal_ewm_window=weighted_signal_ewm_window,\n",
    "            rolling_r2_window=rolling_r2_window, lower_r_sqr_limit=lower_r_sqr_limit,\n",
    "            upper_r_sqr_limit=upper_r_sqr_limit, r2_smooth_window=r2_smooth_window, r2_confirm_days=r2_confirm_days,\n",
    "            log_std_window=log_std_window, coef_of_variation_window=coef_of_variation_window,\n",
    "            vol_of_vol_z_score_window=vol_of_vol_z_score_window, vol_of_vol_p_min=vol_of_vol_p_min,\n",
    "            r2_strong_threshold=r2_strong_threshold,\n",
    "            use_activation=use_activation, tanh_activation_constant_dict=tanh_activation_constant_dict,\n",
    "            moving_avg_type=moving_avg_type, price_or_returns_calc=price_or_returns_calc, long_only=long_only,\n",
    "            use_coinbase_data=use_coinbase_data, use_saved_files=use_saved_files,\n",
    "            saved_file_end_date=saved_file_end_date)\n",
    "\n",
    "        trend_cols = [close_price_col, open_price_col, trend_continuous_signal_col, trend_continuous_signal_rank_col,\n",
    "                      final_weighted_additive_signal_col,\n",
    "                      rolling_r2_col, final_signal_col]\n",
    "        df_trend = df_trend[trend_cols]\n",
    "        trend_list.append(df_trend)\n",
    "\n",
    "    df_trend = pd.concat(trend_list, axis=1)\n",
    "\n",
    "    return df_trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a0e30e-5743-4341-808f-8b7fde1e8484",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_end_dates = pd.date_range(start=pd.Timestamp('2022-03-31').date(), end=pd.Timestamp('2022-12-31').date(), freq='M')\n",
    "eligible_ticker_liquidity_dict = {}\n",
    "for month_end in month_end_dates:\n",
    "    print(month_end)\n",
    "    out = ELIGIBLE_DIR / f\"{pd.Timestamp(month_end).date()}_eligible.parquet\"\n",
    "    df_eligible = pd.read_parquet(out)\n",
    "    eligible_ticker_list = df_eligible.product_id.unique().tolist()\n",
    "    eligible_ticker_liquidity_dict[pd.Timestamp(month_end).date()] = eligible_ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff27f35-7c10-4f11-bcdf-d88c1eabf73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in eligible_ticker_liquidity_dict.items():\n",
    "    print(k, len(v), sorted(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b25529-5b6d-47f1-8049-ba24cb5500a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get Eligible Ticker List based on Liquidity Metrics and Trend Following Signal at Month-End\n",
    "month_end_dates = pd.date_range(start=pd.Timestamp('2022-03-31').date(), end=pd.Timestamp('2022-12-31').date(), freq='M')\n",
    "eligible_ticker_dict = {}\n",
    "for month_end in month_end_dates:\n",
    "    print(month_end)\n",
    "    out = ELIGIBLE_DIR / f\"{pd.Timestamp(month_end).date()}_eligible.parquet\"\n",
    "    df_eligible = pd.read_parquet(out)\n",
    "    eligible_ticker_list = df_eligible.product_id.unique().tolist()\n",
    "    df_trend_eligible = get_trend_donchian_signal_for_portfolio_with_rolling_r_sqr_vol_of_vol(\n",
    "        start_date=pd.Timestamp(month_end).date()-pd.Timedelta(days=warmup_days), end_date=pd.Timestamp(month_end).date() + pd.Timedelta(days=10), ticker_list=eligible_ticker_list, fast_mavg=fast_mavg, slow_mavg=slow_mavg,\n",
    "        mavg_stepsize=mavg_stepsize, mavg_z_score_window=mavg_z_score_window,\n",
    "        entry_rolling_donchian_window=entry_rolling_donchian_window,\n",
    "        exit_rolling_donchian_window=exit_rolling_donchian_window, use_donchian_exit_gate=use_donchian_exit_gate,\n",
    "        ma_crossover_signal_weight=ma_crossover_signal_weight, donchian_signal_weight=donchian_signal_weight,\n",
    "        weighted_signal_ewm_window=weighted_signal_ewm_window, rolling_r2_window=rolling_r2_window,\n",
    "        lower_r_sqr_limit=lower_r_sqr_limit, upper_r_sqr_limit=upper_r_sqr_limit, r2_smooth_window=r2_smooth_window,\n",
    "        r2_confirm_days=r2_confirm_days, log_std_window=log_std_window, coef_of_variation_window=coef_of_variation_window,\n",
    "        vol_of_vol_z_score_window=vol_of_vol_z_score_window, vol_of_vol_p_min=vol_of_vol_p_min,\n",
    "        r2_strong_threshold=r2_strong_threshold, use_activation=use_activation,\n",
    "        tanh_activation_constant_dict=tanh_activation_constant_dict, moving_avg_type=moving_avg_type,\n",
    "        long_only=long_only, price_or_returns_calc=price_or_returns_calc, use_coinbase_data=use_coinbase_data,\n",
    "        use_saved_files=False, saved_file_end_date=saved_file_end_date)\n",
    "    \n",
    "    date_cond = (df_trend_eligible.index == pd.Timestamp(month_end))\n",
    "    final_signal_cols = [f'{ticker}_final_signal' for ticker in eligible_ticker_list]\n",
    "    df_raw_eligible_list = df_trend_eligible[date_cond][final_signal_cols].T.reset_index()\n",
    "    df_raw_eligible_list.columns = ['ticker', 'final_signal']\n",
    "    df_raw_eligible_list = df_raw_eligible_list.sort_values('final_signal', ascending=False)\n",
    "    min_strength = np.quantile(df_raw_eligible_list['final_signal'], q=0.8)\n",
    "    min_strength_cond = (df_raw_eligible_list['final_signal'] > min_strength)\n",
    "    df_raw_eligible_list = df_raw_eligible_list[min_strength_cond]\n",
    "    df_raw_eligible_list[\"ticker\"] = df_raw_eligible_list[\"ticker\"].str.replace(r\"_final_signal$\", \"\", regex=True)\n",
    "    final_eligible_list = df_raw_eligible_list.ticker.tolist()\n",
    "    eligible_ticker_dict[pd.Timestamp(month_end).date()] = final_eligible_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a09a2ea-b139-4774-ad7a-aa6eb55696ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in eligible_ticker_dict.items():\n",
    "    print(key, sorted(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "98c40c75-0168-476e-8db3-75c264989877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clamp_to_per_asset_caps(desired_delta: pd.Series,\n",
    "                            current_notional_prev: pd.Series,\n",
    "                            total_portfolio_value_upper_limit: float,\n",
    "                            per_asset_weight_cap: float,\n",
    "                            per_asset_notional_cap: float | None) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Enforce per-asset caps by limiting *post-trade* notional to:\n",
    "      min(weight_cap * TPV_upper, absolute_cap if given).\n",
    "    Only constrains the *upside* (you can always reduce).\n",
    "    \"\"\"\n",
    "    if len(desired_delta) == 0:\n",
    "        return desired_delta\n",
    "\n",
    "    # cap each asset's *final* notional (current + delta)\n",
    "    weight_cap_notional = per_asset_weight_cap * float(total_portfolio_value_upper_limit)\n",
    "    cap_notional = weight_cap_notional if per_asset_notional_cap is None else min(weight_cap_notional, per_asset_notional_cap)\n",
    "\n",
    "    # current long notionals; if you allow shorting, drop the clip\n",
    "    curr = current_notional_prev.fillna(0.0).clip(lower=0.0)\n",
    "    target_after = (curr + desired_delta).fillna(0.0)\n",
    "\n",
    "    # where target_after exceeds cap, cut the delta so final == cap\n",
    "    over = target_after > cap_notional\n",
    "    if over.any():\n",
    "        desired_delta.loc[over] = cap_notional - curr.loc[over]\n",
    "\n",
    "    return desired_delta\n",
    "\n",
    "\n",
    "def enforce_freeze_on_notional_deltas(desired_delta: pd.Series,\n",
    "                                      current_notional_prev: pd.Series,\n",
    "                                      frozen_tickers: list[str] | None,\n",
    "                                      allow_adds_on_frozen: bool) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Freeze policy:\n",
    "      - If allow_adds_on_frozen=True: do nothing (you may increase frozen tickers).\n",
    "      - If False: you may *not* increase frozen tickers; only flat or decrease.\n",
    "    \"\"\"\n",
    "    if not frozen_tickers:\n",
    "        return desired_delta\n",
    "\n",
    "    if allow_adds_on_frozen:\n",
    "        return desired_delta\n",
    "\n",
    "    # block positive deltas for frozen tickers\n",
    "    fz = pd.Index(frozen_tickers).intersection(desired_delta.index)\n",
    "    pos = desired_delta.loc[fz] > 0\n",
    "    if pos.any():\n",
    "        desired_delta.loc[fz[pos]] = 0.0\n",
    "    return desired_delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "02672f90-e0d0-4845-9707-3b70e4895a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_today_signals(df: pd.DataFrame, date, tickers, suffix: str) -> pd.Series:\n",
    "    \"\"\"Return a Series index=ticker, value=today's signal (NaN -> -inf for ranking).\"\"\"\n",
    "    cols = [f\"{t}{suffix}\" for t in tickers]\n",
    "    row = df.loc[date, cols] if date in df.index else pd.Series([np.nan]*len(cols), index=cols)\n",
    "    s = row.copy()\n",
    "    s.index = [c[:-len(suffix)] for c in s.index]\n",
    "    return s.astype(float).fillna(-np.inf)\n",
    "\n",
    "def _enforce_daily_position_budget(\n",
    "    desired_delta: pd.Series,\n",
    "    current_notional_prev: pd.Series,\n",
    "    today_signals: pd.Series,\n",
    "    max_positions: int | None,\n",
    "    max_new_per_day: int | None,\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Allows exits/reductions as-is. Among *entries* (delta>0 on names not currently held),\n",
    "    keep only top-K by signal, where K = min(max_new_per_day, max_positions - held_count).\n",
    "    \"\"\"\n",
    "    ## Make no changes if there is no set max positions or new max positions per day and execute desired trades\n",
    "    if max_positions is None and max_new_per_day is None:\n",
    "        return desired_delta\n",
    "\n",
    "    ## Get the total number of held positions in the portfolio and the number of desired new entrants\n",
    "    curr = current_notional_prev.fillna(0.0)\n",
    "    held = curr > 0\n",
    "    entrants = (desired_delta.fillna(0.0) > 0) & (~held)\n",
    "\n",
    "    ## If there are no new entrants, do nothing and execute the desired trades\n",
    "    if not entrants.any():\n",
    "        return desired_delta\n",
    "\n",
    "    ## If max number of positions is set, get the number of open slots in the portfolio\n",
    "    held_cnt = int(held.sum())\n",
    "    slots = None\n",
    "    if max_positions is not None:\n",
    "        slots = max(max_positions - held_cnt, 0)\n",
    "    \n",
    "    ## If there is a max number of new positions set, modify the number of slots based on the max_new_per_day param\n",
    "    if max_new_per_day is not None:\n",
    "        slots = max_new_per_day if slots is None else min(slots, max_new_per_day)\n",
    "\n",
    "    ## If the max number of positions is not exceeded after accounting for the entrants, execute desired trades\n",
    "    if slots is None or slots >= int(entrants.sum()):\n",
    "        return desired_delta  # nothing to trim\n",
    "\n",
    "    ## If the number of entrants is greater than the number of available slots, use signal strength to \n",
    "    ## rank the new entrants and pick the top few that fill up the number of open slots\n",
    "    tf_signal = today_signals.reindex(desired_delta.index).fillna(-np.inf)\n",
    "    tf_signal_entrants = tf_signal[entrants].sort_values(ascending=False)\n",
    "    allow = set(tf_signal_entrants.index[:slots])\n",
    "\n",
    "    ## Based on the signal strength, block the entrants that are not chosen\n",
    "    block = [t for t in tf_signal_entrants.index if t not in allow]\n",
    "    if block:\n",
    "        desired_delta.loc[block] = 0.0\n",
    "        \n",
    "    return desired_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1fbfde05-9f3c-47a1-ad0e-fd58aeb2347c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_volatility_daily_portfolio_positions_expanded_universe(df, ticker_list, initial_capital, rolling_cov_window,\n",
    "                                                                      stop_loss_strategy, rolling_atr_window, atr_multiplier,\n",
    "                                                                      highest_high_window, cash_buffer_percentage,\n",
    "                                                                      annualized_target_volatility, transaction_cost_est=0.001,\n",
    "                                                                      passive_trade_rate=0.05, notional_threshold_pct=0.02,\n",
    "                                                                      min_trade_notional_abs=10, cooldown_counter_threshold=3,\n",
    "                                                                      annual_trading_days=365, use_specific_start_date=False,\n",
    "                                                                      signal_start_date=None, start_date=None, previous_month_open_positions_df=None,\n",
    "                                                                      frozen_ticker_list=None,\n",
    "                                                                      per_asset_weight_cap=0.25,                # e.g., max 25% of PV upper limit per asset\n",
    "                                                                      per_asset_notional_cap=None,              # e.g., 5000. If None, ignore absolute cap.\n",
    "                                                                      allow_adds_on_frozen=True,                # True = you can scale UP frozen tickers\n",
    "                                                                      eligibility_by_date=None,                 # dict[date]->set([...]) of liquidity-eligible tickers\n",
    "                                                                      force_exit_if_ineligible=True,            # True = immediate full exit if ineligible today\n",
    "                                                                      max_positions = None,                     # e.g., 12\n",
    "                                                                      max_new_per_day = None,                   # e.g., 3\n",
    "                                                                      signal_col_suffix = \"_final_signal\"       # so we can rank entries cleanly\n",
    "                                                                     ):\n",
    "\n",
    "    # Ensure DatetimeIndex (tz-naive), normalized, sorted\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        df.index = pd.to_datetime(df.index, utc=True).tz_localize(None)\n",
    "    elif df.index.tz is not None:\n",
    "        df.index = df.index.tz_localize(None)\n",
    "    df.index = df.index.normalize()\n",
    "    df.sort_index(inplace=True)\n",
    "\n",
    "    ## Calculate the covariance matrix for tickers in the portfolio\n",
    "    returns_cols = [f'{ticker}_t_1_close_pct_returns' for ticker in ticker_list]\n",
    "    cov_matrix = df[returns_cols].rolling(rolling_cov_window).cov(pairwise=True).dropna()\n",
    "\n",
    "    ## Delete rows prior to the first available date of the covariance matrix\n",
    "    cov_matrix_start_date = cov_matrix.index[0][0]\n",
    "    df = df[df.index >= cov_matrix_start_date]\n",
    "\n",
    "    ## Derive the Daily Target Portfolio Volatility\n",
    "    daily_target_volatility = annualized_target_volatility / np.sqrt(annual_trading_days)\n",
    "\n",
    "    ## Reorder dataframe columns\n",
    "    for ticker in ticker_list:\n",
    "        df[f'{ticker}_new_position_size'] = 0.0\n",
    "        df[f'{ticker}_new_position_notional'] = 0.0\n",
    "        df[f'{ticker}_open_position_size'] = 0.0\n",
    "        df[f'{ticker}_open_position_notional'] = 0.0\n",
    "        df[f'{ticker}_actual_position_size'] = 0.0\n",
    "        df[f'{ticker}_actual_position_notional'] = 0.0\n",
    "        df[f'{ticker}_short_sale_proceeds'] = 0.0\n",
    "        df[f'{ticker}_new_position_entry_exit_price'] = 0.0\n",
    "        df[f'{ticker}_target_vol_normalized_weight'] = 0.0\n",
    "        df[f'{ticker}_target_notional'] = 0.0\n",
    "        df[f'{ticker}_target_size'] = 0.0\n",
    "        df[f'{ticker}_stop_loss'] = 0.0\n",
    "        df[f'{ticker}_stopout_flag'] = False\n",
    "        df[f'{ticker}_cooldown_counter'] = 0.0\n",
    "        df[f'{ticker}_event'] = np.nan\n",
    "    ord_cols = size_bin.reorder_columns_by_ticker(df.columns, ticker_list)\n",
    "    df = df[ord_cols]\n",
    "\n",
    "    ## Portfolio Level Cash and Positions are all set to 0\n",
    "    df['daily_portfolio_volatility'] = 0.0\n",
    "    df['available_cash'] = 0.0\n",
    "    df['count_of_positions'] = 0.0\n",
    "    df['total_actual_position_notional'] = 0.0\n",
    "    df['total_target_notional'] = 0.0\n",
    "    df['total_portfolio_value'] = 0.0\n",
    "    df['total_portfolio_value_upper_limit'] = 0.0\n",
    "    df['target_vol_scaling_factor'] = 1.0\n",
    "    df['cash_scaling_factor'] = 1.0\n",
    "    df['final_scaling_factor'] = 1.0\n",
    "    df['cash_shrink_factor'] = 1.0\n",
    "\n",
    "    # ## Cash and the Total Portfolio Value on Day 1 is the initial capital for the strategy\n",
    "    # if use_specific_start_date and signal_start_date is not None:\n",
    "    #     # start_index_position = df.index.get_loc(signal_start_date)\n",
    "    #     key = pd.Timestamp(signal_start_date).normalize()\n",
    "    #     start_index_position = df.index.get_loc(key)\n",
    "    # else:\n",
    "    #     start_index_position = 0\n",
    "\n",
    "    # --- pick the desired logical start date for THIS run ---\n",
    "    if use_specific_start_date and signal_start_date is not None:\n",
    "        logical_start = pd.Timestamp(signal_start_date).normalize()   # only for first month\n",
    "    elif start_date is not None:\n",
    "        logical_start = pd.Timestamp(start_date).normalize()          # monthâ€™s first day\n",
    "    else:\n",
    "        logical_start = df.index[0]                                   # fallback\n",
    "    \n",
    "    # --- align to available index after the cov trimming you did above ---\n",
    "    # df already trimmed by cov_matrix_start_date; its first index may be > logical_start\n",
    "    pos = df.index.searchsorted(logical_start, side=\"left\")\n",
    "    start_index_position = int(min(pos, len(df.index)-1))\n",
    "\n",
    "    ## TODO: ADD PREVIOUS MONTH OPEN POSITIONS, AVAILABLE CASH AND TOTAL PORTFOLIO VALUE HERE\n",
    "    if previous_month_open_positions_df is not None:\n",
    "        df.iloc[start_index_position, df.columns.get_loc('available_cash')]        = previous_month_open_positions_df['available_cash'].iloc[0]\n",
    "        df.iloc[start_index_position, df.columns.get_loc('total_portfolio_value')] = previous_month_open_positions_df['total_portfolio_value'].iloc[0]\n",
    "        prev_month_open_ticker_list = [col.split('_')[0] for col in previous_month_open_positions_df.columns if '_actual_position_notional' in col]\n",
    "        for ticker in prev_month_open_ticker_list:\n",
    "            df.iloc[start_index_position, df.columns.get_loc(f'{ticker}_actual_position_notional')] = previous_month_open_positions_df[f'{ticker}_actual_position_notional'].iloc[0]\n",
    "            df.iloc[start_index_position, df.columns.get_loc(f'{ticker}_actual_position_size')]     = previous_month_open_positions_df[f'{ticker}_actual_position_size'].iloc[0]\n",
    "    else:\n",
    "        print('Previous Month End Not Available')\n",
    "        df.iloc[start_index_position, df.columns.get_loc('available_cash')]        = initial_capital\n",
    "        df.iloc[start_index_position, df.columns.get_loc('total_portfolio_value')] = initial_capital\n",
    "\n",
    "    ## Identify Daily Positions starting from day 2\n",
    "    for date in df.index[start_index_position + 1:]:\n",
    "        previous_date = df.index[df.index.get_loc(date) - 1]\n",
    "\n",
    "        ## Start the day with the available cash from yesterday\n",
    "        df.loc[date, 'available_cash'] = df.loc[previous_date, 'available_cash']\n",
    "\n",
    "        ## Roll Portfolio Value from the Previous Day\n",
    "        total_portfolio_value = df.loc[previous_date, 'total_portfolio_value']\n",
    "        df.loc[date, 'total_portfolio_value'] = total_portfolio_value\n",
    "\n",
    "        ## Update Total Portfolio Value Upper Limit based on the Total Portfolio Value\n",
    "        total_portfolio_value_upper_limit = (df.loc[date, 'total_portfolio_value'] *\n",
    "                                             (1 - cash_buffer_percentage))\n",
    "        df.loc[date, 'total_portfolio_value_upper_limit'] = total_portfolio_value_upper_limit\n",
    "\n",
    "        ## Calculate the target notional by ticker\n",
    "        df = size_cont.get_target_volatility_position_sizing(df, cov_matrix, date, ticker_list, daily_target_volatility,\n",
    "                                                             total_portfolio_value_upper_limit)\n",
    "\n",
    "        ## Adjust Positions for Cash Available\n",
    "        desired_positions, cash_shrink_factor = size_cont.get_cash_adjusted_desired_positions(\n",
    "            df, date, previous_date, ticker_list, cash_buffer_percentage, transaction_cost_est, passive_trade_rate,\n",
    "            total_portfolio_value, notional_threshold_pct, min_trade_notional_abs)\n",
    "\n",
    "        ## Build current notional *from previous_date* for the union ticker_list\n",
    "        current_notional_prev = df.loc[previous_date, [f\"{t}_actual_position_notional\" for t in ticker_list]]\n",
    "        current_notional_prev.index = [c.replace(\"_actual_position_notional\",\"\") for c in current_notional_prev.index]\n",
    "\n",
    "        # Convert your desired_positions dict to a Series keyed by ticker -> notional delta\n",
    "        desired_delta = pd.Series(\n",
    "            {t: desired_positions[t]['new_trade_notional'] for t in desired_positions},\n",
    "            dtype=float\n",
    "        ).reindex(current_notional_prev.index).fillna(0.0)\n",
    "\n",
    "        ## NEW (3): daily liquidity eligibility -> hard exit\n",
    "        if force_exit_if_ineligible and (eligibility_by_date is not None):\n",
    "            ## These include all coins that are in today's ticker list and are eligible\n",
    "            ## This returns the set of common elements between eligibility_by_date and ticker_list\n",
    "            today_set = set(eligibility_by_date.get(pd.Timestamp(date).date(), ticker_list))\n",
    "            drops = [t for t in ticker_list if t not in today_set and float(current_notional_prev.get(t, 0.0)) != 0.0]\n",
    "            if drops:\n",
    "                # Full flatten: set delta = -current_notional\n",
    "                # (If you want a â€œreduce-onlyâ€ when negative PnL, this is where you'd do it; here we just flatten.)\n",
    "                desired_delta.loc[drops] = -current_notional_prev.loc[drops].astype(float)\n",
    "                # optional: mark events (per-ticker columns already exist)\n",
    "                for t in drops:\n",
    "                    df.loc[date, f'{t}_event'] = 'Liquidity Exit'\n",
    "    \n",
    "                # Also block *new* entries for ineligible tickers\n",
    "                blocks = [t for t in ticker_list if t not in today_set and float(current_notional_prev.get(t, 0.0)) == 0.0]\n",
    "                if blocks:\n",
    "                    desired_delta.loc[blocks] = 0.0\n",
    "        \n",
    "        ## NEW (2): freeze policy now *allows* adds if you wish\n",
    "        desired_delta = enforce_freeze_on_notional_deltas(\n",
    "            desired_delta, current_notional_prev,\n",
    "            frozen_tickers=frozen_ticker_list,\n",
    "            allow_adds_on_frozen=allow_adds_on_frozen\n",
    "        )\n",
    "\n",
    "        ## NEW (1): apply per-asset caps to post-trade notionals\n",
    "        desired_delta = clamp_to_per_asset_caps(\n",
    "            desired_delta=desired_delta,\n",
    "            current_notional_prev=current_notional_prev,\n",
    "            total_portfolio_value_upper_limit=total_portfolio_value_upper_limit,\n",
    "            per_asset_weight_cap=per_asset_weight_cap,\n",
    "            per_asset_notional_cap=per_asset_notional_cap\n",
    "        )\n",
    "\n",
    "        # ---- NEW: Daily position budget (entries only) ----\n",
    "        today_signals = _get_today_signals(df, date, ticker_list, signal_col_suffix)\n",
    "        desired_delta = _enforce_daily_position_budget(\n",
    "            desired_delta=desired_delta,\n",
    "            current_notional_prev=current_notional_prev,\n",
    "            today_signals=today_signals,\n",
    "            max_positions=max_positions,\n",
    "            max_new_per_day=max_new_per_day\n",
    "        )\n",
    "        \n",
    "        ## Write back to your dict structure (if your downstream expects the nested dict)\n",
    "        for t in desired_positions:\n",
    "            desired_positions[t]['new_trade_notional'] = float(desired_delta.get(t, 0.0))\n",
    "\n",
    "        ## Get the daily positions\n",
    "        df = size_cont.get_daily_positions_and_portfolio_cash(\n",
    "            df, date, previous_date, desired_positions, cash_shrink_factor, ticker_list,\n",
    "            stop_loss_strategy, rolling_atr_window, atr_multiplier, highest_high_window,\n",
    "            transaction_cost_est, passive_trade_rate, cooldown_counter_threshold)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b095e220-29f4-49f4-a4ab-8a6f4f7d0cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prune_usd_products(df_products):\n",
    "    cols = set(df_products.columns)\n",
    "    filt = (df_products[\"quote_currency\"] == \"USD\") if \"quote_currency\" in cols else True\n",
    "    if \"status\" in cols:           filt &= (df_products[\"status\"] == \"online\")\n",
    "    if \"trading_disabled\" in cols: filt &= (~df_products[\"trading_disabled\"])\n",
    "    if \"cancel_only\" in cols:      filt &= (~df_products[\"cancel_only\"])\n",
    "    if \"limit_only\" in cols:       filt &= (~df_products[\"limit_only\"])\n",
    "    if \"post_only\" in cols:        filt &= (~df_products[\"post_only\"])\n",
    "    if \"auction_mode\" in cols:     filt &= (~df_products[\"auction_mode\"])\n",
    "    df = df_products.loc[filt].copy()\n",
    "    stables = {\"USDC-USD\",\"USDT-USD\",\"DAI-USD\"}\n",
    "    return [p for p in df[\"product_id\"].unique().tolist() if p.endswith(\"-USD\") and p not in stables]\n",
    "\n",
    "def build_eligibility_by_date_for_month(\n",
    "    client,\n",
    "    month_start_date, month_end_date,\n",
    "    lookback_day_count=90,          # your current default\n",
    "    adv_quantile=0.60, high_low_quantile=0.60,\n",
    "    product_list=None,\n",
    "    max_workers=8, batch_size=16, between_batches_sleep=0.10\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns dict[date -> set(product_id)] for every calendar day in [month_start_date, month_end_date].\n",
    "    \"\"\"\n",
    "    ms = pd.Timestamp(month_start_date).date()\n",
    "    me = pd.Timestamp(month_end_date).date()\n",
    "\n",
    "    if product_list is None:\n",
    "        # 1) snapshot once at month-start and prune\n",
    "        df_products = coinbase_product_snapshot(client, asof=ms, save=True)\n",
    "        curr_product_list = _prune_usd_products(df_products)\n",
    "    else:\n",
    "        curr_product_list = product_list\n",
    "\n",
    "    elig_by_date = {}\n",
    "\n",
    "    # 2) daily scan across the month using the same pid list\n",
    "    for d in pd.date_range(ms, me, freq=\"D\").date:\n",
    "        print(d)\n",
    "        df_liq = get_liquidity_metrics_all_tickers_daily_fast(\n",
    "            client, product_id_list=curr_product_list, asof_date=d,\n",
    "            lookback_day_count=lookback_day_count,\n",
    "            max_workers=max_workers, batch_size=batch_size,\n",
    "            between_batches_sleep=between_batches_sleep, save=False\n",
    "        )\n",
    "        # compute daily eligibility thresholds and list\n",
    "        df_eligible, adv_floor, spread_floor = get_eligible_ticker_list_daily(\n",
    "            df=df_liq, asof_date=d,\n",
    "            median_adv_col='adv_90d_median',\n",
    "            median_high_low_spread_col='high_low_spread_90d_median',\n",
    "            adv_quantile_threshold=adv_quantile,\n",
    "            high_low_quantile_threshold=high_low_quantile,\n",
    "            save=False\n",
    "        )\n",
    "        elig_by_date[d] = set(df_eligible[\"product_id\"].tolist())\n",
    "\n",
    "    return elig_by_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446b781f-0aa8-4d3e-94d0-79034ed0778a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get Final Ticker List Based on Signal Strength on Last Month End Date!!\n",
      "2022-04-01 2022-04-30 ['BTC-USD', 'ETH-USD', 'ZEC-USD', 'DOGE-USD', 'LINK-USD', 'ADA-USD', 'LTC-USD', 'XLM-USD', 'BCH-USD', 'AAVE-USD', 'UNI-USD', 'ICP-USD', 'FIL-USD', 'ETC-USD', 'ALGO-USD', 'MANA-USD', 'COMP-USD', 'MKR-USD', 'ANKR-USD', 'YFI-USD', 'EOS-USD', 'XTZ-USD']\n",
      "Is the first month flag set: True!!\n",
      "Check if there are any open positions from prior month!!\n",
      "No Open Positions at Prior Month-end!!\n",
      "Create Final Ticker List and Frozen Ticker List!!\n",
      "Final Ticker List for Current Month: ['BTC-USD', 'ETH-USD', 'ZEC-USD', 'DOGE-USD', 'LINK-USD', 'ADA-USD', 'LTC-USD', 'XLM-USD', 'BCH-USD', 'AAVE-USD', 'UNI-USD', 'ICP-USD', 'FIL-USD', 'ETC-USD', 'ALGO-USD', 'MANA-USD', 'COMP-USD', 'MKR-USD', 'ANKR-USD', 'YFI-USD', 'EOS-USD', 'XTZ-USD']\n",
      "Pull all eligible tickers based on Liquidity Metrics for every date in the current month!!\n",
      "2022-04-01\n",
      "2022-04-02\n",
      "2022-04-03\n",
      "2022-04-04\n",
      "2022-04-05\n",
      "2022-04-06\n",
      "2022-04-07\n",
      "2022-04-08\n",
      "2022-04-09\n",
      "2022-04-10\n",
      "2022-04-11\n",
      "2022-04-12\n",
      "2022-04-13\n",
      "2022-04-14\n",
      "2022-04-15\n",
      "2022-04-16\n",
      "2022-04-17\n",
      "2022-04-18\n",
      "2022-04-19\n",
      "2022-04-20\n",
      "2022-04-21\n",
      "2022-04-22\n",
      "2022-04-23\n",
      "2022-04-24\n",
      "2022-04-25\n",
      "2022-04-26\n",
      "2022-04-27\n",
      "2022-04-28\n",
      "2022-04-29\n",
      "2022-04-30\n",
      "Generating Moving Average Ribbon Signal!!\n",
      "Generating Volatility Adjusted Trend Signal!!\n",
      "Getting Average True Range for Stop Loss Calculation!!\n",
      "BTC-USD\n",
      "ETH-USD\n",
      "ZEC-USD\n",
      "DOGE-USD\n",
      "LINK-USD\n",
      "ADA-USD\n",
      "LTC-USD\n",
      "XLM-USD\n",
      "BCH-USD\n",
      "AAVE-USD\n",
      "UNI-USD\n",
      "ICP-USD\n",
      "FIL-USD\n",
      "ETC-USD\n",
      "ALGO-USD\n",
      "MANA-USD\n",
      "COMP-USD\n",
      "MKR-USD\n",
      "ANKR-USD\n",
      "YFI-USD\n",
      "EOS-USD\n",
      "XTZ-USD\n",
      "Calculating Volatility Targeted Position Size and Cash Management!!\n",
      "Previous Month End Not Available\n",
      "Get Final Ticker List Based on Signal Strength on Last Month End Date!!\n",
      "2022-05-01 2022-05-31 ['BTC-USD', 'ETH-USD', 'SOL-USD', 'DOGE-USD', 'LINK-USD', 'ADA-USD', 'LTC-USD', 'XLM-USD', 'BCH-USD', 'AAVE-USD', 'CRV-USD', 'DOT-USD', 'ICP-USD', 'UNI-USD', 'ATOM-USD', 'FIL-USD', 'ETC-USD', 'ALGO-USD', 'QNT-USD', 'SUSHI-USD', 'AMP-USD', 'MANA-USD', 'MKR-USD', 'COMP-USD', 'YFI-USD', 'XTZ-USD', 'ANKR-USD', 'EOS-USD']\n",
      "Is the first month flag set: False!!\n",
      "Check if there are any open positions from prior month!!\n",
      "Tickers with Open Positions at Prior Month-end: []\n",
      "Create Final Ticker List and Frozen Ticker List!!\n",
      "Final Ticker List for Current Month: ['BTC-USD', 'ETH-USD', 'SOL-USD', 'DOGE-USD', 'LINK-USD', 'ADA-USD', 'LTC-USD', 'XLM-USD', 'BCH-USD', 'AAVE-USD', 'CRV-USD', 'DOT-USD', 'ICP-USD', 'UNI-USD', 'ATOM-USD', 'FIL-USD', 'ETC-USD', 'ALGO-USD', 'QNT-USD', 'SUSHI-USD', 'AMP-USD', 'MANA-USD', 'MKR-USD', 'COMP-USD', 'YFI-USD', 'XTZ-USD', 'ANKR-USD', 'EOS-USD']\n",
      "Pull all eligible tickers based on Liquidity Metrics for every date in the current month!!\n",
      "2022-05-01\n",
      "2022-05-02\n",
      "2022-05-03\n",
      "2022-05-04\n",
      "2022-05-05\n",
      "2022-05-06\n",
      "2022-05-07\n",
      "2022-05-08\n",
      "2022-05-09\n",
      "2022-05-10\n",
      "2022-05-11\n",
      "2022-05-12\n",
      "2022-05-13\n",
      "2022-05-14\n",
      "2022-05-15\n",
      "2022-05-16\n",
      "2022-05-17\n",
      "2022-05-18\n",
      "2022-05-19\n",
      "2022-05-20\n",
      "2022-05-21\n",
      "2022-05-22\n",
      "2022-05-23\n",
      "2022-05-24\n",
      "2022-05-25\n",
      "2022-05-26\n",
      "2022-05-27\n",
      "2022-05-28\n",
      "2022-05-29\n",
      "2022-05-30\n",
      "2022-05-31\n",
      "Generating Moving Average Ribbon Signal!!\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import pyarrow as pa\n",
    "import pyarrow.dataset as ds\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIG: storage locations\n",
    "# -----------------------------\n",
    "PERF_STORE_DIR = Path(\"/Users/adheerchauhan/Documents/git/trend_following/data_folder/universe/perf_store\")      # partitioned parquet\n",
    "PERF_STORE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MONTH_END_OPEN_POSITION_DIR = Path(\"/Users/adheerchauhan/Documents/git/trend_following/data_folder/universe/prev_month_open_positions\")\n",
    "MONTH_END_OPEN_POSITION_DIR.mkdir(parents=True, exist_ok=True)\n",
    "POSITIONS_DIR = Path(\"/Users/adheerchauhan/Documents/git/trend_following/data_folder/universe/positions_daily\")\n",
    "POSITIONS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ELIGIBLE_DIR = Path(\"/Users/adheerchauhan/Documents/git/trend_following/data_folder/universe/eligible_products\")\n",
    "\n",
    "# -----------------------------\n",
    "# UTILS\n",
    "# -----------------------------\n",
    "def _tz_naive_sorted_index(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    idx = pd.to_datetime(df.index)\n",
    "    if getattr(idx, \"tz\", None) is not None:\n",
    "        idx = idx.tz_localize(None)\n",
    "    df.index = idx\n",
    "    df.sort_index(inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def write_monthly_performance(\n",
    "    df: pd.DataFrame,\n",
    "    cols: list[str],\n",
    "    month_start: pd.Timestamp,\n",
    "    month_end: pd.Timestamp,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Write ONLY the current month's rows (no warmup leakage) to a partitioned Parquet dataset.\n",
    "    \"\"\"\n",
    "    # 1) normalize + sort\n",
    "    df = df.copy()\n",
    "    idx = pd.to_datetime(df.index)\n",
    "    if getattr(idx, \"tz\", None) is not None:\n",
    "        idx = idx.tz_localize(None)\n",
    "    df.index = idx.normalize()\n",
    "    df.sort_index(inplace=True)\n",
    "\n",
    "    # 2) clamp to [month_start, month_end]\n",
    "    ms = pd.Timestamp(month_start).normalize()\n",
    "    me = pd.Timestamp(month_end).normalize()\n",
    "    df = df.loc[(df.index >= ms) & (df.index <= me)]\n",
    "\n",
    "    if df.empty:\n",
    "        return\n",
    "\n",
    "    # 3) keep only requested cols; add missing as NA\n",
    "    out = pd.DataFrame(index=df.index)\n",
    "    for c in cols:\n",
    "        out[c] = df[c] if c in df.columns else pd.NA\n",
    "\n",
    "    # 4) add partitions\n",
    "    out = out.reset_index().rename(columns={\"index\": \"date\"})\n",
    "    out[\"year\"]  = out[\"date\"].dt.year.astype(int)\n",
    "    out[\"month\"] = out[\"date\"].dt.month.astype(int)\n",
    "\n",
    "    # sanity: should be a single month\n",
    "    assert out[[\"year\",\"month\"]].drop_duplicates().shape[0] == 1, \"Leak outside month!\"\n",
    "\n",
    "    # nuke existing partition dir for this month to make the write idempotent\n",
    "    y, m = int(out[\"year\"].iloc[0]), int(out[\"month\"].iloc[0])\n",
    "    part_dir = PERF_STORE_DIR / f\"year={y}\" / f\"month={m}\"\n",
    "    if part_dir.exists():\n",
    "        shutil.rmtree(part_dir)\n",
    "\n",
    "    # 5) append to dataset\n",
    "    out.to_parquet(\n",
    "        PERF_STORE_DIR,\n",
    "        engine=\"pyarrow\",\n",
    "        partition_cols=[\"year\", \"month\"],\n",
    "        index=False,\n",
    "        existing_data_behavior=\"overwrite_or_ignore\",  # fine: no duplicates if you only write the month once\n",
    "    )\n",
    "\n",
    "\n",
    "def snapshot_open_positions_long(df, month_end_date, ticker_list):\n",
    "    d = pd.Timestamp(month_end_date).normalize()\n",
    "    df = _tz_naive_sorted_index(df)\n",
    "\n",
    "    available_cash = float(df.loc[d, \"available_cash\"])\n",
    "    total_pv = float(df.loc[d, \"total_portfolio_value\"])\n",
    "\n",
    "    rows = []\n",
    "    for t in ticker_list:\n",
    "        size_col = f\"{t}_actual_position_size\"\n",
    "        notl_col = f\"{t}_actual_position_notional\"\n",
    "        if size_col in df.columns and notl_col in df.columns:\n",
    "            size_val = float(df.loc[d, size_col])\n",
    "            if size_val > 0:\n",
    "                rows.append({\n",
    "                    \"date\": d, \"ticker\": t,\n",
    "                    \"actual_position_size\": float(df.loc[d, size_col]),\n",
    "                    \"actual_position_notional\": float(df.loc[d, notl_col]),\n",
    "                    \"available_cash\": available_cash,\n",
    "                    \"total_portfolio_value\": total_pv,\n",
    "                })\n",
    "\n",
    "    if not rows:\n",
    "        rows.append({\n",
    "            \"date\": d, \"ticker\": None,\n",
    "            \"actual_position_size\": 0.0, \"actual_position_notional\": 0.0,\n",
    "            \"available_cash\": available_cash, \"total_portfolio_value\": total_pv,\n",
    "        })\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    out[\"year\"]  = out[\"date\"].dt.year.astype(\"int32\")\n",
    "    out[\"month\"] = out[\"date\"].dt.month.astype(\"int32\")\n",
    "\n",
    "    # enforce stable dtypes\n",
    "    out[\"ticker\"] = out[\"ticker\"].astype(\"string\")\n",
    "    for c in [\"actual_position_size\",\"actual_position_notional\",\"available_cash\",\"total_portfolio_value\"]:\n",
    "        out[c] = pd.to_numeric(out[c], errors=\"coerce\").astype(\"float64\")\n",
    "\n",
    "    # --- NEW: replace the partition to keep it idempotent ---\n",
    "    y, m = int(out[\"year\"].iloc[0]), int(out[\"month\"].iloc[0])\n",
    "    part_dir = MONTH_END_OPEN_POSITION_DIR / f\"year={y}\" / f\"month={m}\"\n",
    "    if part_dir.exists():\n",
    "        shutil.rmtree(part_dir)\n",
    "\n",
    "    out.to_parquet(\n",
    "        MONTH_END_OPEN_POSITION_DIR,\n",
    "        engine=\"pyarrow\",\n",
    "        partition_cols=[\"year\",\"month\"],\n",
    "        index=False,\n",
    "    )\n",
    "    \n",
    "\n",
    "def write_daily_positions(df_month, ticker_list, month_start_date, month_end_date):\n",
    "    \"\"\"\n",
    "    df_month is your monthly dataframe that currently contains per-coin columns.\n",
    "    This function melts it to long rows per dateÃ—coin and writes only the month (no warmup).\n",
    "    \"\"\"\n",
    "    # 1) clamp to month\n",
    "    df = df_month.copy()\n",
    "    idx = pd.to_datetime(df.index)\n",
    "    if getattr(idx, \"tz\", None) is not None: idx = idx.tz_localize(None)\n",
    "    df.index = idx.normalize()\n",
    "    ms, me = pd.Timestamp(month_start_date).normalize(), pd.Timestamp(month_end_date).normalize()\n",
    "    df = df.loc[(df.index >= ms) & (df.index <= me)]\n",
    "    if df.empty:\n",
    "        return\n",
    "    \n",
    "    # 2) pick coin-level columns and melt\n",
    "    SUFFIXES = [\n",
    "        \"actual_position_size\",\n",
    "        \"actual_position_notional\",\n",
    "        \"target_size\",\n",
    "        \"target_notional\",\n",
    "        \"final_weighted_additive_signal\",\n",
    "        \"final_signal\",\n",
    "        \"t_1_close\",\n",
    "        \"open\",\n",
    "        \"20_avg_true_range_price\",\n",
    "        \"highest_high_56\",\n",
    "        \"stop_loss\",\n",
    "        \"stopout_flag\",\n",
    "        \"annualized_volatility_30\",\n",
    "        \"event\",\n",
    "    ]\n",
    "    # CONTEXT_COLS = [\"available_cash\", \"total_portfolio_value\"]  # optional\n",
    "    \n",
    "    ticker_cols = [f'{ticker}_{s}' for ticker in ticker_list for s in SUFFIXES]\n",
    "    wide = df[ticker_cols].copy()\n",
    "    long = (\n",
    "        wide\n",
    "        .stack()                       # index: (date, column_name)\n",
    "        .rename(\"value\")\n",
    "        .reset_index()\n",
    "        .rename(columns={\"level_0\":\"date\",\"level_1\":\"field\"})\n",
    "    )\n",
    "    \n",
    "    # 3) parse product_id and metric from \"BTC-USD_actual_position_size\"\n",
    "    sp = long[\"field\"].str.split(\"_\", n=1)\n",
    "    long[\"product_id\"] = sp.str[0]\n",
    "    long[\"metric\"]     = sp.str[1]\n",
    "    # non-coin fields (available_cash/total_portfolio_value) will have metric=None; drop or keep separately\n",
    "    coin_mask = long[\"product_id\"].str.contains(\"-\", na=False)\n",
    "    long = long[coin_mask]\n",
    "    \n",
    "    # 4) pivot metrics back to columns per (date, product_id)\n",
    "    pos = (\n",
    "        long.pivot_table(index=[\"date\",\"product_id\"], columns=\"metric\", values=\"value\", aggfunc=\"last\")\n",
    "            .reset_index()\n",
    "    )\n",
    "    \n",
    "    # 5) add partitions and enforce dtypes\n",
    "    pos[\"date\"]   = pd.to_datetime(pos[\"date\"]).dt.normalize()\n",
    "    pos[\"year\"]   = pos[\"date\"].dt.year.astype(\"int32\")\n",
    "    pos[\"month\"]  = pos[\"date\"].dt.month.astype(\"int32\")\n",
    "    pos[\"product_id\"] = pos[\"product_id\"].astype(\"string\")\n",
    "    \n",
    "    float_cols = [\"actual_position_size\",\"actual_position_notional\",\"target_size\",\n",
    "                  \"target_notional\",\"final_weighted_additive_signal\",\"final_signal\",\n",
    "                  \"t_1_close\",\"open\",\"20_avg_true_range_price\",\"highest_high_56\",\n",
    "                  \"stop_loss\",\"annualized_volatility_30\"]\n",
    "    for c in float_cols:\n",
    "        if c in pos.columns:\n",
    "            pos[c] = pd.to_numeric(pos[c], errors=\"coerce\").astype(\"float64\")\n",
    "    if \"stopout_flag\" in pos.columns:\n",
    "        pos[\"stopout_flag\"] = pos[\"stopout_flag\"].astype(\"boolean\")\n",
    "    if \"event\" in pos.columns:\n",
    "        pos[\"event\"] = pos[\"event\"].astype(\"string\")\n",
    "\n",
    "    # --- NEW: replace the partition to keep it idempotent ---\n",
    "    y, m = int(pos[\"year\"].iloc[0]), int(pos[\"month\"].iloc[0])\n",
    "    part_dir = POSITIONS_DIR / f\"year={y}\" / f\"month={m}\"\n",
    "    if part_dir.exists():\n",
    "        shutil.rmtree(part_dir)\n",
    "\n",
    "    # 6) write\n",
    "    pos.to_parquet(\n",
    "        POSITIONS_DIR,\n",
    "        engine=\"pyarrow\",\n",
    "        partition_cols=[\"year\",\"month\"],\n",
    "        index=False,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_prev_month_snapshot_wide(prev_month_end: pd.Timestamp) -> pd.DataFrame | None:\n",
    "    d = pd.Timestamp(prev_month_end).normalize()\n",
    "\n",
    "    # enforce a stable schema across all files\n",
    "    schema = pa.schema([\n",
    "        (\"date\", pa.timestamp(\"ns\")),       # use \"ms\" if you wrote ms\n",
    "        (\"ticker\", pa.string()),            # string with NA allowed\n",
    "        (\"actual_position_size\", pa.float64()),\n",
    "        (\"actual_position_notional\", pa.float64()),\n",
    "        (\"available_cash\", pa.float64()),\n",
    "        (\"total_portfolio_value\", pa.float64()),\n",
    "        (\"year\", pa.int32()),\n",
    "        (\"month\", pa.int32()),\n",
    "    ])\n",
    "\n",
    "    dset = ds.dataset(str(MONTH_END_OPEN_POSITION_DIR), format=\"parquet\",\n",
    "                      partitioning=\"hive\", schema=schema)\n",
    "\n",
    "    # read only that month partition\n",
    "    tbl = dset.to_table(\n",
    "        filter=(ds.field(\"year\") == d.year) & (ds.field(\"month\") == d.month)\n",
    "    )\n",
    "    snap = tbl.to_pandas()\n",
    "    if snap.empty:\n",
    "        return None\n",
    "\n",
    "    snap[\"date\"] = pd.to_datetime(snap[\"date\"]).dt.normalize()\n",
    "    snap = snap.loc[snap[\"date\"] == d]\n",
    "    if snap.empty:\n",
    "        return None\n",
    "\n",
    "    # pivot back to your wide shape\n",
    "    available_cash = float(snap[\"available_cash\"].iloc[0])\n",
    "    total_pv = float(snap[\"total_portfolio_value\"].iloc[0])\n",
    "\n",
    "    pos = snap.dropna(subset=[\"ticker\"])\n",
    "    wide = pd.DataFrame(index=[d], columns=[\"available_cash\", \"total_portfolio_value\"])\n",
    "    wide.loc[d, \"available_cash\"] = available_cash\n",
    "    wide.loc[d, \"total_portfolio_value\"] = total_pv\n",
    "\n",
    "    for _, r in pos.iterrows():\n",
    "        t = r[\"ticker\"]\n",
    "        wide.loc[d, f\"{t}_actual_position_size\"] = float(r[\"actual_position_size\"])\n",
    "        wide.loc[d, f\"{t}_actual_position_notional\"] = float(r[\"actual_position_notional\"])\n",
    "\n",
    "    return wide\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# MAIN MONTHLY LOOP (streamlined)\n",
    "# -----------------------------\n",
    "adv_quantile = 0.60\n",
    "high_low_quantile = 0.60\n",
    "\n",
    "## Month-End Date Range for Backtest\n",
    "month_end_dates = pd.date_range(\n",
    "    start=pd.Timestamp(\"2022-03-31\").date(),\n",
    "    end=pd.Timestamp(\"2024-12-31\").date(),\n",
    "    freq=\"M\"\n",
    ")\n",
    "\n",
    "## Performance columns to persist for portfolio analysis\n",
    "PERF_COLS = [\n",
    "    \"daily_portfolio_volatility\", \"available_cash\", \"count_of_positions\",\n",
    "    \"total_actual_position_notional\", \"total_target_notional\",\n",
    "    \"total_portfolio_value\", \"total_portfolio_value_upper_limit\",\n",
    "]\n",
    "\n",
    "for prev_month_end in month_end_dates:\n",
    "    ## Pull Base Universe from Monthly Eligible Ticker List\n",
    "    print(\"Get Final Ticker List Based on Signal Strength on Last Month End Date!!\")\n",
    "    eligible_path = ELIGIBLE_DIR / f\"{pd.Timestamp(prev_month_end).date()}_eligible.parquet\"\n",
    "    df_eligible = pd.read_parquet(eligible_path)\n",
    "    base_universe = df_eligible[\"product_id\"].unique().tolist()\n",
    "\n",
    "    ## Get Month Start and End Dates\n",
    "    month_start_date = pd.Timestamp(prev_month_end).normalize() + pd.Timedelta(days=1)\n",
    "    month_end_date = (pd.Timestamp(prev_month_end) + pd.offsets.MonthEnd(1)).normalize()\n",
    "    print(month_start_date.date(), month_end_date.date(), base_universe)\n",
    "\n",
    "    ## Check if this is the first month in the run\n",
    "    is_first_month = (month_start_date.normalize() == pd.Timestamp(signal_start_date).normalize())\n",
    "    print(f\"Is the first month flag set: {is_first_month}!!\")\n",
    "\n",
    "    ## Pull Previous Month Available Cash, Total Portfolio Value and Open Positions if available\n",
    "    ## If not available, it is the first month and we start with the Initial Capital\n",
    "    print(\"Check if there are any open positions from prior month!!\")\n",
    "    previous_month_open_positions_df = load_prev_month_snapshot_wide(prev_month_end)\n",
    "    if previous_month_open_positions_df is not None:\n",
    "        prev_month_available_cash = previous_month_open_positions_df.loc[prev_month_end.normalize(), \"available_cash\"]\n",
    "        prev_month_total_portfolio_value = previous_month_open_positions_df.loc[prev_month_end.normalize(), \"total_portfolio_value\"]\n",
    "        prev_month_open_ticker_list = [\n",
    "            col.split(\"_\")[0]\n",
    "            for col in previous_month_open_positions_df.columns\n",
    "            if col.endswith(\"_actual_position_notional\")\n",
    "        ]\n",
    "        print(f\"Tickers with Open Positions at Prior Month-end: {prev_month_open_ticker_list}\")\n",
    "    else:\n",
    "        prev_month_open_ticker_list = []\n",
    "        prev_month_available_cash = cfg[\"run\"][\"initial_capital\"]\n",
    "        prev_month_total_portfolio_value = cfg[\"run\"][\"initial_capital\"]\n",
    "        print(\"No Open Positions at Prior Month-end!!\")\n",
    "\n",
    "    ## Create a frozen list of tickers with open positions that are not on the eligible ticker list\n",
    "    print(\"Create Final Ticker List and Frozen Ticker List!!\")\n",
    "    frozen_ticker_list = [t for t in prev_month_open_ticker_list if t not in base_universe]\n",
    "    final_month_ticker_list = base_universe + frozen_ticker_list\n",
    "    print(f\"Final Ticker List for Current Month: {final_month_ticker_list}\")\n",
    "\n",
    "    ## Get the liquidity metrics for all tickers by date\n",
    "    ## This is to exit positions if tickers fall off the daily eligible list based on liquidity criteria\n",
    "    print(\"Pull all eligible tickers based on Liquidity Metrics for every date in the current month!!\")\n",
    "    eligibility_by_date = build_eligibility_by_date_for_month(\n",
    "        client,\n",
    "        month_start_date=month_start_date.date(),\n",
    "        month_end_date=month_end_date.date(),\n",
    "        lookback_day_count=lookback_day_count,\n",
    "        adv_quantile=adv_quantile,\n",
    "        high_low_quantile=high_low_quantile,\n",
    "        product_list=base_universe,\n",
    "        max_workers=5,\n",
    "        batch_size=10,\n",
    "        between_batches_sleep=0.10,\n",
    "    )\n",
    "\n",
    "    ## Generate Trend Following Trading Signal\n",
    "    print(\"Generating Moving Average Ribbon Signal!!\")\n",
    "    df_trend = get_trend_donchian_signal_for_portfolio_with_rolling_r_sqr_vol_of_vol(\n",
    "        start_date=month_start_date - pd.Timedelta(days=warmup_days),\n",
    "        end_date=month_end_date,\n",
    "        ticker_list=final_month_ticker_list,\n",
    "        fast_mavg=fast_mavg,\n",
    "        slow_mavg=slow_mavg,\n",
    "        mavg_stepsize=mavg_stepsize,\n",
    "        mavg_z_score_window=mavg_z_score_window,\n",
    "        entry_rolling_donchian_window=entry_rolling_donchian_window,\n",
    "        exit_rolling_donchian_window=exit_rolling_donchian_window,\n",
    "        use_donchian_exit_gate=use_donchian_exit_gate,\n",
    "        ma_crossover_signal_weight=ma_crossover_signal_weight,\n",
    "        donchian_signal_weight=donchian_signal_weight,\n",
    "        weighted_signal_ewm_window=weighted_signal_ewm_window,\n",
    "        rolling_r2_window=rolling_r2_window,\n",
    "        lower_r_sqr_limit=lower_r_sqr_limit,\n",
    "        upper_r_sqr_limit=upper_r_sqr_limit,\n",
    "        r2_smooth_window=r2_smooth_window,\n",
    "        r2_confirm_days=r2_confirm_days,\n",
    "        log_std_window=log_std_window,\n",
    "        coef_of_variation_window=coef_of_variation_window,\n",
    "        vol_of_vol_z_score_window=vol_of_vol_z_score_window,\n",
    "        vol_of_vol_p_min=vol_of_vol_p_min,\n",
    "        r2_strong_threshold=r2_strong_threshold,\n",
    "        use_activation=use_activation,\n",
    "        tanh_activation_constant_dict=tanh_activation_constant_dict,\n",
    "        moving_avg_type=moving_avg_type,\n",
    "        long_only=long_only,\n",
    "        price_or_returns_calc=price_or_returns_calc,\n",
    "        use_coinbase_data=use_coinbase_data,\n",
    "        use_saved_files=False,\n",
    "        saved_file_end_date=saved_file_end_date,\n",
    "    )\n",
    "\n",
    "    ## Volatility Adjust the Trend Signal\n",
    "    print(\"Generating Volatility Adjusted Trend Signal!!\")\n",
    "    df_signal = size_cont.get_volatility_adjusted_trend_signal_continuous(\n",
    "        df=df_trend,\n",
    "        ticker_list=final_month_ticker_list,\n",
    "        volatility_window=volatility_window,\n",
    "        annual_trading_days=annual_trading_days,\n",
    "    )\n",
    "\n",
    "    ## Get Average True Range for all tickers\n",
    "    print(\"Getting Average True Range for Stop Loss Calculation!!\")\n",
    "    df_atr = size_cont.get_average_true_range_portfolio(\n",
    "        start_date=month_start_date - pd.Timedelta(days=warmup_days),\n",
    "        end_date=month_end_date,\n",
    "        ticker_list=final_month_ticker_list,\n",
    "        rolling_atr_window=rolling_atr_window,\n",
    "        highest_high_window=highest_high_window,\n",
    "        price_or_returns_calc=\"price\",\n",
    "        use_coinbase_data=use_coinbase_data,\n",
    "        use_saved_files=False,\n",
    "        saved_file_end_date=saved_file_end_date,\n",
    "    )\n",
    "    df_signal = pd.merge(df_signal, df_atr, left_index=True, right_index=True, how=\"left\")\n",
    "\n",
    "    ## Get the Volatility Targeted Position Sizes for the eligible tickers\n",
    "    print(\"Calculating Volatility Targeted Position Size and Cash Management!!\")\n",
    "    df_month = get_target_volatility_daily_portfolio_positions_expanded_universe(\n",
    "        df_signal,\n",
    "        ticker_list=final_month_ticker_list,\n",
    "        initial_capital=initial_capital,\n",
    "        rolling_cov_window=rolling_cov_window,\n",
    "        stop_loss_strategy=stop_loss_strategy,\n",
    "        rolling_atr_window=rolling_atr_window,\n",
    "        atr_multiplier=atr_multiplier,\n",
    "        highest_high_window=highest_high_window,\n",
    "        cash_buffer_percentage=cash_buffer_percentage,\n",
    "        annualized_target_volatility=annualized_target_volatility,\n",
    "        transaction_cost_est=transaction_cost_est,\n",
    "        passive_trade_rate=passive_trade_rate,\n",
    "        notional_threshold_pct=notional_threshold_pct,\n",
    "        min_trade_notional_abs=min_trade_notional_abs,\n",
    "        cooldown_counter_threshold=cooldown_counter_threshold,\n",
    "        annual_trading_days=annual_trading_days,\n",
    "        use_specific_start_date=is_first_month,\n",
    "        signal_start_date=signal_start_date,\n",
    "        start_date=month_start_date,\n",
    "        previous_month_open_positions_df=previous_month_open_positions_df,\n",
    "        frozen_ticker_list=frozen_ticker_list,\n",
    "        per_asset_weight_cap=0.25,\n",
    "        per_asset_notional_cap=None,\n",
    "        allow_adds_on_frozen=True,\n",
    "        eligibility_by_date=eligibility_by_date,\n",
    "        force_exit_if_ineligible=True,\n",
    "        max_positions=12,\n",
    "        max_new_per_day=3,\n",
    "        signal_col_suffix=\"_final_signal\",\n",
    "    )\n",
    "\n",
    "    ## Write the current month's portfolio performance metrics to a Parquet file\n",
    "    write_monthly_performance(df_month,\n",
    "                              cols=PERF_COLS,\n",
    "                              month_start=month_start_date,\n",
    "                              month_end=month_end_date\n",
    "                             )\n",
    "\n",
    "    ## Save the Open Positions at month end to a Parquet file\n",
    "    snapshot_open_positions_long(\n",
    "        df=df_month,\n",
    "        month_end_date=month_end_date,\n",
    "        ticker_list=final_month_ticker_list,\n",
    "    )\n",
    "\n",
    "    ## Archive the Daily Positions file by ticker for further analysis\n",
    "    write_daily_positions(df_month, ticker_list=final_month_ticker_list,\n",
    "                          month_start_date=month_start_date, month_end_date=month_end_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ba529f-d85f-4b3f-86de-c20525b22d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_month.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66ba9de-375b-48b6-8947-85705dd54552",
   "metadata": {},
   "outputs": [],
   "source": [
    "long.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8265a627-542c-42f0-a968-29a27ea889df",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8a0665-3444-4873-828f-00786ca33c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "atr_cols = [col for col in df_month.columns if 'avg_true_range' in col]\n",
    "df_month[df_month.index > pd.Timestamp('2022-03-31')][atr_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6cc914-8082-4343-ab85-da493ae1e5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82e7e07-3875-4a6b-a677-6d6bdef4bfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717f1485-58a9-4e73-b307-c111cbf715a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.dataset as ds\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# OPEN_POS_DIR = Path(\"/Users/adheerchauhan/Documents/git/trend_following/data_folder/universe/prev_month_open_positions\")\n",
    "\n",
    "# Define the schema we expect across ALL files\n",
    "open_pos_schema = pa.schema([\n",
    "    (\"date\", pa.timestamp(\"ns\")),            # or \"ms\" if that's what you wrote; adjust if needed\n",
    "    (\"ticker\", pa.string()),                 # enforce string, NA allowed\n",
    "    (\"actual_position_size\", pa.float64()),\n",
    "    (\"actual_position_notional\", pa.float64()),\n",
    "    (\"available_cash\", pa.float64()),\n",
    "    (\"total_portfolio_value\", pa.float64()),\n",
    "    (\"year\", pa.int32()),\n",
    "    (\"month\", pa.int32()),\n",
    "])\n",
    "\n",
    "# Build a Dataset with hive partitioning (year=..., month=...)\n",
    "dset = ds.dataset(str(MONTH_END_OPEN_POSITION_DIR), format=\"parquet\", partitioning=\"hive\", schema=open_pos_schema)\n",
    "\n",
    "# Optional pruning with a filter; omit filter to read all\n",
    "# filt = (ds.field(\"year\") == 2022) & (ds.field(\"month\").isin([4,5,6]))\n",
    "# tbl = dset.to_table(filter=filt, columns=[...])\n",
    "\n",
    "tbl = dset.to_table()  # full read with enforced schema\n",
    "df_open = tbl.to_pandas()\n",
    "\n",
    "# Make sure date is normalized if you rely on equality checks\n",
    "df_open[\"date\"] = pd.to_datetime(df_open[\"date\"]).dt.normalize()\n",
    "df_open = df_open.sort_values(['year','month'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a10e967-cebc-4988-8d04-7b5826f62ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001f61fe-795c-4681-94b9-a4b22c3e050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pyarrow as pa\n",
    "import pyarrow.dataset as ds\n",
    "import pandas as pd\n",
    "\n",
    "PERF_COLS = [\n",
    "    \"daily_portfolio_volatility\", \"available_cash\", \"count_of_positions\",\n",
    "    \"total_actual_position_notional\", \"total_target_notional\",\n",
    "    \"total_portfolio_value\", \"total_portfolio_value_upper_limit\",\n",
    "]\n",
    "\n",
    "PERF_STORE_DIR = Path(\"/Users/adheerchauhan/Documents/git/trend_following/data_folder/universe/perf_store\")\n",
    "\n",
    "# --- Define a consistent schema for the perf dataset ---\n",
    "# Adjust timestamp unit to \"ms\" if you wrote in milliseconds instead of nanoseconds.\n",
    "perf_schema = pa.schema(\n",
    "    [(\"date\", pa.timestamp(\"ns\"))] +\n",
    "    # floats for all continuous/numeric portfolio fields\n",
    "    [(c, pa.float64()) for c in PERF_COLS if c != \"count_of_positions\"] +\n",
    "    # count_of_positions as integer (nullable Int32 for safety)\n",
    "    [(\"count_of_positions\", pa.int32())] +\n",
    "    # partition columns\n",
    "    [(\"year\", pa.int32()), (\"month\", pa.int32())]\n",
    ")\n",
    "\n",
    "# --- Build the Dataset (hive partitioning: year=..., month=...) ---\n",
    "perf_ds = ds.dataset(str(PERF_STORE_DIR), format=\"parquet\", partitioning=\"hive\", schema=perf_schema)\n",
    "\n",
    "# --- Read everything (fast; respects partitions) ---\n",
    "perf_tbl = perf_ds.to_table(columns=[\"date\"] + PERF_COLS + [\"year\", \"month\"])\n",
    "df_perf = perf_tbl.to_pandas()\n",
    "\n",
    "# Normalize & index by date\n",
    "df_perf[\"date\"] = pd.to_datetime(df_perf[\"date\"]).dt.normalize()\n",
    "df_perf = df_perf.sort_values([\"year\", \"month\", \"date\"]).set_index(\"date\")\n",
    "\n",
    "# Optional: drop partition columns in the final frame\n",
    "df_perf = df_perf[PERF_COLS]\n",
    "\n",
    "# --- Example: read a filtered slice efficiently (only scans needed folders) ---\n",
    "# filt = (ds.field(\"year\") == 2022) & (ds.field(\"month\").isin([4, 5, 6]))\n",
    "# perf_tbl_q2 = perf_ds.to_table(filter=filt, columns=[\"date\"] + PERF_COLS + [\"year\", \"month\"])\n",
    "# df_perf_q2 = (perf_tbl_q2.to_pandas()\n",
    "#               .assign(date=lambda d: pd.to_datetime(d[\"date\"]).dt.normalize())\n",
    "#               .sort_values([\"year\", \"month\", \"date\"])\n",
    "#               .set_index(\"date\"))[PERF_COLS]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb2885a-e71f-4d59-bb77-e3d283c648cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8619706-b8ec-474b-b918-4c533c3043d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff36d0ac-c297-44fd-af86-d6033f08eaec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adv_quantile=0.60\n",
    "high_low_quantile=0.60\n",
    "\n",
    "MONTH_END_OPEN_POSITION_DIR = Path(\"/Users/adheerchauhan/Documents/git/trend_following/data_folder/universe/prev_month_open_positions\")\n",
    "MONTH_END_OPEN_POSITION_DIR.mkdir(parents=True, exist_ok=True)\n",
    "month_end_dates = pd.date_range(start=pd.Timestamp('2022-03-31').date(), end=pd.Timestamp('2022-12-31').date(), freq='M')\n",
    "prev_month_open_ticker_list = []\n",
    "month_df_dict = {}\n",
    "\n",
    "## Loop through all month-end dates\n",
    "for prev_month_end in month_end_dates:    \n",
    "    ## Pull in the final ticker list for the month based on the signal strength\n",
    "    print('Get Final Ticker List Based on Signal Strength on Last Month End Date!!')\n",
    "    out = ELIGIBLE_DIR / f\"{pd.Timestamp(prev_month_end).date()}_eligible.parquet\"\n",
    "    df_eligible = pd.read_parquet(out)\n",
    "    base_universe = df_eligible.product_id.unique().tolist()\n",
    "\n",
    "    ## Set the start and end date based on the following months\n",
    "    month_start_date = prev_month_end.date() + pd.Timedelta(days=1)\n",
    "    month_end_date = (prev_month_end + pd.offsets.MonthEnd(1)).date()\n",
    "    print(month_start_date, month_end_date, base_universe)\n",
    "\n",
    "    ## Set a flag to track the first month in the run\n",
    "    is_first_month = (pd.Timestamp(month_start_date).normalize()\n",
    "                      == pd.Timestamp(signal_start_date).normalize())\n",
    "    print(f'Is the first month flag set: {is_first_month}!!')\n",
    "\n",
    "    ## Pull in the available cash, total portfolio value and any open positions from the previous month\n",
    "    print('Check if there are any open positions from prior month!!')\n",
    "    prev_month_open_positions = MONTH_END_OPEN_POSITION_DIR / f'{prev_month_end.date()}_open_positions.pickle'\n",
    "    previous_month_open_positions_df = None\n",
    "    if prev_month_open_positions.exists():\n",
    "        previous_month_open_positions_df = pd.read_pickle(prev_month_open_positions)\n",
    "        prev_month_available_cash = previous_month_open_positions_df.loc[prev_month_end, 'available_cash']\n",
    "        prev_month_total_portfolio_value = previous_month_open_positions_df.loc[prev_month_end, 'total_portfolio_value']\n",
    "        prev_month_open_ticker_list = [col.split('_')[0] for col in previous_month_open_positions_df.columns if '_actual_position_notional' in col]\n",
    "        print(f'Tickers with Open Positions at Prior Month-end: {prev_month_open_ticker_list}')\n",
    "    else:\n",
    "        prev_month_open_ticker_list = []\n",
    "        prev_month_available_cash = cfg['run']['initial_capital']\n",
    "        prev_month_total_portfolio_value = cfg['run']['initial_capital']\n",
    "        print('No Open Positions at Prior Month-end!!')\n",
    "\n",
    "    ## Account for any tickers with open positions that are no longer on the final ticker list\n",
    "    print('Create Final Ticker List and Frozen Ticker List!!')\n",
    "    frozen_ticker_list = [ticker for ticker in prev_month_open_ticker_list if ticker not in base_universe]\n",
    "    final_month_ticker_list = base_universe + frozen_ticker_list\n",
    "    print(f'Final Ticker List for Current Month: {final_month_ticker_list}')\n",
    "\n",
    "    # ---- NEW: build daily eligibility map (ADV/spread only) ----\n",
    "    print('Pull all eligible tickers based on Liquidity Metrics for every date in the current month!!')\n",
    "    eligibility_by_date = build_eligibility_by_date_for_month(\n",
    "        client,\n",
    "        month_start_date=month_start_date,\n",
    "        month_end_date=month_end_date,\n",
    "        lookback_day_count=lookback_day_count,\n",
    "        adv_quantile=adv_quantile, high_low_quantile=high_low_quantile,\n",
    "        product_list=base_universe,\n",
    "        max_workers=5, batch_size=12, between_batches_sleep=0.10\n",
    "    )\n",
    "    # -----------------------------------------------------------\n",
    "\n",
    "    print('Generating Moving Average Ribbon Signal!!')\n",
    "    ## Generate Trend Signal for all tickers including tickers on the frozen list\n",
    "    df_trend = get_trend_donchian_signal_for_portfolio_with_rolling_r_sqr_vol_of_vol(\n",
    "        start_date=month_start_date - pd.Timedelta(days=warmup_days), end_date=month_end_date, ticker_list=final_month_ticker_list,\n",
    "        fast_mavg=fast_mavg, slow_mavg=slow_mavg, mavg_stepsize=mavg_stepsize, mavg_z_score_window=mavg_z_score_window,\n",
    "        entry_rolling_donchian_window=entry_rolling_donchian_window,\n",
    "        exit_rolling_donchian_window=exit_rolling_donchian_window, use_donchian_exit_gate=use_donchian_exit_gate,\n",
    "        ma_crossover_signal_weight=ma_crossover_signal_weight, donchian_signal_weight=donchian_signal_weight,\n",
    "        weighted_signal_ewm_window=weighted_signal_ewm_window, rolling_r2_window=rolling_r2_window,\n",
    "        lower_r_sqr_limit=lower_r_sqr_limit, upper_r_sqr_limit=upper_r_sqr_limit, r2_smooth_window=r2_smooth_window,\n",
    "        r2_confirm_days=r2_confirm_days, log_std_window=log_std_window, coef_of_variation_window=coef_of_variation_window,\n",
    "        vol_of_vol_z_score_window=vol_of_vol_z_score_window, vol_of_vol_p_min=vol_of_vol_p_min,\n",
    "        r2_strong_threshold=r2_strong_threshold, use_activation=use_activation,\n",
    "        tanh_activation_constant_dict=tanh_activation_constant_dict, moving_avg_type=moving_avg_type,\n",
    "        long_only=long_only, price_or_returns_calc=price_or_returns_calc, use_coinbase_data=use_coinbase_data,\n",
    "        use_saved_files=False, saved_file_end_date=saved_file_end_date)\n",
    "    \n",
    "    print('Generating Volatility Adjusted Trend Signal!!')\n",
    "    ## Get Volatility Adjusted Trend Signal\n",
    "    df_signal = size_cont.get_volatility_adjusted_trend_signal_continuous(df=df_trend, ticker_list=final_month_ticker_list,\n",
    "                                                                          volatility_window=volatility_window,\n",
    "                                                                          annual_trading_days=annual_trading_days)\n",
    "    \n",
    "    print('Getting Average True Range for Stop Loss Calculation!!')\n",
    "    ## Get Average True Range for Stop Loss Calculation\n",
    "    df_atr = size_cont.get_average_true_range_portfolio(start_date=month_start_date - pd.Timedelta(days=warmup_days), end_date=month_end_date,\n",
    "                                                        ticker_list=final_month_ticker_list, rolling_atr_window=rolling_atr_window,\n",
    "                                                        highest_high_window=highest_high_window,\n",
    "                                                        price_or_returns_calc='price',\n",
    "                                                        use_coinbase_data=use_coinbase_data,\n",
    "                                                        use_saved_files=False,\n",
    "                                                        saved_file_end_date=saved_file_end_date)\n",
    "    df_signal = pd.merge(df_signal, df_atr, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    print('Calculating Volatility Targeted Position Size and Cash Management!!')\n",
    "    ## Get Target Volatility Position Sizing and Run Cash Management\n",
    "    df = get_target_volatility_daily_portfolio_positions_expanded_universe(\n",
    "        df_signal, ticker_list=final_month_ticker_list, initial_capital=initial_capital, rolling_cov_window=rolling_cov_window,\n",
    "        stop_loss_strategy=stop_loss_strategy, rolling_atr_window=rolling_atr_window, atr_multiplier=atr_multiplier,\n",
    "        highest_high_window=highest_high_window,\n",
    "        cash_buffer_percentage=cash_buffer_percentage, annualized_target_volatility=annualized_target_volatility,\n",
    "        transaction_cost_est=transaction_cost_est, passive_trade_rate=passive_trade_rate,\n",
    "        notional_threshold_pct=notional_threshold_pct, min_trade_notional_abs=min_trade_notional_abs,\n",
    "        cooldown_counter_threshold=cooldown_counter_threshold, annual_trading_days=annual_trading_days,\n",
    "        use_specific_start_date=is_first_month, signal_start_date=signal_start_date,\n",
    "        start_date=month_start_date, previous_month_open_positions_df=previous_month_open_positions_df,\n",
    "        frozen_ticker_list=frozen_ticker_list, \n",
    "        per_asset_weight_cap=0.25,                # e.g., max 25% of PV upper limit per asset\n",
    "        per_asset_notional_cap=None,              # e.g., 5000. If None, ignore absolute cap.\n",
    "        allow_adds_on_frozen=True,                # True = you can scale UP frozen tickers\n",
    "        eligibility_by_date=eligibility_by_date,  # dict[date]->set([...]) of liquidity-eligible tickers\n",
    "        force_exit_if_ineligible=True,            # True = immediate full exit if ineligible today\n",
    "        max_positions = 12,                       # e.g., 12\n",
    "        max_new_per_day = 3,                      # e.g., 3\n",
    "        signal_col_suffix = \"_final_signal\"       # so we can rank entries cleanly\n",
    "    )\n",
    "\n",
    "    ## Save the monthly dataframe to a dictionary for further analysis\n",
    "    print('Saving final monthly dataframe to dictionary!!')\n",
    "    month_df_dict[month_start_date] = df\n",
    "\n",
    "    ## Save month end positions as a pickle file\n",
    "    actual_position_notional_cols = [col for col in df.columns if '_actual_position_notional' in col]\n",
    "    actual_position_size_cols = [col for col in df.columns if '_actual_position_size' in col]\n",
    "    open_position_size_list = []\n",
    "    for ticker in final_month_ticker_list:\n",
    "        if df.loc[pd.Timestamp(month_end_date), f'{ticker}_actual_position_size'] > 0:\n",
    "            open_position_size_list.append(ticker)\n",
    "    \n",
    "    ## Create month-end dataframe to archive for following month\n",
    "    prev_month_cols = ['date', 'available_cash', 'total_portfolio_value']\n",
    "    open_position_size_cols = [f'{ticker}_actual_position_size' for ticker in open_position_size_list]\n",
    "    open_position_notional_cols = [f'{ticker}_actual_position_notional' for ticker in open_position_size_list]\n",
    "    prev_month_cols = prev_month_cols + open_position_size_cols + open_position_notional_cols\n",
    "    df_month_end_positions = pd.DataFrame(columns=prev_month_cols)\n",
    "    df_month_end_positions.loc[0, 'date'] = pd.Timestamp(month_end_date)\n",
    "    df_month_end_positions = df_month_end_positions.set_index('date')\n",
    "    df_month_end_positions.loc[pd.Timestamp(month_end_date), 'available_cash'] = df.loc[pd.Timestamp(month_end_date), 'available_cash']\n",
    "    df_month_end_positions.loc[pd.Timestamp(month_end_date), 'total_portfolio_value'] = df.loc[pd.Timestamp(month_end_date), 'total_portfolio_value']\n",
    "    for ticker in open_position_size_list:\n",
    "        df_month_end_positions.loc[pd.Timestamp(month_end_date), f'{ticker}_actual_position_notional'] = df.loc[pd.Timestamp(month_end_date), f'{ticker}_actual_position_notional']\n",
    "        df_month_end_positions.loc[pd.Timestamp(month_end_date), f'{ticker}_actual_position_size'] = df.loc[pd.Timestamp(month_end_date), f'{ticker}_actual_position_size']\n",
    "\n",
    "    month_end_open_positions = MONTH_END_OPEN_POSITION_DIR / f'{month_end_date}_open_positions.pickle'\n",
    "    df_month_end_positions.to_pickle(month_end_open_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10288ec2-861f-4369-beaf-d7a7718594b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# monthly_frames: dict where key is any date inside the month (e.g., month_start or month_end)\n",
    "# and value is the month's DataFrame returned by your sizing pipeline.\n",
    "# Example: {date(2022,4,1): df_apr, date(2022,5,1): df_may, ...}\n",
    "def collect_performance_across_months(monthly_frames: dict, cols: list[str]) -> pd.DataFrame:\n",
    "    pieces = []\n",
    "    for k, df in monthly_frames.items():\n",
    "        # 1) ensure DatetimeIndex, tz-naive, normalized, sorted\n",
    "        idx = pd.to_datetime(df.index, utc=True).tz_localize(None) if not isinstance(df.index, pd.DatetimeIndex) else df.index\n",
    "        if idx.tz is not None:\n",
    "            idx = idx.tz_localize(None)\n",
    "        idx = idx.normalize()\n",
    "        if not df.index.equals(idx):\n",
    "            df = df.copy()\n",
    "            df.index = idx\n",
    "        df = df.sort_index()\n",
    "\n",
    "        # 2) derive month start/end for this DF\n",
    "        # Try to use the dict key 'k' as an anchor (it can be a date or timestamp)\n",
    "        anchor = pd.Timestamp(k).normalize()\n",
    "        # month start = first day of that month; month end = last day of that month\n",
    "        ms = (anchor - pd.offsets.MonthBegin(1)) if anchor.day != 1 else anchor\n",
    "        me = ms + pd.offsets.MonthEnd(0)\n",
    "\n",
    "        # If your dict key is month-end (common), ms above still works:\n",
    "        #   e.g., k=2022-03-31 -> ms=2022-03-01, me=2022-03-31\n",
    "\n",
    "        # 3) clamp rows to [ms, me] (handles warmup because we simply start at max(first_idx, ms))\n",
    "        df_month = df.loc[(df.index >= ms) & (df.index <= me)]\n",
    "\n",
    "        if df_month.empty:\n",
    "            continue\n",
    "\n",
    "        # 4) ensure columns exist; select + add missing as NaN\n",
    "        keep = [c for c in cols if c in df_month.columns]\n",
    "        missing = [c for c in cols if c not in df_month.columns]\n",
    "        out = df_month[keep].copy()\n",
    "        for m in missing:\n",
    "            out[m] = np.nan\n",
    "        out = out[cols]\n",
    "\n",
    "        # 5) add a date column if you want (optional); or keep index as is\n",
    "        out = out.copy()\n",
    "        out[\"date\"] = out.index\n",
    "\n",
    "        pieces.append(out)\n",
    "\n",
    "    if not pieces:\n",
    "        return pd.DataFrame(columns=cols + [\"date\"])\n",
    "\n",
    "    df_performance_track = pd.concat(pieces, axis=0, ignore_index=False)\n",
    "    # sort and drop duplicates in case overlapping months produced repeats\n",
    "    df_performance_track = df_performance_track.sort_index()\n",
    "    df_performance_track = df_performance_track[~df_performance_track.index.duplicated(keep=\"last\")]\n",
    "\n",
    "    # Reorder final columns (index first; or move 'date' first if you prefer)\n",
    "    # If you'd rather have a RangeIndex and 'date' as a column, uncomment:\n",
    "    # df_performance_track = df_performance_track.reset_index(drop=True)\n",
    "\n",
    "    return df_performance_track\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be324ea-3b30-4cfa-af1a-cea8a3fee6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def month_key(dt_like) -> pd.Period:\n",
    "    return pd.Timestamp(dt_like).to_period('M')\n",
    "\n",
    "def collect_performance(monthly_frames: dict[pd.Period, pd.DataFrame], cols: list[str]) -> pd.DataFrame:\n",
    "    pieces = []\n",
    "    for p, df in monthly_frames.items():\n",
    "        # Ensure DatetimeIndex is tz-naive daily timestamps\n",
    "        idx = pd.to_datetime(df.index)\n",
    "        if getattr(idx, \"tz\", None) is not None:\n",
    "            idx = idx.tz_localize(None)\n",
    "        df = df.copy()\n",
    "        df.index = idx\n",
    "\n",
    "        # Clamp to that month using the Period key\n",
    "        mask = (df.index >= p.start_time) & (df.index <= p.end_time)\n",
    "        df_month = df.loc[mask]\n",
    "\n",
    "        if df_month.empty:\n",
    "            continue\n",
    "\n",
    "        # Keep only needed cols; add missing as NaN\n",
    "        keep = [c for c in cols if c in df_month.columns]\n",
    "        out = df_month[keep].copy()\n",
    "        for m in (set(cols) - set(keep)):\n",
    "            out[m] = np.nan\n",
    "        out = out[cols]\n",
    "\n",
    "        pieces.append(out)\n",
    "\n",
    "    if not pieces:\n",
    "        return pd.DataFrame(columns=cols)\n",
    "\n",
    "    out = pd.concat(pieces, axis=0)\n",
    "    out = out[~out.index.duplicated(keep=\"last\")]\n",
    "    return out.sort_index()\n",
    "\n",
    "# Example while building the dict:\n",
    "# month_df_dict[month_key(month_start_date)] = df_month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16c9315-f18f-4bd7-85e0-eaf784bfffa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# while saving each monthly df:\n",
    "month_df_dict[pd.Timestamp(month_start_date).to_period('M')] = df\n",
    "\n",
    "# then build:\n",
    "cols = [\n",
    "    'daily_portfolio_volatility','available_cash','count_of_positions',\n",
    "    'total_actual_position_notional','total_target_notional',\n",
    "    'total_portfolio_value','total_portfolio_value_upper_limit'\n",
    "]\n",
    "df_performance_track = collect_performance(month_df_dict, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818492c3-e5de-471c-b3d9-710d1e83b50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_performance_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811d9d96-542a-4c8f-9d83-4bea1f4dca2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_performance_track = size_bin.calculate_portfolio_returns(df_performance_track, rolling_sharpe_window=rolling_sharpe_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f786f5aa-87aa-4362-9123-4fde31c647a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_performance_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0619b8f3-7e3f-4821-8a55-78740cba0a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_performance_track['portfolio_strategy_cumulative_return'].plot(figsize=(12,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2a43eb-87bc-4c4c-b12c-65a6ad6a0eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cond = month_df_dict[pd.Timestamp('2023-01-01').date()].index >= pd.Timestamp('2023-01-01')\n",
    "month_df_dict[pd.Timestamp('2023-01-01').date()][date_cond].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9401117-f34f-45e9-90c3-e9b804b32b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_date_key = pd.Timestamp('2023-01-01').date()\n",
    "event_cols = [x for x in month_df_dict[dict_date_key].columns if 'event' in x]\n",
    "month_df_dict[pd.Timestamp('2023-01-01').date()][date_cond][event_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a51a72-b8ff-4c54-8944-db59505822fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_df_dict[pd.Timestamp('2023-01-01').date()]['BTC-USD_event']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69a22f4-71ba-473e-a499-53c14515e6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "12.94 - 1.75*0.848609"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74975d38-f2f1-405d-90d2-250a97bdae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_date_key = pd.Timestamp('2022-04-01').date()\n",
    "date_cond = (month_df_dict[dict_date_key].index >= pd.Timestamp('2022-04-01'))\n",
    "month_df_dict[dict_date_key][date_cond].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3be5f1-e1b3-4427-b26d-6e699b406738",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_cols = [x for x in month_df_dict[dict_date_key].columns if 'event' in x]\n",
    "month_df_dict[dict_date_key][date_cond][event_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089ca562-e863-43e7-bdf9-4ac2971625cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_notional_cols = [x for x in month_df_dict[dict_date_key].columns if 'actual_position_notional' in x and 'total' not in x]\n",
    "month_df_dict[dict_date_key][date_cond][actual_notional_cols].plot(figsize=(12,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f736a2-b5a3-4acc-9f11-d5a606e57049",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_date_key = pd.Timestamp('2022-05-01').date()\n",
    "date_cond = (month_df_dict[dict_date_key].index >= pd.Timestamp('2022-05-01'))\n",
    "month_df_dict[dict_date_key][date_cond].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fb41cb-1712-4bf5-b941-c9ea82d6f910",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_signal_cols = [f'{ticker}_final_signal' for ticker in final_month_ticker_list]\n",
    "month_df_dict[dict_date_key][date_cond][final_signal_cols].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b6cda9-91f5-4603-ad49-a8f9ffb37fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_month_open_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010ca53a-8dfa-4003-9065-9a34509ffa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_month_open_positions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fbdf14-b99c-43ac-86c6-27505490c41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_end_date_temp = pd.Timestamp('2022-04-30').date()\n",
    "month_end_open_positions = MONTH_END_OPEN_POSITION_DIR / f'{month_end_date_temp}_open_positions.pickle'\n",
    "df_month_end_positions_temp = pd.read_pickle(month_end_open_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a050b2-21cf-4395-b68b-df015ab0d1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_month_end_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3873dcd6-b85b-4472-ac99-fd32d20008bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_df_dict[dict_date_key][date_cond]['total_portfolio_value'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c18357-892b-4289-9665-ff17adfbfd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144cae08-d1d2-4394-9647-c13f0d59f083",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_first_month = (pd.Timestamp(month_start_date).normalize()\n",
    "                  == pd.Timestamp(signal_start_date).normalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696b3bf1-f54c-4163-91c7-a9a7145cf0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_first_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dc968c-a0ee-4a81-87c9-61041675c039",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc20f59d-7042-4dd7-b7cb-6a38256d01b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_confirm_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfaf119-c373-47c3-8ec4-aee6ba6710b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_month_end_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ca28ab-1955-42e3-a9fa-cd4174f9643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cond = (df.index >= pd.Timestamp('2022-05-01'))\n",
    "df[date_cond].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47894095-3c7b-4cff-bf41-02ef645eb43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.index >= pd.Timestamp('2022-03-20'))]['available_cash'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3add1c99-10dc-4bba-b51f-b6b14d4339bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_signal_cols = [f'{ticker}_final_signal' for ticker in final_month_ticker_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64981d86-5063-4db3-ba57-ea27b7754424",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cond = (df_signal.index >= pd.Timestamp('2022-04-01'))\n",
    "df_signal[date_cond][final_signal_cols].plot(figsize=(12,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b4e40c-8ab0-4b34-b3a5-106de1119f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cond = (df.index >= pd.Timestamp('2022-04-01'))\n",
    "notional_cols = [f'{ticker}_actual_position_notional' for ticker in final_month_ticker_list]\n",
    "df[date_cond][notional_cols].plot(figsize=(12,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50f652a-9d3b-4c8a-bb60-2b458ac2f7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cond = (df.index >= pd.Timestamp('2022-04-01'))\n",
    "notional_cols = [f'{ticker}_target_notional' for ticker in final_month_ticker_list]\n",
    "df[date_cond][notional_cols].plot(figsize=(12,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1b0b8e-d6ee-401f-a6a0-080bb55bdb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[date_cond]['total_portfolio_value'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db104f98-4dc9-47c0-9eaf-b35e0b320d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[date_cond][notional_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2552f277-f1fc-4340-9d09-8ae30df320e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[date_cond].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03093821-5ded-4495-8803-9492bb1a9ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in eligibility_by_date.items():\n",
    "    print(k, len(v), sorted(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff8d6ab-39bb-48cb-b16f-6b37fd20e266",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_month_ticker_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28138c70-1d94-4834-ace9-e126fc4fb184",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(final_month_ticker_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3819c3b5-2953-4ea0-ad84-d4ab97c80798",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40afb3fc-934f-4b0f-bbed-5cf47ecdf88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadcad15-166f-42bc-9435-1044b9d171fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_specific_start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7a5abc-b656-47b8-b7fa-ee3e4150b221",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_signal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c749185-678b-48d1-b370-d21348734702",
   "metadata": {},
   "outputs": [],
   "source": [
    "eligibility_by_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbede98-ed9d-460a-87d8-7805ba67d041",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trend.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeeb8b1-93aa-45dc-a185-2ad24146ecb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "month_end_dates = pd.date_range(start=pd.Timestamp('2022-03-31').date(), end=pd.Timestamp('2022-12-31').date(), freq='M')\n",
    "prev_month_open_ticker_list = []\n",
    "\n",
    "## Loop through all month-end dates\n",
    "for prev_month_end in month_end_dates:\n",
    "    ## Pull in the final ticker list for the month based on the signal strength\n",
    "    final_month_ticker_list = eligible_ticker_dict[prev_month_end.date()]\n",
    "\n",
    "    ## Set the start and end date based on the following months\n",
    "    month_start_date = prev_month_end.date() + pd.Timedelta(days=1)\n",
    "    month_end_date = (prev_month_end + pd.offsets.MonthEnd(1)).date()\n",
    "    print(month_start_date, month_end_date, final_month_ticker_list)\n",
    "\n",
    "    eligibility_by_date = build_eligibility_by_date_for_month(\n",
    "            client,\n",
    "            month_start_date=month_start_date,\n",
    "            month_end_date=month_end_date,\n",
    "            lookback_day_count=lookback_day_count,\n",
    "            adv_quantile=adv_quantile, high_low_quantile=high_low_quantile,\n",
    "            max_workers=5, batch_size=12, between_batches_sleep=0.10\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d626d334-de25-4837-b06d-c25a9b502146",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in eligibility_by_date.items():\n",
    "    print(k, len(v), v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6410b9cc-c804-47eb-8f05-b015c73d8cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_ends_between(start_date='2025-01-31', end_date='2025-02-28')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad86fd46-6075-4420-8cec-96d7460efdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible_ticker_dict[pd.Timestamp('2022-03-31').date()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8aeeea-004b-4479-aa33-ca6103b187db",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_month_ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1fb396-c1ac-4639-bb36-9dc2f7627bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_month_open_ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dd74f7-5063-4d1d-a18c-19f49e299bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_ticker_list = [ticker for ticker in prev_month_open_ticker_list if ticker not in final_month_ticker_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4424e7c9-c445-4689-aff3-522f1976f07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8106c839-615e-4427-b914-8ec4f3251624",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_month_ticker_list = final_month_ticker_list + frozen_ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654a69fb-69bf-473f-9d05-0370677ce188",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_month_ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceae33bc-9fae-4014-a2c0-b205cafb8f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7648c41-5236-45f3-9d41-5e4ed5b49765",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_eligible_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216cc6ee-0693-42eb-8e55-00bb3c275322",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_position_notional_cols = [col for col in df_final_1.columns if '_actual_position_notional' in col]\n",
    "actual_position_size_cols = [col for col in df_final_1.columns if '_actual_position_size' in col]\n",
    "open_position_size_list = []\n",
    "for ticker in final_eligible_list:\n",
    "    if df_final_1[f'{ticker}_actual_position_size'].loc[pd.Timestamp(end_date)] > 0:\n",
    "        open_position_size_list.append(ticker)\n",
    "\n",
    "## Create previous months dataframe\n",
    "prev_month_cols = ['date', 'available_cash', 'total_portfolio_value']\n",
    "open_position_size_cols = [f'{ticker}_actual_position_size' for ticker in open_position_size_list]\n",
    "open_position_notional_cols = [f'{ticker}_actual_position_notional' for ticker in open_position_size_list]\n",
    "prev_month_cols = prev_month_cols + open_position_size_cols + open_position_notional_cols\n",
    "df_previous_month_positions = pd.DataFrame(columns=prev_month_cols)\n",
    "df_previous_month_positions.loc[0, 'date'] = pd.Timestamp(end_date)\n",
    "df_previous_month_positions = df_previous_month_positions.set_index('date')\n",
    "df_previous_month_positions.loc[pd.Timestamp(end_date), 'available_cash'] = df_final_1.loc[pd.Timestamp(end_date), 'available_cash']\n",
    "df_previous_month_positions.loc[pd.Timestamp(end_date), 'total_portfolio_value'] = df_final_1.loc[pd.Timestamp(end_date), 'total_portfolio_value']\n",
    "for ticker in open_position_size_list:\n",
    "    df_previous_month_positions.loc[pd.Timestamp(end_date), f'{ticker}_actual_position_notional'] = df_final_1.loc[pd.Timestamp(end_date), f'{ticker}_actual_position_notional']\n",
    "    df_previous_month_positions.loc[pd.Timestamp(end_date), f'{ticker}_actual_position_size'] = df_final_1.loc[pd.Timestamp(end_date), f'{ticker}_actual_position_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4b2750-7db9-46c3-ad7c-e2a79ba0144f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_previous_month_positions.loc[0, 'date'] = pd.Timestamp(end_date)\n",
    "df_previous_month_positions = df_previous_month_positions.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3bcbed-44cf-42cd-b26a-6df5c1c85e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_previous_month_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bbfcca-26cb-4c9e-9945-ddee40e8a99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_previous_month_positions['available_cash'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a40acf-6511-4047-ae1f-8f8edf8d095e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_month_open_ticker_list = [col.split('_')[0] for col in df_previous_month_positions.columns if '_actual_position_notional' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acab0ed-5d6c-40d1-a89f-61b40c7ec8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_month_open_ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001912a2-5dce-4a5a-99fb-182753e38f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04343f85-3768-46f2-8b38-aeef63c6825d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_previous_month_positions.loc[pd.Timestamp(end_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e1fa62-5dc9-4804-b3c2-6c0a7c04ddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48221210-d10d-4bdb-af68-4de4381dbd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Generating Moving Average Ribbon Signal!!')\n",
    "## Generate Trend Signal for all tickers\n",
    "\n",
    "df_trend = get_trend_donchian_signal_for_portfolio_with_rolling_r_sqr_vol_of_vol(\n",
    "    start_date=start_date - pd.Timedelta(days=warmup_days), end_date=end_date, ticker_list=ticker_list, fast_mavg=fast_mavg, slow_mavg=slow_mavg,\n",
    "    mavg_stepsize=mavg_stepsize, mavg_z_score_window=mavg_z_score_window,\n",
    "    entry_rolling_donchian_window=entry_rolling_donchian_window,\n",
    "    exit_rolling_donchian_window=exit_rolling_donchian_window, use_donchian_exit_gate=use_donchian_exit_gate,\n",
    "    ma_crossover_signal_weight=ma_crossover_signal_weight, donchian_signal_weight=donchian_signal_weight,\n",
    "    weighted_signal_ewm_window=weighted_signal_ewm_window, rolling_r2_window=rolling_r2_window,\n",
    "    lower_r_sqr_limit=lower_r_sqr_limit, upper_r_sqr_limit=upper_r_sqr_limit, r2_smooth_window=r2_smooth_window,\n",
    "    r2_confirm_days=r2_confirm_days, log_std_window=log_std_window, coef_of_variation_window=coef_of_variation_window,\n",
    "    vol_of_vol_z_score_window=vol_of_vol_z_score_window, vol_of_vol_p_min=vol_of_vol_p_min,\n",
    "    r2_strong_threshold=r2_strong_threshold, use_activation=use_activation,\n",
    "    tanh_activation_constant_dict=tanh_activation_constant_dict, moving_avg_type=moving_avg_type,\n",
    "    long_only=long_only, price_or_returns_calc=price_or_returns_calc, use_coinbase_data=use_coinbase_data,\n",
    "    use_saved_files=use_saved_files, saved_file_end_date=saved_file_end_date)\n",
    "\n",
    "print('Generating Volatility Adjusted Trend Signal!!')\n",
    "## Get Volatility Adjusted Trend Signal\n",
    "df_signal = size_cont.get_volatility_adjusted_trend_signal_continuous(df_trend, ticker_list, volatility_window,\n",
    "                                                                      annual_trading_days)\n",
    "\n",
    "print('Getting Average True Range for Stop Loss Calculation!!')\n",
    "## Get Average True Range for Stop Loss Calculation\n",
    "df_atr = size_cont.get_average_true_range_portfolio(start_date=start_date, end_date=end_date,\n",
    "                                                    ticker_list=ticker_list, rolling_atr_window=rolling_atr_window,\n",
    "                                                    highest_high_window=highest_high_window,\n",
    "                                                    price_or_returns_calc='price',\n",
    "                                                    use_coinbase_data=use_coinbase_data,\n",
    "                                                    use_saved_files=use_saved_files,\n",
    "                                                    saved_file_end_date=saved_file_end_date)\n",
    "df_signal = pd.merge(df_signal, df_atr, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc572c9b-8f6e-4aa7-9aa7-1622c665616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_signal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f4df28-3017-4596-b412-bddc931ba675",
   "metadata": {},
   "outputs": [],
   "source": [
    "## With R2 Confirm Days = 2\n",
    "df_final_1 = apply_target_volatility_position_sizing_continuous_strategy_with_rolling_r_sqr_vol_of_vol(\n",
    "    start_date=start_date - pd.Timedelta(days=warmup_days), end_date=end_date, ticker_list=final_eligible_list, fast_mavg=fast_mavg, slow_mavg=slow_mavg, mavg_stepsize=mavg_stepsize, mavg_z_score_window=mavg_z_score_window, \n",
    "    entry_rolling_donchian_window=entry_rolling_donchian_window, exit_rolling_donchian_window=exit_rolling_donchian_window, use_donchian_exit_gate=use_donchian_exit_gate, \n",
    "    ma_crossover_signal_weight=ma_crossover_signal_weight, donchian_signal_weight=donchian_signal_weight, weighted_signal_ewm_window=weighted_signal_ewm_window,\n",
    "    rolling_r2_window=rolling_r2_window, lower_r_sqr_limit=lower_r_sqr_limit, upper_r_sqr_limit=upper_r_sqr_limit, r2_smooth_window=r2_smooth_window, r2_confirm_days=2,\n",
    "    log_std_window=log_std_window, coef_of_variation_window=coef_of_variation_window, vol_of_vol_z_score_window=vol_of_vol_z_score_window, vol_of_vol_p_min=vol_of_vol_p_min, r2_strong_threshold=r2_strong_threshold,\n",
    "    use_activation=use_activation, tanh_activation_constant_dict=tanh_activation_constant_dict,\n",
    "    moving_avg_type=moving_avg_type, long_only=long_only, price_or_returns_calc=price_or_returns_calc,\n",
    "    initial_capital=initial_capital, rolling_cov_window=rolling_cov_window, volatility_window=volatility_window,\n",
    "    rolling_atr_window=rolling_atr_window, atr_multiplier=atr_multiplier,\n",
    "    transaction_cost_est=transaction_cost_est, passive_trade_rate=passive_trade_rate,\n",
    "    notional_threshold_pct=notional_threshold_pct, cooldown_counter_threshold=cooldown_counter_threshold,\n",
    "    use_coinbase_data=use_coinbase_data, use_saved_files=False, saved_file_end_date=saved_file_end_date, \n",
    "    rolling_sharpe_window=rolling_sharpe_window, cash_buffer_percentage=cash_buffer_percentage, annualized_target_volatility=annualized_target_volatility,\n",
    "    annual_trading_days=annual_trading_days, use_specific_start_date=use_specific_start_date, signal_start_date=start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e369b6-799c-42bc-bd27-79bac7cb7533",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_position_notional_cols = [f'{ticker}_actual_position_notional']\n",
    "actual_position_notional_cols = [f'{ticker}_actual_position_size']\n",
    "df_final_1[actual_position_notional_cols].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf318f3-65a0-42a1-aa18-e833226aefe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519dce0d-8b20-4517-9644-53717652f7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible_ticker_start_date = pd.Timestamp('2022-04-01').date() - pd.Timedelta(days=warmup_days)\n",
    "eligible_ticker_end_date = pd.Timestamp('2022-04-30').date()\n",
    "eligible_ticker_list = eligible_ticker_dict[pd.Timestamp('2022-03-31').date()]\n",
    "df_trend = get_trend_donchian_signal_for_portfolio_with_rolling_r_sqr_vol_of_vol(\n",
    "    start_date=eligible_ticker_start_date, end_date=eligible_ticker_end_date, ticker_list=eligible_ticker_list, fast_mavg=fast_mavg, slow_mavg=slow_mavg,\n",
    "    mavg_stepsize=mavg_stepsize, mavg_z_score_window=mavg_z_score_window,\n",
    "    entry_rolling_donchian_window=entry_rolling_donchian_window,\n",
    "    exit_rolling_donchian_window=exit_rolling_donchian_window, use_donchian_exit_gate=use_donchian_exit_gate,\n",
    "    ma_crossover_signal_weight=ma_crossover_signal_weight, donchian_signal_weight=donchian_signal_weight,\n",
    "    weighted_signal_ewm_window=weighted_signal_ewm_window, rolling_r2_window=rolling_r2_window,\n",
    "    lower_r_sqr_limit=lower_r_sqr_limit, upper_r_sqr_limit=upper_r_sqr_limit, r2_smooth_window=r2_smooth_window,\n",
    "    r2_confirm_days=r2_confirm_days, log_std_window=log_std_window, coef_of_variation_window=coef_of_variation_window,\n",
    "    vol_of_vol_z_score_window=vol_of_vol_z_score_window, vol_of_vol_p_min=vol_of_vol_p_min,\n",
    "    r2_strong_threshold=r2_strong_threshold, use_activation=use_activation,\n",
    "    tanh_activation_constant_dict=tanh_activation_constant_dict, moving_avg_type=moving_avg_type,\n",
    "    long_only=long_only, price_or_returns_calc=price_or_returns_calc, use_coinbase_data=use_coinbase_data,\n",
    "    use_saved_files=False, saved_file_end_date=saved_file_end_date)\n",
    "\n",
    "print('Generating Volatility Adjusted Trend Signal!!')\n",
    "## Get Volatility Adjusted Trend Signal\n",
    "df_signal = size_cont.get_volatility_adjusted_trend_signal_continuous(df_trend, eligible_ticker_list, volatility_window,\n",
    "                                                                      annual_trading_days)\n",
    "\n",
    "print('Getting Average True Range for Stop Loss Calculation!!')\n",
    "## Get Average True Range for Stop Loss Calculation\n",
    "df_atr = size_cont.get_average_true_range_portfolio(start_date=eligible_ticker_start_date, end_date=eligible_ticker_end_date,\n",
    "                                                    ticker_list=eligible_ticker_list, rolling_atr_window=rolling_atr_window,\n",
    "                                                    highest_high_window=highest_high_window,\n",
    "                                                    price_or_returns_calc='price',\n",
    "                                                    use_coinbase_data=use_coinbase_data,\n",
    "                                                    use_saved_files=False,\n",
    "                                                    saved_file_end_date=saved_file_end_date)\n",
    "df_signal = pd.merge(df_signal, df_atr, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bbb566-e37a-4d10-9880-5ca5b260750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trend.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdd39bf-492c-4ed3-aef6-c3c680420b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_signal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05196feb-f22f-4062-9046-ac4f5fcfa91f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1162a3ea-b04b-4c2f-a181-92b882465445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a384eab-b5ac-497a-8732-2be77267ae92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ab9270-2d54-406d-bc94-23ba45a97f26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafef615-0cfd-4565-956a-2d4e5ece8356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bed6cd-71ef-45c4-9627-5e311d840495",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_eligible_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dcd4fe-78c5-4a4a-b2a1-171a5e06c417",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.Timestamp('2022-04-01').date()\n",
    "end_date = pd.Timestamp('2022-04-30').date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993b5449-8161-43b0-ac7c-a685b31e8971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_asset_level_returns(df, end_date, ticker_list):\n",
    "    ## Check if data is available for all the tickers\n",
    "    # date_list = cn.coinbase_start_date_by_ticker_dict\n",
    "    # ticker_list = [ticker for ticker in ticker_list if pd.Timestamp(date_list[ticker]).date() < end_date]\n",
    "\n",
    "    for ticker in ticker_list:\n",
    "        df[f'{ticker}_daily_pnl'] = (df[f'{ticker}_actual_position_size'] * df[f'{ticker}_open'].diff().shift(-1))\n",
    "        df[f'{ticker}_daily_pct_returns'] = (df[f'{ticker}_daily_pnl'] / df[f'total_portfolio_value'].shift(1)).fillna(\n",
    "            0)\n",
    "        df[f'{ticker}_position_count'] = np.where((df[f'{ticker}_actual_position_notional'] != 0), 1,\n",
    "                                                  0)  ## This is not entirely accurate\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5d6733-cd57-4201-bd38-8705ec134660",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d705aa0c-b48e-4bb2-8996-a3bfb04b49d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## With R2 Confirm Days = 2\n",
    "df_final_1 = apply_target_volatility_position_sizing_continuous_strategy_with_rolling_r_sqr_vol_of_vol(\n",
    "    start_date=start_date - pd.Timedelta(days=warmup_days), end_date=end_date, ticker_list=final_eligible_list, fast_mavg=fast_mavg, slow_mavg=slow_mavg, mavg_stepsize=mavg_stepsize, mavg_z_score_window=mavg_z_score_window, \n",
    "    entry_rolling_donchian_window=entry_rolling_donchian_window, exit_rolling_donchian_window=exit_rolling_donchian_window, use_donchian_exit_gate=use_donchian_exit_gate, \n",
    "    ma_crossover_signal_weight=ma_crossover_signal_weight, donchian_signal_weight=donchian_signal_weight, weighted_signal_ewm_window=weighted_signal_ewm_window,\n",
    "    rolling_r2_window=rolling_r2_window, lower_r_sqr_limit=lower_r_sqr_limit, upper_r_sqr_limit=upper_r_sqr_limit, r2_smooth_window=r2_smooth_window, r2_confirm_days=2,\n",
    "    log_std_window=log_std_window, coef_of_variation_window=coef_of_variation_window, vol_of_vol_z_score_window=vol_of_vol_z_score_window, vol_of_vol_p_min=vol_of_vol_p_min, r2_strong_threshold=r2_strong_threshold,\n",
    "    use_activation=use_activation, tanh_activation_constant_dict=tanh_activation_constant_dict,\n",
    "    moving_avg_type=moving_avg_type, long_only=long_only, price_or_returns_calc=price_or_returns_calc,\n",
    "    initial_capital=initial_capital, rolling_cov_window=rolling_cov_window, volatility_window=volatility_window,\n",
    "    rolling_atr_window=rolling_atr_window, atr_multiplier=atr_multiplier,\n",
    "    transaction_cost_est=transaction_cost_est, passive_trade_rate=passive_trade_rate,\n",
    "    notional_threshold_pct=notional_threshold_pct, cooldown_counter_threshold=cooldown_counter_threshold,\n",
    "    use_coinbase_data=use_coinbase_data, use_saved_files=False, saved_file_end_date=saved_file_end_date, \n",
    "    rolling_sharpe_window=rolling_sharpe_window, cash_buffer_percentage=cash_buffer_percentage, annualized_target_volatility=annualized_target_volatility,\n",
    "    annual_trading_days=annual_trading_days, use_specific_start_date=use_specific_start_date, signal_start_date=start_date)\n",
    "df_final_1 = df_final_1[df_final_1.index >= pd.Timestamp(start_date)]\n",
    "\n",
    "print('Calculating In Sample Asset Returns!!')\n",
    "df_final_1 = calculate_asset_level_returns(df_final_1, end_date, final_eligible_list)\n",
    "\n",
    "portfolio_perf_metrics_1 = calculate_risk_and_performance_metrics(df_final_1, strategy_daily_return_col=f'portfolio_daily_pct_returns',\n",
    "                                                                  strategy_trade_count_col=f'count_of_positions', include_transaction_costs_and_fees=False, passive_trade_rate=0.05, annual_trading_days=365, transaction_cost_est=0.001)\n",
    "portfolio_perf_metrics_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3068a8-78cb-47df-bfe0-183b016b022a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_perf_prod_config_expanded_1 = {}\n",
    "for t in final_eligible_list:\n",
    "    _ticker_perf = perf.calculate_risk_and_performance_metrics(\n",
    "        df_final_1,\n",
    "        strategy_daily_return_col=f'{t}_daily_pct_returns',\n",
    "        strategy_trade_count_col=f'{t}_position_count',\n",
    "        annual_trading_days=365,\n",
    "        include_transaction_costs_and_fees=False\n",
    "    )\n",
    "    ticker_perf_prod_config_expanded_1[t] = _ticker_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898a3129-40b5-4773-bf18-1430af56c36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_perf_prod_config_expanded_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57112a5-9373-4354-8cab-d9e1caf79994",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7326c6-daff-402e-b41e-a728a8caa57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = ELIGIBLE_DIR / f\"2022-04-30_eligible.parquet\"\n",
    "df_eligible_2 = pd.read_parquet(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f809a67b-c920-4f98-a9e6-bf313ac36f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible_ticker_start_date = pd.Timestamp('2022-04-30').date()\n",
    "eligible_ticker_end_date = pd.Timestamp('2022-05-31').date()\n",
    "\n",
    "eligible_ticker_list = df_eligible_2.product_id.unique().tolist()\n",
    "df_trend_eligible_2 = get_trend_donchian_signal_for_portfolio_with_rolling_r_sqr_vol_of_vol(\n",
    "    start_date=eligible_ticker_start_date-pd.Timedelta(days=warmup_days), end_date=eligible_ticker_end_date, ticker_list=eligible_ticker_list, fast_mavg=fast_mavg, slow_mavg=slow_mavg,\n",
    "    mavg_stepsize=mavg_stepsize, mavg_z_score_window=mavg_z_score_window,\n",
    "    entry_rolling_donchian_window=entry_rolling_donchian_window,\n",
    "    exit_rolling_donchian_window=exit_rolling_donchian_window, use_donchian_exit_gate=use_donchian_exit_gate,\n",
    "    ma_crossover_signal_weight=ma_crossover_signal_weight, donchian_signal_weight=donchian_signal_weight,\n",
    "    weighted_signal_ewm_window=weighted_signal_ewm_window, rolling_r2_window=rolling_r2_window,\n",
    "    lower_r_sqr_limit=lower_r_sqr_limit, upper_r_sqr_limit=upper_r_sqr_limit, r2_smooth_window=r2_smooth_window,\n",
    "    r2_confirm_days=r2_confirm_days, log_std_window=log_std_window, coef_of_variation_window=coef_of_variation_window,\n",
    "    vol_of_vol_z_score_window=vol_of_vol_z_score_window, vol_of_vol_p_min=vol_of_vol_p_min,\n",
    "    r2_strong_threshold=r2_strong_threshold, use_activation=use_activation,\n",
    "    tanh_activation_constant_dict=tanh_activation_constant_dict, moving_avg_type=moving_avg_type,\n",
    "    long_only=long_only, price_or_returns_calc=price_or_returns_calc, use_coinbase_data=use_coinbase_data,\n",
    "    use_saved_files=False, saved_file_end_date=saved_file_end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb7a615-0696-4710-8220-9af1b83d22a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible_ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b4c2ae-2223-4e1d-97be-1df4a9c6e7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_signal_cols = [f'{ticker}_final_signal' for ticker in eligible_ticker_list]#[0:11]]\n",
    "date_cond = (df_trend_eligible_2.index >= pd.Timestamp(eligible_ticker_start_date)) & (df_trend_eligible_2.index <= pd.Timestamp(eligible_ticker_end_date))\n",
    "df_trend_eligible_2[date_cond][final_signal_cols].plot(figsize=(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949827d7-bedc-434a-9c19-6e3a81c4229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(eligible_ticker_list))\n",
    "eligible_ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a848a31-0aa4-44af-b2cf-e2507f43cf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cond = (df_trend_eligible_2.index == pd.Timestamp(eligible_ticker_start_date))\n",
    "df_raw_eligible_list = df_trend_eligible_2[date_cond][final_signal_cols].T.reset_index()\n",
    "df_raw_eligible_list.columns = ['ticker', 'final_signal']\n",
    "df_raw_eligible_list = df_raw_eligible_list.sort_values('final_signal', ascending=False)\n",
    "min_strength = np.quantile(df_raw_eligible_list['final_signal'], q=0.8)\n",
    "min_strength_cond = (df_raw_eligible_list['final_signal'] > min_strength)\n",
    "df_raw_eligible_list = df_raw_eligible_list[min_strength_cond]\n",
    "df_raw_eligible_list[\"ticker\"] = df_raw_eligible_list[\"ticker\"].str.replace(r\"_final_signal$\", \"\", regex=True)\n",
    "final_eligible_list_2 = df_raw_eligible_list.ticker.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd69a805-4b38-4f31-b2fb-a7815ebb5d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_eligible_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9da579-6d80-4504-93d8-14f22ec8e479",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_signal_cols = [f'{ticker}_final_signal' for ticker in final_eligible_list_2]\n",
    "date_cond = (df_trend_eligible_2.index >= pd.Timestamp(eligible_ticker_start_date)) & (df_trend_eligible_2.index <= pd.Timestamp(eligible_ticker_end_date))\n",
    "df_trend_eligible_2[date_cond][final_signal_cols].plot(figsize=(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d370317-76f2-41a6-be08-d23bad3b5775",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.Timestamp('2022-05-01').date()\n",
    "end_date = pd.Timestamp('2022-05-31').date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841e8b6e-525e-416a-b936-02e54e9bf91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## With R2 Confirm Days = 2\n",
    "df_final_2 = apply_target_volatility_position_sizing_continuous_strategy_with_rolling_r_sqr_vol_of_vol(\n",
    "    start_date=start_date - pd.Timedelta(days=warmup_days), end_date=end_date, ticker_list=final_eligible_list_2, fast_mavg=fast_mavg, slow_mavg=slow_mavg, mavg_stepsize=mavg_stepsize, mavg_z_score_window=mavg_z_score_window, \n",
    "    entry_rolling_donchian_window=entry_rolling_donchian_window, exit_rolling_donchian_window=exit_rolling_donchian_window, use_donchian_exit_gate=use_donchian_exit_gate, \n",
    "    ma_crossover_signal_weight=ma_crossover_signal_weight, donchian_signal_weight=donchian_signal_weight, weighted_signal_ewm_window=weighted_signal_ewm_window,\n",
    "    rolling_r2_window=rolling_r2_window, lower_r_sqr_limit=lower_r_sqr_limit, upper_r_sqr_limit=upper_r_sqr_limit, r2_smooth_window=r2_smooth_window, r2_confirm_days=2,\n",
    "    log_std_window=log_std_window, coef_of_variation_window=coef_of_variation_window, vol_of_vol_z_score_window=vol_of_vol_z_score_window, vol_of_vol_p_min=vol_of_vol_p_min, r2_strong_threshold=r2_strong_threshold,\n",
    "    use_activation=use_activation, tanh_activation_constant_dict=tanh_activation_constant_dict,\n",
    "    moving_avg_type=moving_avg_type, long_only=long_only, price_or_returns_calc=price_or_returns_calc,\n",
    "    initial_capital=initial_capital, rolling_cov_window=rolling_cov_window, volatility_window=volatility_window,\n",
    "    rolling_atr_window=rolling_atr_window, atr_multiplier=atr_multiplier,\n",
    "    transaction_cost_est=transaction_cost_est, passive_trade_rate=passive_trade_rate,\n",
    "    notional_threshold_pct=notional_threshold_pct, cooldown_counter_threshold=cooldown_counter_threshold,\n",
    "    use_coinbase_data=use_coinbase_data, use_saved_files=False, saved_file_end_date=saved_file_end_date, \n",
    "    rolling_sharpe_window=rolling_sharpe_window, cash_buffer_percentage=cash_buffer_percentage, annualized_target_volatility=annualized_target_volatility,\n",
    "    annual_trading_days=annual_trading_days, use_specific_start_date=use_specific_start_date, signal_start_date=start_date)\n",
    "df_final_2 = df_final_2[df_final_2.index >= pd.Timestamp(start_date)]\n",
    "\n",
    "print('Calculating In Sample Asset Returns!!')\n",
    "df_final_2 = calculate_asset_level_returns(df_final_2, end_date, final_eligible_list_2)\n",
    "\n",
    "portfolio_perf_metrics_2 = calculate_risk_and_performance_metrics(df_final_2, strategy_daily_return_col=f'portfolio_daily_pct_returns',\n",
    "                                                                  strategy_trade_count_col=f'count_of_positions', include_transaction_costs_and_fees=False, passive_trade_rate=0.05, annual_trading_days=365, transaction_cost_est=0.001)\n",
    "portfolio_perf_metrics_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e805563e-ab65-4249-89d5-e7b6f847208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_perf_prod_config_expanded_2 = {}\n",
    "for t in final_eligible_list_2:\n",
    "    _ticker_perf = perf.calculate_risk_and_performance_metrics(\n",
    "        df_final_2,\n",
    "        strategy_daily_return_col=f'{t}_daily_pct_returns',\n",
    "        strategy_trade_count_col=f'{t}_position_count',\n",
    "        annual_trading_days=365,\n",
    "        include_transaction_costs_and_fees=False\n",
    "    )\n",
    "    ticker_perf_prod_config_expanded_2[t] = _ticker_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6bd487-eacd-4a60-a311-47eafeed26b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_perf_prod_config_expanded_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df6677f-8787-419f-94e1-8534568cfabf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becec3da-524d-428f-81f9-505f90cd67c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e976ee-0481-4bba-b17f-7854c856d10a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aaac92-149d-4ef5-bcbc-178ccaeecb82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad42add3-fa77-4621-91b6-e43f653e5c60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f138ed7d-34e2-4108-9039-ace751522feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bd674e-6722-4f89-8dba-3a0bdb98c4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_1 = apply_target_volatility_position_sizing_continuous_strategy_with_rolling_r_sqr_vol_of_vol(\n",
    "    start_date=start_date - pd.Timedelta(days=warmup_days), end_date=end_date, ticker_list=final_eligible_list, fast_mavg=fast_mavg, slow_mavg=slow_mavg, mavg_stepsize=mavg_stepsize, mavg_z_score_window=mavg_z_score_window, \n",
    "    entry_rolling_donchian_window=entry_rolling_donchian_window, exit_rolling_donchian_window=exit_rolling_donchian_window, use_donchian_exit_gate=use_donchian_exit_gate, \n",
    "    ma_crossover_signal_weight=ma_crossover_signal_weight, donchian_signal_weight=donchian_signal_weight, weighted_signal_ewm_window=weighted_signal_ewm_window,\n",
    "    rolling_r2_window=rolling_r2_window, lower_r_sqr_limit=lower_r_sqr_limit, upper_r_sqr_limit=upper_r_sqr_limit, r2_smooth_window=r2_smooth_window, r2_confirm_days=r2_confirm_days,\n",
    "    log_std_window=log_std_window, coef_of_variation_window=coef_of_variation_window, vol_of_vol_z_score_window=vol_of_vol_z_score_window, vol_of_vol_p_min=vol_of_vol_p_min, r2_strong_threshold=r2_strong_threshold,\n",
    "    use_activation=use_activation, tanh_activation_constant_dict=tanh_activation_constant_dict,\n",
    "    moving_avg_type=moving_avg_type, long_only=long_only, price_or_returns_calc=price_or_returns_calc,\n",
    "    initial_capital=initial_capital, rolling_cov_window=rolling_cov_window, volatility_window=volatility_window,\n",
    "    rolling_atr_window=rolling_atr_window, atr_multiplier=atr_multiplier,\n",
    "    transaction_cost_est=transaction_cost_est, passive_trade_rate=passive_trade_rate,\n",
    "    notional_threshold_pct=notional_threshold_pct, cooldown_counter_threshold=cooldown_counter_threshold,\n",
    "    use_coinbase_data=use_coinbase_data, use_saved_files=False, saved_file_end_date=saved_file_end_date, \n",
    "    rolling_sharpe_window=rolling_sharpe_window, cash_buffer_percentage=cash_buffer_percentage, annualized_target_volatility=annualized_target_volatility,\n",
    "    annual_trading_days=annual_trading_days, use_specific_start_date=use_specific_start_date, signal_start_date=start_date)\n",
    "df_final_1 = df_final_1[df_final_1.index >= pd.Timestamp(start_date)]\n",
    "\n",
    "print('Calculating In Sample Asset Returns!!')\n",
    "df_final_1 = calculate_asset_level_returns(df_final_1, end_date, final_eligible_list)\n",
    "\n",
    "portfolio_perf_metrics_1 = calculate_risk_and_performance_metrics(df_final_1, strategy_daily_return_col=f'portfolio_daily_pct_returns',\n",
    "                                                                  strategy_trade_count_col=f'count_of_positions', include_transaction_costs_and_fees=False, passive_trade_rate=0.05, annual_trading_days=365, transaction_cost_est=0.001)\n",
    "portfolio_perf_metrics_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327fd06c-9930-4a64-8ebf-b1283bf5161a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_perf_prod_config_expanded_1 = {}\n",
    "for t in final_eligible_list:\n",
    "    _ticker_perf = perf.calculate_risk_and_performance_metrics(\n",
    "        df_final_1,\n",
    "        strategy_daily_return_col=f'{t}_daily_pct_returns',\n",
    "        strategy_trade_count_col=f'{t}_position_count',\n",
    "        annual_trading_days=365,\n",
    "        include_transaction_costs_and_fees=False\n",
    "    )\n",
    "    ticker_perf_prod_config_expanded_1[t] = _ticker_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b306810b-a991-4095-9997-e02a490128d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_perf_prod_config_expanded_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea374361-6b76-40ed-936e-c60d72f231fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_1['equity_curve'].plot(figsize=(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec61a16a-76e4-424e-9690-ebd5ce620a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_1.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7ae996-79a6-4f3a-9c2c-10ac4ae09bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_trend_signal_cols = [f'{ticker}_final_weighted_additive_signal' for ticker in eligible_ticker_list]\n",
    "final_signal_cols = [f'{ticker}_final_signal' for ticker in eligible_ticker_list]\n",
    "date_cond = (df_trend_eligible.index >= start_date)\n",
    "df_trend_eligible[date_cond][raw_trend_signal_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0140c80-2767-43da-ab51-8f11081fabb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trend_eligible.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4985f1d0-cab3-456c-9aae-4fe877ac3935",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cond = (df_trend_eligible.index <= pd.Timestamp('2022-04-30').date())\n",
    "open_cols = [f'{ticker}' for ticker in ]\n",
    "df_trend_eligible[date_cond]['EOS-USD_open'].plot(figsize=(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b2dd59-26ed-466f-b892-7b5f382c113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trend_eligible[date_cond][raw_trend_signal_cols].loc[start_date].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07717bfd-706a-4059-9f3c-4c4ef31814b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trend_eligible[date_cond][final_signal_cols].loc[start_date].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660d2651-6ce0-4cfb-912c-59347fa2bb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_floor_usd = 2000000\n",
    "median_spread_bps_cap = 25\n",
    "warmup_days_available = True\n",
    "exclusions = ['USDC-USD', 'DAI-USD', 'USDT-USD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c02e810-1d1f-4329-a44b-c82b7a2e3525",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "end_date = '2025-10-24'\n",
    "df_liquidity = pd.DataFrame(columns=['asof_date','product_id','adv_90d_median','high_low_spread_90d_median','warmup_days_available'])\n",
    "for product_id in curr_product_list:\n",
    "    print(product_id)\n",
    "    df = get_liquidity_metrics(client, product_id, asof_date=end_date, lookback_day_count=90)\n",
    "    row = {\n",
    "        'asof_date': end_date,\n",
    "        'product_id': product_id,\n",
    "        'adv_90d_median': df.loc[pd.Timestamp(end_date).date()]['adv_90d_median'],\n",
    "        'high_low_spread_90d_median': df.loc[pd.Timestamp(end_date).date()]['high_low_spread_90d_median'],\n",
    "        'warmup_days_available': has_warmup_coverage(client, product_id=product_id, asof_date=end_date, warmup_days=300)\n",
    "    }\n",
    "    df_liquidity.loc[df_liquidity.shape[0]] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e372a6c6-4361-424a-a839-43282a9fd8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_null_cond = (df_liquidity['adv_90d_median'].notnull())\n",
    "high_low_null_cond = (df_liquidity['high_low_spread_90d_median'].notnull())\n",
    "adv_usd_floor = np.quantile(df_liquidity[adv_null_cond]['adv_90d_median'], q=0.60)\n",
    "high_low_spread_floor = np.quantile(df_liquidity[adv_null_cond]['high_low_spread_90d_median'], q=0.60)\n",
    "exclusions = ['USDC-USD', 'DAI-USD', 'USDT-USD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0371644f-dc5d-45db-9fe9-92b815c40704",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_usd_floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacbb887-7649-4ab7-98fe-690b2daf89e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_low_spread_floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84389c55-f21e-4d23-8f37-1e13f175a25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liquidity[df_liquidity.warmup_days_available].groupby(['asof_date']).agg({'adv_90d_median': ['median','mean','min','max'],\n",
    "                                                                             'high_low_spread_90d_median': ['median','mean','min','max']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df707a1d-5a6e-43c9-a41b-8a425145050c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liquidity[df_liquidity.product_id == 'USDT-USD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402ceec4-8b07-4ef7-8087-637c2ee14209",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusions = ['USDC-USD', 'DAI-USD', 'USDT-USD']\n",
    "eligible_cond = (\n",
    "    (df_liquidity[\"warmup_days_available\"]) &\n",
    "    (df_liquidity[\"adv_90d_median\"] >= adv_usd_floor) &\n",
    "    (df_liquidity[\"high_low_spread_90d_median\"] <= high_low_spread_floor) &\n",
    "    (~df_liquidity['product_id'].isin(exclusions))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a05ec29-e2e9-475e-b468-b91c4402ffb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liquidity[eligible_cond].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fde243-6b3e-488f-b2ef-38fb56e530e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_liquidity[eligible_cond]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536aeb92-e94f-4894-b8e8-18b828aa5d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liquidity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2459a6b-4785-4371-8c47-13f04665353b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liquidity[df_liquidity.warmup_days_available].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2967cc9a-f137-4bc4-8202-bdf00b7c9f23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_liquidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfa8a0a-ad91-4542-8be6-56049c8c853b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liquidity.agg({'adv_90d_median': ['median','mean','min','max']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9069e8-afef-4056-b9a6-f7b4947b61a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = 'XRP-USD'\n",
    "liquidity_day_count = 90\n",
    "end_date = pd.Timestamp('2025-10-24').date()\n",
    "start_date = end_date - pd.Timedelta(days=90)\n",
    "df_ohlc = cn.save_historical_crypto_prices_from_coinbase(ticker=ticker, user_start_date=True, start_date=start_date, end_date=end_date, save_to_file=False, portfolio_name='Default')\n",
    "df_ohlc['adv_90d_median'] = df_ohlc['volume'].rolling(90).median()\n",
    "df_ohlc['high_low_spread_bps'] = (df_ohlc['high'] - df_ohlc['low']) / ((df_ohlc['high'] + df_ohlc['low']) / 2) * 10000\n",
    "df_ohlc['high_low_spread_90d_median'] = df_ohlc['high_low_spread_bps'].rolling(90).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64796a1-e1a5-4846-8ea8-e7af1652a63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohlc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7596e893-cd15-4d79-b37d-f9b2c094c24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohlc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8118a376-b839-40b4-a610-9116c6a11de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ebcc9c-154d-4b2c-8cda-73350a2cdc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# liquidity_metrics.py\n",
    "def compute_adv_and_spread(df_ohlcv, window=90):\n",
    "    \"\"\"\n",
    "    df_ohlcv: Multi-asset daily OHLCV with columns:\n",
    "       ['date','ticker','open','high','low','close','volume']  # volume in base units\n",
    "    Returns per-day per-ticker ADV (USD) and median spread proxy (bps).\n",
    "    \"\"\"\n",
    "    df = df_ohlcv.copy()\n",
    "    df[\"notional_usd\"] = df[\"close\"] * df[\"volume\"]\n",
    "    adv = (df\n",
    "           .groupby(\"ticker\")\n",
    "           .apply(lambda g: g.set_index(\"date\")[\"notional_usd\"]\n",
    "                  .rolling(window, min_periods=max(30, window//3)).median())\n",
    "           .rename(\"adv_usd_median_90\")\n",
    "           .reset_index())\n",
    "\n",
    "    # If you donâ€™t have L1 quotes, use a conservative spread proxy:\n",
    "    df[\"spread_bps_proxy\"] = (df[\"high\"] - df[\"low\"]) / ((df[\"high\"] + df[\"low\"])/2) * 1e4\n",
    "    spr = (df\n",
    "           .groupby(\"ticker\")\n",
    "           .apply(lambda g: g.set_index(\"date\")[\"spread_bps_proxy\"]\n",
    "                  .rolling(window, min_periods=max(30, window//3)).median())\n",
    "           .rename(\"spread_bps_median_90\")\n",
    "           .reset_index())\n",
    "    out = adv.merge(spr, on=[\"ticker\",\"date\"], how=\"outer\")\n",
    "    # history_days (since first valid bar)\n",
    "    first_date = (df.dropna(subset=[\"close\"])\n",
    "                  .groupby(\"ticker\")[\"date\"].min()\n",
    "                  .rename(\"first_date\")\n",
    "                  .reset_index())\n",
    "    out = out.merge(first_date, on=\"ticker\", how=\"left\")\n",
    "    out[\"history_days\"] = (pd.to_datetime(out[\"date\"]) - pd.to_datetime(out[\"first_date\"])).dt.days\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc807ae-056e-40a1-81f9-1776b50fd791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cfc5aa-2be6-4cc7-8ea5-f7196d1a91ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf826ac8-f37d-4b5e-9e41-a5d16af70e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = client.get_products()['products']\n",
    "rows = [product_to_dict(p) for p in prod]\n",
    "df_products = pd.json_normalize(rows)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0f8e8f-58ef-44ca-8dc6-12d57d473c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: keep only columns you care about\n",
    "reqd_cols = [\n",
    "    \"product_id\",\"base_currency_id\",\"quote_currency_id\",\"product_type\",\"status\",\n",
    "    \"trading_disabled\",\"is_disabled\",\"cancel_only\",\"limit_only\",\"post_only\",\"auction_mode\",\"view_only\",\n",
    "    \"base_increment\",\"quote_increment\",\"price_increment\",\"base_min_size\",\"quote_min_size\",\n",
    "    \"alias\",\"alias_to\",\"display_name\",\"product_venue\",\"new_at\",\"price\",\"approximate_quote_24h_volume\"\n",
    "]\n",
    "df_products = df_products[reqd_cols]\n",
    "\n",
    "# optional: coerce numerics\n",
    "for col in [\"base_increment\",\"quote_increment\",\"price_increment\",\"base_min_size\",\"quote_min_size\",\n",
    "            \"price\",\"approximate_quote_24h_volume\"]:\n",
    "    if col in df_products.columns:\n",
    "        df_products[col] = pd.to_numeric(df_products[col], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736ee049-b3b9-46e5-b0a7-9335638ae34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CANON_QUOTE = \"USD\"\n",
    "# Filter to USD spot & tradable\n",
    "filt = (\n",
    "    (df_products[\"product_type\"] == \"SPOT\") &\n",
    "    (df_products[\"quote_currency_id\"] == CANON_QUOTE) &\n",
    "    (df_products[\"status\"] == \"online\") &\n",
    "    (~df_products[\"trading_disabled\"]) &\n",
    "    (~df_products[\"is_disabled\"]) &\n",
    "    (~df_products[\"view_only\"]) &\n",
    "    (~df_products[\"cancel_only\"]) &\n",
    "    (~df_products[\"auction_mode\"])\n",
    ")\n",
    "df_products = df_products[filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4336d95-f898-4ddd-ba00-cb7313d345e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products.groupby(['base_currency_id']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b91072-5e72-467c-bd6a-3969ccb00394",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products.alias_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5be45d-9a87-4fe5-86e5-aefcdd6a4396",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeea574a-ab28-4926-911b-a103123c52ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products[filt].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88f2acb-01c3-4d21-acfd-649ef1ecc329",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_products.trading_disabled.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d555c40-c222-4d3f-a5b9-29e6b3e2037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83670dd7-d3ba-4af3-9e5e-445bedea8068",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7335a3-fbfe-4737-a612-8c6d33e4754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# universe.py\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "PRODUCTS_DIR = Path(\"data_folder/universe/products\")\n",
    "PRODUCTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CANON_QUOTE = \"USD\"\n",
    "\n",
    "def _to_bool(x):\n",
    "    # Coinbase fields come as bools or strings; normalize\n",
    "    if isinstance(x, bool): return x\n",
    "    if x is None: return False\n",
    "    s = str(x).strip().lower()\n",
    "    return s in (\"true\", \"1\", \"yes\")\n",
    "\n",
    "def coinbase_products_snapshot(client, asof=None, save=True):\n",
    "    asof = asof or datetime.now(timezone.utc).date().isoformat()\n",
    "    raw = client.get_products()['products']\n",
    "    df = pd.DataFrame(raw)\n",
    "\n",
    "    # Ensure missing columns exist\n",
    "    for col in [\"alias\",\"alias_to\",\"min_market_funds\"]:\n",
    "        if col not in df.columns: df[col] = None\n",
    "\n",
    "    # Filter to USD spot & tradable\n",
    "    filt = (\n",
    "        (df[\"product_type\"] == \"SPOT\") &\n",
    "        (df[\"quote_currency_id\"] == CANON_QUOTE) &\n",
    "        (df[\"status\"] == \"online\") &\n",
    "        (~df[\"trading_disabled\"].apply(_to_bool)) &\n",
    "        (~df[\"is_disabled\"].apply(_to_bool)) &\n",
    "        (~df[\"view_only\"].apply(_to_bool)) &\n",
    "        (~df[\"cancel_only\"].apply(_to_bool)) &\n",
    "        (~df[\"auction_mode\"].apply(_to_bool))\n",
    "    )\n",
    "    df = df.loc[filt].copy()\n",
    "\n",
    "    # Canonicalize: prefer -USD symbol if aliasing points to it\n",
    "    # Build a map: if row.alias is a valid USD symbol, use alias as canonical id\n",
    "    def canon_pid(row):\n",
    "        alias = (row.get(\"alias\") or \"\").strip()\n",
    "        pid = row[\"product_id\"]\n",
    "        return alias if alias.endswith(\"-USD\") and len(alias) > 0 else pid\n",
    "\n",
    "    df[\"canonical_product_id\"] = df.apply(canon_pid, axis=1)\n",
    "\n",
    "    # Deduplicate on canonical product id, prefer the row whose product_id endswith('-USD')\n",
    "    df[\"prefer_usd_flag\"] = df[\"product_id\"].str.endswith(\"-USD\")\n",
    "    df = (df.sort_values([\"canonical_product_id\",\"prefer_usd_flag\"], ascending=[True, False])\n",
    "            .drop_duplicates(subset=[\"canonical_product_id\"], keep=\"first\"))\n",
    "\n",
    "    # Keep a lean schema for downstream\n",
    "    keep_cols = [\n",
    "        \"canonical_product_id\",\"product_id\",\"base_currency_id\",\"quote_currency_id\",\"product_type\",\"status\",\n",
    "        \"trading_disabled\",\"is_disabled\",\"cancel_only\",\"limit_only\",\"post_only\",\"auction_mode\",\"view_only\",\n",
    "        \"base_increment\",\"quote_increment\",\"price_increment\",\"base_min_size\",\"quote_min_size\",\"min_market_funds\",\n",
    "        \"alias\",\"alias_to\",\"display_name\",\"product_venue\",\"new_at\"\n",
    "    ]\n",
    "    df = df[keep_cols].rename(columns={\"canonical_product_id\":\"ticker\"})\n",
    "\n",
    "    # Coerce numerics where helpful\n",
    "    for col in [\"base_increment\",\"quote_increment\",\"price_increment\",\"base_min_size\",\"quote_min_size\",\"min_market_funds\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    df[\"asof_date\"] = pd.to_datetime(asof).date()\n",
    "\n",
    "    if save:\n",
    "        out = PRODUCTS_DIR / f\"{asof}.parquet\"\n",
    "        df.to_parquet(out, index=False)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bedd463-b538-4266-8fd2-c8a3132a0885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3f0dc6-f322-4ea7-8960-d6da5b351c88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79865bcd-a0e1-42e1-ba9b-7652733173a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382e976c-2ca3-49f7-b4e1-179297b96f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5f6d30-ae49-4a30-bc78-8f28652e654c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6842fed1-382b-498e-b48c-57233bacb17f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6b49d9-1774-4ba4-a7b9-11515e579f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5b23ce-a1c1-4e49-8544-e460e0f0d7b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0585fbc9-3cfe-46dc-851b-e958238d8026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c94f9e-c08f-44b3-a220-ac532fd49f31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4e1a3d-39b2-4680-b176-507a538ccf50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d57cdb7-e59a-4027-9d65-b1c9e71c263e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f213f1-c8f4-410f-a6f5-f0677a6fc662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a43e5bf-4747-4cb5-9c3a-99cfaf38d56a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87240c36-db5d-4be3-b95c-6143873333c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdfbe06-c92b-4cd3-af87-655c597995a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35efa32-dd52-4bc2-9059-fe38e23157a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
