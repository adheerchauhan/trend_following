{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fcdcc8e-b598-4212-a74d-9eb7daa0415c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary modules\n",
    "import os\n",
    "import sys\n",
    "import os, sys\n",
    "# from .../research/notebooks -> go up two levels to repo root\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.insert(0, repo_root)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as mtick\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score \n",
    "import pandas_datareader as pdr\n",
    "import math\n",
    "import datetime as dt\n",
    "from datetime import datetime, timezone\n",
    "import itertools\n",
    "import ast\n",
    "import yfinance as yf\n",
    "import seaborn as sn\n",
    "import yaml\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from IPython.display import display, HTML\n",
    "from strategy_signal.trend_following_signal import (\n",
    "    apply_jupyter_fullscreen_css, get_trend_donchian_signal_for_portfolio_with_rolling_r_sqr_vol_of_vol\n",
    ")\n",
    "from portfolio.strategy_performance import (calculate_sharpe_ratio, calculate_calmar_ratio, calculate_CAGR, calculate_risk_and_performance_metrics,\n",
    "                                          calculate_compounded_cumulative_returns, estimate_fee_per_trade, rolling_sharpe_ratio)\n",
    "from utils import coinbase_utils as cn\n",
    "from portfolio import strategy_performance as perf\n",
    "from sizing import position_sizing_binary_utils as size_bin\n",
    "from sizing import position_sizing_continuous_utils as size_cont\n",
    "from strategy_signal import trend_following_signal as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00567546-10fb-4153-9703-f46ce0bbb7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'sizing.position_sizing_continuous_utils' from '/Users/adheerchauhan/git/trend_following/sizing/position_sizing_continuous_utils.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(cn)\n",
    "importlib.reload(perf)\n",
    "importlib.reload(tf)\n",
    "importlib.reload(size_bin)\n",
    "importlib.reload(size_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da5f829f-4a79-4fc4-88e4-37e4ba8cfffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>:root {\n",
       "    --jp-notebook-max-width: 100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('Display.max_rows', None)\n",
    "pd.set_option('Display.max_columns',None)\n",
    "apply_jupyter_fullscreen_css()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e48cd6b-1f2a-4b30-85f8-4f7e183cfcc2",
   "metadata": {},
   "source": [
    "## Coinbase Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b7f00b5-8dec-4055-8f6a-aec7ccc3b81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coinbase_historical_price_data(\n",
    "    client,\n",
    "    ticker,\n",
    "    start_timestamp,\n",
    "    end_timestamp,\n",
    "    granularity=\"ONE_DAY\",\n",
    "    retries=3,\n",
    "    delay=5,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generic candle puller for Coinbase Advanced Trade RESTClient.get_candles().\n",
    "\n",
    "    granularity examples:\n",
    "      ONE_MINUTE, FIVE_MINUTE, FIFTEEN_MINUTE, THIRTY_MINUTE,\n",
    "      ONE_HOUR, TWO_HOUR, FOUR_HOUR, SIX_HOUR, ONE_DAY\n",
    "    \"\"\"\n",
    "    attempts = 0\n",
    "    while attempts < retries:\n",
    "        try:\n",
    "            candle_list = client.get_candles(\n",
    "                product_id=ticker,\n",
    "                start=int(start_timestamp),\n",
    "                end=int(end_timestamp),\n",
    "                granularity=granularity,\n",
    "            ).candles\n",
    "\n",
    "            if not candle_list:\n",
    "                cols = [\"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "                return pd.DataFrame(columns=cols).rename_axis(\"date\")\n",
    "\n",
    "            candle_data = []\n",
    "            for c in candle_list:\n",
    "                candle_data.append(\n",
    "                    {\n",
    "                        \"date\": c[\"start\"],  # epoch seconds\n",
    "                        \"low\": float(c[\"low\"]),\n",
    "                        \"high\": float(c[\"high\"]),\n",
    "                        \"open\": float(c[\"open\"]),\n",
    "                        \"close\": float(c[\"close\"]),\n",
    "                        \"volume\": float(c[\"volume\"]),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            df = pd.DataFrame(candle_data)\n",
    "            if df.empty or \"date\" not in df.columns:\n",
    "                cols = [\"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "                return pd.DataFrame(columns=cols).rename_axis(\"date\")\n",
    "\n",
    "            # epoch seconds -> tz-aware UTC -> drop tz (tz-naive UTC)\n",
    "            s = pd.to_datetime(pd.to_numeric(df[\"date\"], errors=\"coerce\"), unit=\"s\", utc=True).dt.tz_localize(None)\n",
    "\n",
    "            # Only normalize for daily bars; keep intraday timestamps intact\n",
    "            if granularity == \"ONE_DAY\":\n",
    "                s = s.dt.normalize()\n",
    "\n",
    "            df[\"date\"] = s\n",
    "            df = df.set_index(\"date\").sort_index().rename_axis(\"date\")\n",
    "\n",
    "            return df\n",
    "\n",
    "        except requests.exceptions.ConnectionError as e:\n",
    "            print(f\"Connection error: {e}. Retrying in {delay} seconds...\")\n",
    "            attempts += 1\n",
    "            time.sleep(delay)\n",
    "\n",
    "    raise Exception(\"Max retries exceeded. Could not connect to Coinbase API.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0178e89e-d302-44b8-a845-a48f2cf92d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_historical_crypto_prices_from_coinbase(\n",
    "    ticker,\n",
    "    user_start_date=False,\n",
    "    start_date=None,\n",
    "    end_date=None,\n",
    "    save_to_file=False,\n",
    "    portfolio_name=\"Default\",\n",
    "    granularity=\"ONE_DAY\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Pull historical candles for a single ticker at the requested granularity.\n",
    "\n",
    "    Note: Coinbase candle endpoints have request caps (commonly 300 candles per call),\n",
    "    so we chunk requests.\n",
    "    \"\"\"\n",
    "    client = cn.get_coinbase_rest_api_client(portfolio_name=portfolio_name)\n",
    "\n",
    "    if user_start_date:\n",
    "        start_date = pd.Timestamp(start_date)\n",
    "    else:\n",
    "        start_date = cn.coinbase_start_date_by_ticker_dict.get(ticker)\n",
    "        start_date = pd.Timestamp(start_date)\n",
    "        if start_date is None:\n",
    "            print(f\"Start date for {ticker} is not included in the dictionary!\")\n",
    "            return None\n",
    "\n",
    "    end_date = pd.Timestamp(end_date)\n",
    "\n",
    "    # seconds per bar (used to step chunks without gaps)\n",
    "    granularity_to_seconds = {\n",
    "        \"ONE_MINUTE\": 60,\n",
    "        \"FIVE_MINUTE\": 300,\n",
    "        \"FIFTEEN_MINUTE\": 900,\n",
    "        \"THIRTY_MINUTE\": 1800,\n",
    "        \"ONE_HOUR\": 3600,\n",
    "        \"TWO_HOUR\": 7200,\n",
    "        \"FOUR_HOUR\": 14400,\n",
    "        \"SIX_HOUR\": 21600,\n",
    "        \"ONE_DAY\": 86400,\n",
    "    }\n",
    "    bar_sec = granularity_to_seconds.get(granularity)\n",
    "    if bar_sec is None:\n",
    "        raise ValueError(f\"Unsupported granularity: {granularity}\")\n",
    "\n",
    "    # Keep your old 6-week chunking (works great for ONE_DAY and FOUR_HOUR),\n",
    "    # but ensure we never step by +1 day when doing intraday.\n",
    "    temp_start = start_date\n",
    "    current_end = temp_start\n",
    "\n",
    "    dfs = []\n",
    "    while current_end < end_date:\n",
    "        # 6 weeks is safe for FOUR_HOUR (≈252 candles) under the typical 300 limit :contentReference[oaicite:1]{index=1}\n",
    "        current_end = pd.to_datetime(temp_start) + dt.timedelta(weeks=6)\n",
    "        if current_end > end_date:\n",
    "            current_end = end_date\n",
    "\n",
    "        start_ts = int(pd.Timestamp(temp_start).timestamp())\n",
    "        end_ts = int(pd.Timestamp(current_end).timestamp())\n",
    "\n",
    "        df_chunk = get_coinbase_historical_price_data(\n",
    "            client=client,\n",
    "            ticker=ticker,\n",
    "            start_timestamp=start_ts,\n",
    "            end_timestamp=end_ts,\n",
    "            granularity=granularity,\n",
    "        )\n",
    "        dfs.append(df_chunk)\n",
    "\n",
    "        # advance by exactly one bar to avoid duplicates and avoid gaps\n",
    "        temp_start = pd.to_datetime(current_end) + pd.Timedelta(seconds=bar_sec)\n",
    "\n",
    "    if not dfs:\n",
    "        cols = [\"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "        return pd.DataFrame(columns=cols).rename_axis(\"date\")\n",
    "\n",
    "    df = pd.concat(dfs, axis=0)\n",
    "    df = df[~df.index.duplicated(keep=\"last\")].sort_index()\n",
    "\n",
    "    # optional: save_to_file logic can stay as you had it (not shown in your snippet)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "423131ab-a74b-4cc2-8d05-5541a8404d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "cn_ticker_list = cn.coinbase_start_date_by_ticker_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b083b70-5483-4153-b16f-91fa84a25bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BTC-USD': '2016-01-01',\n",
       " 'ETH-USD': '2016-06-01',\n",
       " 'SOL-USD': '2021-06-01',\n",
       " 'ADA-USD': '2021-03-01',\n",
       " 'AVAX-USD': '2021-09-01',\n",
       " 'DOT-USD': '2021-06-01',\n",
       " 'ATOM-USD': '2020-01-01',\n",
       " 'LTC-USD': '2016-09-01',\n",
       " 'XRP-USD': '2023-06-01',\n",
       " 'ALGO-USD': '2019-08-01',\n",
       " 'XLM-USD': '2019-02-01',\n",
       " 'TON-USD': '2025-11-18',\n",
       " 'NEAR-USD': '2022-09-01',\n",
       " 'ICP-USD': '2021-05-10',\n",
       " 'HBAR-USD': '2022-10-13',\n",
       " 'SUI-USD': '2023-05-18',\n",
       " 'CRO-USD': '2021-11-01',\n",
       " 'APT-USD': '2022-10-19',\n",
       " 'XTZ-USD': '2019-08-06',\n",
       " 'EGLD-USD': '2022-12-07',\n",
       " 'FIL-USD': '2020-12-09',\n",
       " 'SEI-USD': '2023-08-15',\n",
       " 'TIA-USD': '2023-11-01',\n",
       " 'KAVA-USD': '2023-01-19',\n",
       " 'ROSE-USD': '2022-04-26',\n",
       " 'MATIC-USD': '2021-02-01',\n",
       " 'SKL-USD': '2021-02-01',\n",
       " 'OP-USD': '2022-06-01',\n",
       " 'ARB-USD': '2023-03-23',\n",
       " 'POL-USD': '2024-09-04',\n",
       " 'IMX-USD': '2021-12-09',\n",
       " 'STRK-USD': '2024-02-21',\n",
       " 'BLAST-USD': '2024-06-26',\n",
       " 'ZK-USD': '2024-09-25',\n",
       " 'LRC-USD': '2020-09-15',\n",
       " 'ZORA-USD': '2025-04-24',\n",
       " 'METIS-USD': '2022-06-28',\n",
       " 'STX-USD': '2022-01-20',\n",
       " 'DOGE-USD': '2021-06-01',\n",
       " 'SHIB-USD': '2021-08-01',\n",
       " 'LINK-USD': '2019-06-01',\n",
       " 'FET-USD': '2021-07-01',\n",
       " 'GRT-USD': '2020-12-01',\n",
       " 'RNDR-USD': '2022-02-03',\n",
       " 'OXT-USD': '2019-12-01',\n",
       " 'AIOZ-USD': '2022-02-01',\n",
       " 'MOBILE-USD': '2024-02-01',\n",
       " 'HNT-USD': '2023-06-01',\n",
       " 'DIA-USD': '2022-01-25',\n",
       " 'KRL-USD': '2021-10-01',\n",
       " 'ZRO-USD': '2024-06-01',\n",
       " 'USDT-USD': '2021-05-04',\n",
       " 'DAI-USD': '2020-04-01',\n",
       " 'USD1-USD': '2025-08-21',\n",
       " 'PAX-USD': '2021-07-27',\n",
       " 'UNI-USD': '2020-09-01',\n",
       " 'AAVE-USD': '2020-12-01',\n",
       " 'AMP-USD': '2021-05-01',\n",
       " 'COMP-USD': '2020-06-23',\n",
       " 'LDO-USD': '2022-11-17',\n",
       " 'MKR-USD': '2020-06-09',\n",
       " 'SNX-USD': '2020-12-15',\n",
       " 'INJ-USD': '2022-09-20',\n",
       " 'SUSHI-USD': '2021-03-11',\n",
       " 'CRV-USD': '2021-03-25',\n",
       " 'BAL-USD': '2020-10-06',\n",
       " '1INCH-USD': '2021-04-09',\n",
       " 'RPL-USD': '2022-12-08',\n",
       " 'RSR-USD': '2025-04-22',\n",
       " 'ONDO-USD': '2024-01-22',\n",
       " 'ETHFI-USD': '2025-02-06',\n",
       " 'MANA-USD': '2021-04-01',\n",
       " 'REQ-USD': '2021-07-01',\n",
       " 'HONEY-USD': '2024-01-01'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn_ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b00e938a-db29-447c-9641-642609dfdaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_list = []\n",
    "exclude_list = ['USDT-USD','DAI-USD','USD1-USD','PAX-USD','MATIC-USD']\n",
    "for ticker, date in cn_ticker_list.items():\n",
    "    if (pd.Timestamp(cn_ticker_list[ticker]).date() <= pd.Timestamp('2022-04-01').date()) & (ticker not in exclude_list):\n",
    "        ticker_list.append(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9203fc37-e687-43c4-8562-af4e9d7f5150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['BTC-USD',\n",
       " 'ETH-USD',\n",
       " 'SOL-USD',\n",
       " 'ADA-USD',\n",
       " 'AVAX-USD',\n",
       " 'DOT-USD',\n",
       " 'ATOM-USD',\n",
       " 'LTC-USD',\n",
       " 'ALGO-USD',\n",
       " 'XLM-USD',\n",
       " 'ICP-USD',\n",
       " 'CRO-USD',\n",
       " 'XTZ-USD',\n",
       " 'FIL-USD',\n",
       " 'SKL-USD',\n",
       " 'IMX-USD',\n",
       " 'LRC-USD',\n",
       " 'STX-USD',\n",
       " 'DOGE-USD',\n",
       " 'SHIB-USD',\n",
       " 'LINK-USD',\n",
       " 'FET-USD',\n",
       " 'GRT-USD',\n",
       " 'RNDR-USD',\n",
       " 'OXT-USD',\n",
       " 'AIOZ-USD',\n",
       " 'DIA-USD',\n",
       " 'KRL-USD',\n",
       " 'UNI-USD',\n",
       " 'AAVE-USD',\n",
       " 'AMP-USD',\n",
       " 'COMP-USD',\n",
       " 'MKR-USD',\n",
       " 'SNX-USD',\n",
       " 'SUSHI-USD',\n",
       " 'CRV-USD',\n",
       " 'BAL-USD',\n",
       " '1INCH-USD',\n",
       " 'MANA-USD',\n",
       " 'REQ-USD']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(ticker_list))\n",
    "ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69ce5580-931a-477a-8b27-33c7600edbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coinbase_price_data_for_ticker_list(start_date, end_date, ticker_list, fill_missing=True):\n",
    "\n",
    "    df_dict_by_ticker = {}\n",
    "    ticker_list_len = len(ticker_list)\n",
    "    loop_start = 0\n",
    "    loop_end = 0\n",
    "    counter = 0\n",
    "    while counter < ticker_list_len:\n",
    "        loop_start = counter\n",
    "        if counter == 40:\n",
    "            loop_end = ticker_list_len\n",
    "        else:\n",
    "            loop_end = counter + 10\n",
    "        print(counter, loop_start, loop_end, ticker_list[loop_start: loop_end])\n",
    "        for t in ticker_list[loop_start: loop_end]:\n",
    "            df_dict_by_ticker[t] = save_historical_crypto_prices_from_coinbase(\n",
    "                ticker=t,\n",
    "                user_start_date=True,\n",
    "                start_date=start_date,\n",
    "                end_date=end_date,\n",
    "                portfolio_name=\"Default\",\n",
    "                granularity=\"FOUR_HOUR\",\n",
    "            )\n",
    "        counter += 10\n",
    "    \n",
    "    # Optional: one combined frame (MultiIndex: ticker, date)\n",
    "    df_all = pd.concat(df_dict_by_ticker, names=[\"ticker\", \"date\"]).sort_index()\n",
    "\n",
    "    # --- build expected 4H grid ---\n",
    "    start = pd.Timestamp(start_date).floor(\"4H\")\n",
    "    end = pd.Timestamp(end_date).ceil(\"4H\")\n",
    "    expected_dates = pd.date_range(start=start, end=end, freq=\"4H\")#, inclusive=\"left\")\n",
    "\n",
    "    full_index = pd.MultiIndex.from_product(\n",
    "        [ticker_list, expected_dates],\n",
    "        names=[\"ticker\", \"date\"]\n",
    "    )\n",
    "\n",
    "    # --- align everything to full grid ---\n",
    "    df_all = df_all.reindex(full_index)\n",
    "\n",
    "    # --- flag missing bars ---\n",
    "    df_all[\"imputed\"] = df_all[\"close\"].isna()\n",
    "\n",
    "    if fill_missing:\n",
    "        # Forward-fill ONLY close per ticker (for alignment / valuation)\n",
    "        df_all[\"close\"] = df_all.groupby(level=0)[\"close\"].ffill()\n",
    "\n",
    "        # For imputed rows: set OHLC = close, volume=0\n",
    "        m = df_all[\"imputed\"]\n",
    "        for col in [\"open\", \"high\", \"low\"]:\n",
    "            df_all.loc[m, col] = df_all.loc[m, \"close\"]\n",
    "        df_all.loc[m, \"volume\"] = 0.0\n",
    "\n",
    "    # if you want a flat frame:\n",
    "    df_all = df_all.reset_index()\n",
    "\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4665c5b2-34ec-4bc2-aa8a-618d1a9fb5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 μs, sys: 1 μs, total: 4 μs\n",
      "Wall time: 6.91 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_date = \"2022-04-01\"\n",
    "end_date   = \"2024-12-31\"\n",
    "# df_ticker_price_impute = get_coinbase_price_data_for_ticker_list(start_date, end_date, ticker_list, fill_missing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330c937d-35eb-49e5-baf5-8dc39ccd678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save Files to Parquet for later use\n",
    "df_ticker_price_impute.to_parquet(\n",
    "    f\"/Users/adheerchauhan/git/trend_following/data_folder/coinbase_4_min_bar_data/coinbase_ohlcv_4min_{start_date}-{end_date}.parquet\",\n",
    "    index=False,\n",
    "    compression=\"zstd\",  # great balance of size + speed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1be116c9-4808-42ac-a86a-79251da988ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read Parquet Files\n",
    "df_ticker_price_impute = pd.read_parquet(f\"/Users/adheerchauhan/git/trend_following/data_folder/coinbase_4_min_bar_data/coinbase_ohlcv_4min_{start_date}-{end_date}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ac733d0-a74d-41cd-8802-e3096d770a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>imputed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BTC-USD</td>\n",
       "      <td>2022-04-01 00:00:00</td>\n",
       "      <td>44232.86</td>\n",
       "      <td>45655.42</td>\n",
       "      <td>45525.25</td>\n",
       "      <td>44614.99</td>\n",
       "      <td>4498.191859</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BTC-USD</td>\n",
       "      <td>2022-04-01 04:00:00</td>\n",
       "      <td>44554.06</td>\n",
       "      <td>45115.70</td>\n",
       "      <td>44612.73</td>\n",
       "      <td>45030.70</td>\n",
       "      <td>1866.920775</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BTC-USD</td>\n",
       "      <td>2022-04-01 08:00:00</td>\n",
       "      <td>45009.73</td>\n",
       "      <td>45338.35</td>\n",
       "      <td>45030.71</td>\n",
       "      <td>45082.74</td>\n",
       "      <td>1735.690901</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BTC-USD</td>\n",
       "      <td>2022-04-01 12:00:00</td>\n",
       "      <td>44722.00</td>\n",
       "      <td>46739.24</td>\n",
       "      <td>45081.52</td>\n",
       "      <td>46545.39</td>\n",
       "      <td>5000.839037</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BTC-USD</td>\n",
       "      <td>2022-04-01 16:00:00</td>\n",
       "      <td>45906.00</td>\n",
       "      <td>46607.89</td>\n",
       "      <td>46545.31</td>\n",
       "      <td>46390.69</td>\n",
       "      <td>3498.550271</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker                date       low      high      open     close  \\\n",
       "0  BTC-USD 2022-04-01 00:00:00  44232.86  45655.42  45525.25  44614.99   \n",
       "1  BTC-USD 2022-04-01 04:00:00  44554.06  45115.70  44612.73  45030.70   \n",
       "2  BTC-USD 2022-04-01 08:00:00  45009.73  45338.35  45030.71  45082.74   \n",
       "3  BTC-USD 2022-04-01 12:00:00  44722.00  46739.24  45081.52  46545.39   \n",
       "4  BTC-USD 2022-04-01 16:00:00  45906.00  46607.89  46545.31  46390.69   \n",
       "\n",
       "        volume  imputed  \n",
       "0  4498.191859    False  \n",
       "1  1866.920775    False  \n",
       "2  1735.690901    False  \n",
       "3  5000.839037    False  \n",
       "4  3498.550271    False  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ticker_price_impute.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c68ac7d6-e623-4a48-bdb4-02f2e73ca9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(241240, 8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ticker_price_impute.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4c4631d-2419-4462-8fe8-6e01ccbbc96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticker\n",
       "1INCH-USD    6031\n",
       "AAVE-USD     6031\n",
       "ADA-USD      6031\n",
       "AIOZ-USD     6031\n",
       "ALGO-USD     6031\n",
       "AMP-USD      6031\n",
       "ATOM-USD     6031\n",
       "AVAX-USD     6031\n",
       "BAL-USD      6031\n",
       "BTC-USD      6031\n",
       "COMP-USD     6031\n",
       "CRO-USD      6031\n",
       "CRV-USD      6031\n",
       "DIA-USD      6031\n",
       "DOGE-USD     6031\n",
       "DOT-USD      6031\n",
       "ETH-USD      6031\n",
       "FET-USD      6031\n",
       "FIL-USD      6031\n",
       "GRT-USD      6031\n",
       "ICP-USD      6031\n",
       "IMX-USD      6031\n",
       "KRL-USD      6031\n",
       "LINK-USD     6031\n",
       "LRC-USD      6031\n",
       "LTC-USD      6031\n",
       "MANA-USD     6031\n",
       "MKR-USD      6031\n",
       "OXT-USD      6031\n",
       "REQ-USD      6031\n",
       "RNDR-USD     6031\n",
       "SHIB-USD     6031\n",
       "SKL-USD      6031\n",
       "SNX-USD      6031\n",
       "SOL-USD      6031\n",
       "STX-USD      6031\n",
       "SUSHI-USD    6031\n",
       "UNI-USD      6031\n",
       "XLM-USD      6031\n",
       "XTZ-USD      6031\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ticker_price_impute.groupby(['ticker']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c9c4b1-79fd-4506-9865-875d3f26a523",
   "metadata": {},
   "source": [
    "## Backtesting Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6dfc3634-1151-48e8-9d58-7eb95f6b4bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_fee_per_trade_w_enable_switch(passive_trade_rate=0.5, maker_fee=0.006, taker_fee=0.012, enable_fees=True):\n",
    "    if not enable_fees:\n",
    "        return 0.0\n",
    "    proportion_maker = passive_trade_rate\n",
    "    proportion_taker = (1 - passive_trade_rate)\n",
    "    return (maker_fee * proportion_maker) + (taker_fee * proportion_taker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a9f08640-5d8d-4d99-98ea-ec3e2dcec02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# NEW: Turnover helpers\n",
    "# -----------------------------\n",
    "TURNOVER_COLS = [\n",
    "    \"buy_notional_gross\",\n",
    "    \"sell_notional_gross\",\n",
    "    \"gross_traded_notional\",\n",
    "    \"turnover_pct\",\n",
    "    \"turnover_pct_half\",\n",
    "    \"buy_turnover_pct\",\n",
    "    \"sell_turnover_pct\",\n",
    "]\n",
    "\n",
    "def ensure_turnover_cols_in_df(df_portfolio: pd.DataFrame) -> pd.DataFrame:\n",
    "    for c in TURNOVER_COLS:\n",
    "        if c not in df_portfolio.columns:\n",
    "            df_portfolio[c] = 0.0\n",
    "            \n",
    "    return df_portfolio\n",
    "\n",
    "def reset_turnover_for_period(df_portfolio: pd.DataFrame, period) -> pd.DataFrame:\n",
    "    for c in TURNOVER_COLS:\n",
    "        df_portfolio.loc[period, c] = 0.0\n",
    "\n",
    "    return df_portfolio\n",
    "\n",
    "def finalize_turnover_metrics(df_portfolio: pd.DataFrame, period) -> pd.DataFrame:\n",
    "    pv = float(df_portfolio.loc[period, \"total_portfolio_value\"])\n",
    "    gross = float(df_portfolio.loc[period, \"gross_traded_notional\"])\n",
    "    buys = float(df_portfolio.loc[period, \"buy_notional_gross\"])\n",
    "    sells = float(df_portfolio.loc[period, \"sell_notional_gross\"])\n",
    "\n",
    "    if pv > 0:\n",
    "        df_portfolio.loc[period, \"turnover_pct\"] = gross / pv\n",
    "        df_portfolio.loc[period, \"turnover_pct_half\"] = gross / (2.0 * pv)\n",
    "        df_portfolio.loc[period, \"buy_turnover_pct\"] = buys / pv\n",
    "        df_portfolio.loc[period, \"sell_turnover_pct\"] = sells / pv\n",
    "    else:\n",
    "        df_portfolio.loc[period, \"turnover_pct\"] = 0.0\n",
    "        df_portfolio.loc[period, \"turnover_pct_half\"] = 0.0\n",
    "        df_portfolio.loc[period, \"buy_turnover_pct\"] = 0.0\n",
    "        df_portfolio.loc[period, \"sell_turnover_pct\"] = 0.0\n",
    "\n",
    "    return df_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8ccfe462-88a2-472c-a3eb-1060cf5be970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll_portfolio_positions(df_portfolio: pd.DataFrame, current_period) -> pd.DataFrame:\n",
    "    current_period = pd.Timestamp(current_period)\n",
    "\n",
    "    cols = [\n",
    "        \"total_position_notional\",\n",
    "        \"available_cash\",\n",
    "        \"total_portfolio_value\",\n",
    "        \"total_portfolio_value_upper_limit\",\n",
    "    ]\n",
    "\n",
    "    last_vals = df_portfolio.iloc[-1][cols]\n",
    "\n",
    "    # Ensure the row exists, then assign all columns at once\n",
    "    if current_period not in df_portfolio.index:\n",
    "        df_portfolio.loc[current_period, cols] = pd.NA\n",
    "\n",
    "    df_portfolio.loc[current_period, cols] = last_vals.values\n",
    "\n",
    "    ## Reset Turnover for New Period\n",
    "    reset_turnover_for_period(df_portfolio, period=current_period)\n",
    "    \n",
    "    return df_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f75342d2-e4a2-47cb-91b5-a9e62aa4c262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_deployable_cash(df_portfolio, period, cash_buffer_percentage):\n",
    "\n",
    "    ## Total Portfolio Value\n",
    "    pv = float(df_portfolio.loc[period, \"total_portfolio_value\"])\n",
    "\n",
    "    ## Cash Buffer to keep prior to taking positions\n",
    "    desired_cash = pv * cash_buffer_percentage\n",
    "\n",
    "    ## Available Cash to be deployed for new positions\n",
    "    avail_cash = float(df_portfolio.loc[period, \"available_cash\"])\n",
    "    deployable_cash = max(0.0, avail_cash - desired_cash)\n",
    "    \n",
    "    return deployable_cash\n",
    "\n",
    "\n",
    "def compute_gross_to_deploy_target_per_vintage(df_portfolio, period, cash_buffer_percentage, fwd_return_period):\n",
    "    \"\"\"\n",
    "    NEW: deploy ~1/fwd_return_period of the *target invested* notional each bar (subject to buffer + available cash).\n",
    "\n",
    "    target_total_invested = PV * (1 - buffer)\n",
    "    target_per_vintage    = target_total_invested / fwd_return_period\n",
    "\n",
    "    max_deploy_now        = max(0, available_cash - PV*buffer)\n",
    "    gross_to_deploy       = min(target_per_vintage, max_deploy_now)\n",
    "    \"\"\"\n",
    "    ## Total Portfolio Value\n",
    "    pv = float(df_portfolio.loc[period, \"total_portfolio_value\"])\n",
    "\n",
    "    ## Available Cash\n",
    "    avail_cash = float(df_portfolio.loc[period, \"available_cash\"])\n",
    "\n",
    "    ## Cash Buffer to keep prior to taking positions\n",
    "    desired_cash = pv * cash_buffer_percentage\n",
    "    deployable_cash = max(0.0, avail_cash - desired_cash)\n",
    "\n",
    "    ## Target Invested per Vintage\n",
    "    target_total_invested = pv * (1.0 - cash_buffer_percentage)\n",
    "    target_per_vintage = target_total_invested / float(fwd_return_period)\n",
    "    gross_to_deploy = min(target_per_vintage, deployable_cash)\n",
    "    \n",
    "    return float(gross_to_deploy)\n",
    "\n",
    "\n",
    "def open_new_vintage_positions(\n",
    "    df_position, df_portfolio, df_signal, period,\n",
    "    fwd_return_period, cash_buffer_percentage,\n",
    "    transaction_cost_est, passive_trade_rate, enable_fees,\n",
    "    vintage_name, signal_col='trade_signal_exec'\n",
    "):\n",
    "    \n",
    "    df_signal_working = df_signal.copy()\n",
    "    signal_current_period_cond = (df_signal_working[\"date\"] == period)\n",
    "\n",
    "    ## Get Estimated T-Cost\n",
    "    # est_fees = (transaction_cost_est + perf.estimate_fee_per_trade(passive_trade_rate))\n",
    "    est_fees = (transaction_cost_est + estimate_fee_per_trade_w_enable_switch(passive_trade_rate=passive_trade_rate, enable_fees=enable_fees))\n",
    "\n",
    "    ## Calculate cash budget available to be deployed for new positions\n",
    "    deployable_cash = compute_deployable_cash(df_portfolio, period, cash_buffer_percentage)\n",
    "    gross_to_deploy = compute_gross_to_deploy_target_per_vintage(\n",
    "        df_portfolio=df_portfolio,\n",
    "        period=period,\n",
    "        cash_buffer_percentage=cash_buffer_percentage,\n",
    "        fwd_return_period=fwd_return_period,\n",
    "    )\n",
    "\n",
    "    ## Get the updated signal for current period\n",
    "    non_zero_position_cond = (df_signal_working[signal_col].fillna(0).astype(float) != 0.0)\n",
    "    picks = df_signal_working.loc[signal_current_period_cond & non_zero_position_cond].copy()\n",
    "    n = len(picks)\n",
    "    if n == 0 or gross_to_deploy <= 0:\n",
    "        return df_position, df_portfolio\n",
    "\n",
    "    ## Update Trade Weights for current period\n",
    "    # NOTE: it's now informational only; sizing uses gross_to_deploy / n below.\n",
    "    picks[\"position_weight\"] = 1.0 / (fwd_return_period * n)\n",
    "\n",
    "    # -----------------------------\n",
    "    # CHANGE #3: allocate target-per-vintage gross equally across selected names\n",
    "    # -----------------------------\n",
    "    picks[\"trade_notional_gross\"] = gross_to_deploy / float(n)\n",
    "\n",
    "    picks[\"position_notional\"] = picks[\"trade_notional_gross\"] * (1 - est_fees)\n",
    "    picks[\"position_size\"] = picks[\"position_notional\"] / picks[\"open\"]\n",
    "    picks[\"vintage_id\"] = vintage_name\n",
    "    picks[\"holding_period_counter\"] = 1.0\n",
    "\n",
    "    ## Append the Current Period Signal Dataframe for the Vintage to the Daily Positions Dataframe\n",
    "    df_position = pd.concat([df_position, picks], ignore_index=True)\n",
    "\n",
    "    ## Update Portfolio Cash based on new positions\n",
    "    cash_usage = float(picks[\"trade_notional_gross\"].sum())\n",
    "    df_portfolio.loc[period, \"available_cash\"] = float(df_portfolio.loc[period, \"available_cash\"]) - cash_usage\n",
    "\n",
    "    # NEW: turnover accounting (buys)\n",
    "    df_portfolio = ensure_turnover_cols_in_df(df_portfolio)\n",
    "    df_portfolio.loc[period, \"buy_notional_gross\"] = float(df_portfolio.loc[period, \"buy_notional_gross\"]) + cash_usage\n",
    "    df_portfolio.loc[period, \"gross_traded_notional\"] = float(df_portfolio.loc[period, \"gross_traded_notional\"]) + cash_usage\n",
    "\n",
    "    ## Update Portfolio Positions by Net Notional\n",
    "    df_portfolio.loc[period, \"total_position_notional\"] = float(df_portfolio.loc[period, \"total_position_notional\"]) + float(picks[\"position_notional\"].sum())\n",
    "    df_portfolio.loc[period, \"total_portfolio_value\"] = float(df_portfolio.loc[period, \"available_cash\"]) + float(df_portfolio.loc[period, \"total_position_notional\"])\n",
    "    df_portfolio.loc[period, \"total_portfolio_value_upper_limit\"] = float(df_portfolio.loc[period, \"total_portfolio_value\"]) * (1 - cash_buffer_percentage)\n",
    "\n",
    "    return df_position, df_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e161c83e-69a6-437d-ac71-dcbeaf6d00a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_open_vintage_positions(df_position, df_portfolio, df_signal, current_period, prior_period, cash_buffer_percentage, vintage_name):\n",
    "    \"\"\"\n",
    "    Roll/mark-to-market positions that were open in `vintage_name` from prior_period to current_period.\n",
    "\n",
    "    Fixes vs your original:\n",
    "    - Maps prior positions by (date, vintage_id, ticker) so you never accidentally pull from another vintage.\n",
    "    - Avoids per-ticker loops; uses merge/map which is faster + safer.\n",
    "    - Updates holding counter robustly (max across vintage rows) instead of values[0] from an arbitrary row.\n",
    "    - Updates portfolio total_position_notional by the *delta* in this vintage's mark-to-market.\n",
    "    - Leaves cash unchanged (correct for MTM-only step).\n",
    "    \"\"\"\n",
    "\n",
    "    current_period = pd.Timestamp(current_period)\n",
    "    prior_period = pd.Timestamp(prior_period)\n",
    "\n",
    "    ## Get Vintage Position Data for Prior Period\n",
    "    notional_cond = (df_position['position_notional'] > 0)\n",
    "    prior_vintage = df_position.loc[\n",
    "        (df_position[\"date\"] == prior_period) & (df_position[\"vintage_id\"] == vintage_name) & (notional_cond)\n",
    "    ].copy()\n",
    "\n",
    "    ## If there is no Vintage data from the prior period, exit as there is nothing to update.\n",
    "    if prior_vintage.empty:\n",
    "        return df_position, df_portfolio\n",
    "\n",
    "    ## Keep only one row per ticker (should already be one; this guards against accidental duplicates)\n",
    "    prior_vintage = (\n",
    "        prior_vintage.sort_values([\"ticker\"])\n",
    "        .drop_duplicates(subset=[\"ticker\"], keep=\"last\")\n",
    "    )\n",
    "\n",
    "    prior_tickers = prior_vintage[\"ticker\"].tolist()\n",
    "\n",
    "    ## Get current period rows from signal dataframe for Vintage tickers\n",
    "    cur_rows = df_signal.loc[\n",
    "        (df_signal[\"date\"] == current_period) & (df_signal[\"ticker\"].isin(prior_tickers))\n",
    "    ].copy()\n",
    "\n",
    "    ## If for some reason df_signal is missing current_period rows for some tickers, drop them.\n",
    "    if cur_rows.empty:\n",
    "        return df_position, df_portfolio\n",
    "\n",
    "    ## Create a map of the Position Size and Weight by ticker from the prior period\n",
    "    prior_map = prior_vintage.set_index(\"ticker\")[[\"position_size\", \"position_weight\"]]\n",
    "\n",
    "    ## Map the Weight and Position Size from the Prior Period to the Current Period\n",
    "    cur_rows[\"position_size\"] = cur_rows[\"ticker\"].map(prior_map[\"position_size\"])\n",
    "    cur_rows[\"position_weight\"] = cur_rows[\"ticker\"].map(prior_map[\"position_weight\"])\n",
    "\n",
    "    ## Drop any tickers we failed to map (should not happen unless data is inconsistent)\n",
    "    cur_rows = cur_rows.dropna(subset=[\"position_size\", \"position_weight\"])\n",
    "\n",
    "    ## Mark all positions to the current open\n",
    "    cur_rows[\"position_notional\"] = cur_rows[\"position_size\"] * cur_rows[\"open\"]\n",
    "    cur_rows[\"vintage_id\"] = vintage_name\n",
    "\n",
    "    ## Update the Holding Counter\n",
    "    prior_counter = prior_vintage[\"holding_period_counter\"].max()\n",
    "    cur_rows[\"holding_period_counter\"] = prior_counter + 1\n",
    "\n",
    "    ## Append to positions table\n",
    "    df_position = pd.concat([df_position, cur_rows], axis=0, ignore_index=True)\n",
    "\n",
    "    ## Update portfolio MTM for this vintage (cash unchanged)\n",
    "    prior_vintage_notional = prior_vintage[\"position_notional\"].sum()\n",
    "    cur_vintage_notional = cur_rows[\"position_notional\"].sum()\n",
    "    delta_notional = cur_vintage_notional - prior_vintage_notional\n",
    "\n",
    "    df_portfolio.loc[current_period, \"total_position_notional\"] = (\n",
    "        df_portfolio.loc[current_period, \"total_position_notional\"] + delta_notional\n",
    "    )\n",
    "    df_portfolio.loc[current_period, \"total_portfolio_value\"] = (\n",
    "        df_portfolio.loc[current_period, \"available_cash\"]\n",
    "        + df_portfolio.loc[current_period, \"total_position_notional\"]\n",
    "    )\n",
    "    df_portfolio.loc[current_period, \"total_portfolio_value_upper_limit\"] = (\n",
    "        df_portfolio.loc[current_period, \"total_portfolio_value\"] * (1 - cash_buffer_percentage)\n",
    "    )\n",
    "\n",
    "    return df_position, df_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9e9d95f6-c171-4994-a3ac-49fce89f9634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exit_open_vintage_positions(df_position, df_portfolio, df_signal, current_period, prior_period, transaction_cost_est, passive_trade_rate, enable_fees, \n",
    "                                cash_buffer_percentage, vintage_name):\n",
    "    \"\"\"\n",
    "    Exits (closes) all open positions for a given vintage at the CURRENT_PERIOD open,\n",
    "    using position sizes from the PRIOR_PERIOD for that same vintage.\n",
    "\n",
    "    Key fixes vs your version:\n",
    "      - Avoids modifying a filtered slice (SettingWithCopy) by building a .copy() frame for exits.\n",
    "      - Uses a ticker->position_size mapping from df_position (scalar per ticker) and merges via .map().\n",
    "      - Handles duplicates safely (keeps last by date ordering) and empty cases gracefully.\n",
    "    \"\"\"\n",
    "\n",
    "    # Work on copies to avoid side effects\n",
    "    df_signal_working = df_signal.copy()\n",
    "\n",
    "    # --- Conditions ---\n",
    "    position_current_period_cond = (df_position[\"date\"] == current_period)\n",
    "    position_prior_period_cond = (df_position[\"date\"] == prior_period)\n",
    "    signal_current_period_cond = (df_signal_working[\"date\"] == current_period)\n",
    "    vintage_cond = (df_position[\"vintage_id\"] == vintage_name)\n",
    "\n",
    "    # --- Estimated total fees/slippage model ---\n",
    "    # est_fees = (transaction_cost_est + perf.estimate_fee_per_trade(passive_trade_rate))\n",
    "    est_fees = (transaction_cost_est + estimate_fee_per_trade_w_enable_switch(passive_trade_rate=passive_trade_rate, enable_fees=enable_fees))\n",
    "\n",
    "    # --- Identify tickers that were open in the prior period for this vintage ---\n",
    "    prior_vintage_positions = df_position.loc[position_prior_period_cond & vintage_cond, [\"ticker\", \"position_size\", \"position_notional\"]].copy()\n",
    "\n",
    "    if prior_vintage_positions.empty:\n",
    "        # Nothing to exit; return unchanged\n",
    "        return df_position, df_portfolio\n",
    "\n",
    "    # If df_position can contain multiple rows per ticker for the same date/vintage,\n",
    "    # keep the last one deterministically.\n",
    "    prior_vintage_positions = (\n",
    "        prior_vintage_positions\n",
    "        .dropna(subset=[\"ticker\"])\n",
    "        .drop_duplicates(subset=[\"ticker\"], keep=\"last\")\n",
    "    )\n",
    "\n",
    "    non_zero_tickers_prior_period = prior_vintage_positions[\"ticker\"].tolist()\n",
    "\n",
    "    # --- Build exit frame for current period (copy, so we can mutate safely) ---\n",
    "    mask_exit = signal_current_period_cond & df_signal_working[\"ticker\"].isin(non_zero_tickers_prior_period)\n",
    "    df_signal_current_period = df_signal_working.loc[mask_exit].copy()\n",
    "\n",
    "    if df_signal_current_period.empty:\n",
    "        # No signal rows for these tickers at current_period; cannot mark/exit\n",
    "        return df_position, df_portfolio\n",
    "\n",
    "    # --- Map prior position sizes into current period rows ---\n",
    "    ticker_to_size = prior_vintage_positions.set_index(\"ticker\")[\"position_size\"]\n",
    "    df_signal_current_period[\"position_size\"] = df_signal_current_period[\"ticker\"].map(ticker_to_size)\n",
    "\n",
    "    # If any tickers didn't map (shouldn't happen), set them to 0 and ignore in exit\n",
    "    df_signal_current_period[\"position_size\"] = df_signal_current_period[\"position_size\"].fillna(0.0)\n",
    "\n",
    "    # --- Compute exit notional net of fees (sell at open) ---\n",
    "    df_signal_current_period[\"position_notional\"] = (\n",
    "        df_signal_current_period[\"position_size\"] * df_signal_current_period[\"open\"]\n",
    "    )\n",
    "\n",
    "    prior_period_position_notional = float(prior_vintage_positions['position_notional'].sum())\n",
    "    current_mtm_position_notional = float(df_signal_current_period[\"position_notional\"].sum())\n",
    "    exit_net_position_notional = float(df_signal_current_period[\"position_notional\"].sum()) * (1 - est_fees)\n",
    "\n",
    "    # --- Update portfolio accounting ---\n",
    "    # Ensure portfolio rows exist\n",
    "    if current_period not in df_portfolio.index:\n",
    "        raise KeyError(f\"current_period {current_period} not found in df_portfolio.index\")\n",
    "    if \"total_position_notional\" not in df_portfolio.columns or \"available_cash\" not in df_portfolio.columns:\n",
    "        raise KeyError(\"df_portfolio missing required columns: total_position_notional, available_cash\")\n",
    "\n",
    "    ## Capture the Mark to Market from Previous Open to Current Open prior to exiting the position\n",
    "    df_portfolio.loc[current_period, \"total_position_notional\"] = (\n",
    "        df_portfolio.loc[current_period, \"total_position_notional\"] + (current_mtm_position_notional - prior_period_position_notional)\n",
    "    )\n",
    "\n",
    "    ## Capture the Bookeeping related to Exiting the Vintage\n",
    "    # Hear we sell the current position notional but in the available cash, we capture the notional net of transaction costs\n",
    "    df_portfolio.loc[current_period, \"total_position_notional\"] = (\n",
    "        df_portfolio.loc[current_period, \"total_position_notional\"] - current_mtm_position_notional\n",
    "    )\n",
    "    df_portfolio.loc[current_period, \"available_cash\"] = (\n",
    "        df_portfolio.loc[current_period, \"available_cash\"] + exit_net_position_notional\n",
    "    )\n",
    "\n",
    "    ## Capture the Turnover Accounting\n",
    "    df_portfolio = ensure_turnover_cols_in_df(df_portfolio)\n",
    "    df_portfolio.loc[current_period, \"sell_notional_gross\"] = (\n",
    "        float(df_portfolio.loc[current_period, \"sell_notional_gross\"]) + current_mtm_position_notional\n",
    "    )\n",
    "    df_portfolio.loc[current_period, \"gross_traded_notional\"] = (\n",
    "        float(df_portfolio.loc[current_period, \"gross_traded_notional\"]) + current_mtm_position_notional\n",
    "    )\n",
    "\n",
    "    ## Re-calculate the Total Portfolio Value and Upper Limit based on the Updated Portfolio\n",
    "    df_portfolio.loc[current_period, \"total_portfolio_value\"] = (\n",
    "        df_portfolio.loc[current_period, \"available_cash\"] + df_portfolio.loc[current_period, \"total_position_notional\"]\n",
    "    )\n",
    "    df_portfolio.loc[current_period, \"total_portfolio_value_upper_limit\"] = (\n",
    "        df_portfolio.loc[current_period, \"total_portfolio_value\"] * (1 - cash_buffer_percentage)\n",
    "    )\n",
    "\n",
    "    # --- Append \"closed\" rows to df_position for audit trail ---\n",
    "    # Set post-exit state fields\n",
    "    df_signal_current_period[\"position_notional\"] = 0.0\n",
    "    df_signal_current_period[\"position_size\"] = 0.0\n",
    "    df_signal_current_period[\"position_weight\"] = 0.0\n",
    "    df_signal_current_period[\"vintage_id\"] = vintage_name\n",
    "    df_signal_current_period[\"holding_period_counter\"] = 0\n",
    "\n",
    "    # If df_position expects certain columns, align them\n",
    "    for col in df_position.columns:\n",
    "        if col not in df_signal_current_period.columns:\n",
    "            df_signal_current_period[col] = np.nan\n",
    "\n",
    "    df_signal_current_period = df_signal_current_period[df_position.columns]\n",
    "\n",
    "    df_position_out = pd.concat([df_position, df_signal_current_period], axis=0, ignore_index=True)\n",
    "\n",
    "    return df_position_out, df_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ffc725c5-385b-4476-83e7-e11fad64dcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mean_reversion_backtest(df_signal, fwd_return_period, initial_capital, cash_buffer_percentage, transaction_cost_est, passive_trade_rate, enable_fees, \n",
    "                                signal_col='trade_signal_exec'):\n",
    "\n",
    "    ## Get a list of all the periods in the signal dataframe\n",
    "    period_list = sorted(df_signal.date.unique())\n",
    "\n",
    "    if len(period_list) < 4:\n",
    "        raise ValueError(\"Need at least 4 periods in df_signal to run this backtest.\")\n",
    "\n",
    "    ## Define the position weight per signal\n",
    "    daily_weight_allocation = 1 / fwd_return_period # (kept for now; not used directly below)\n",
    "\n",
    "    ## Initialize first positions in the signal dataframe\n",
    "    df_signal = df_signal.copy()\n",
    "    df_signal['position_weight'] = 0.0\n",
    "    df_signal['position_notional'] = 0.0\n",
    "    df_signal['position_size'] = 0.0\n",
    "    df_signal['holding_period_counter'] = 0.0\n",
    "    df_signal['vintage_id'] = np.nan\n",
    "    \n",
    "    ## Estimated T-Cost\n",
    "    # est_fees = (transaction_cost_est + perf.estimate_fee_per_trade(passive_trade_rate))\n",
    "    est_fees = (transaction_cost_est + estimate_fee_per_trade_w_enable_switch(passive_trade_rate=passive_trade_rate, enable_fees=enable_fees))\n",
    "    \n",
    "    ## Initialized Position and Portfolio Dataframes\n",
    "    portfolio_columns = [\n",
    "        'total_position_notional',\n",
    "        'available_cash',\n",
    "        'total_portfolio_value',\n",
    "        'total_portfolio_value_upper_limit',\n",
    "        'buy_notional_gross',\n",
    "        'sell_notional_gross',\n",
    "        'gross_traded_notional',\n",
    "        'turnover_pct',\n",
    "        'turnover_pct_half',\n",
    "        'buy_turnover_pct',\n",
    "        'sell_turnover_pct'\n",
    "    ]\n",
    "    df_portfolio = pd.DataFrame(columns=portfolio_columns)\n",
    "    df_portfolio.index.name = 'date'\n",
    "    df_position = pd.DataFrame(columns=df_signal.columns.tolist())\n",
    "\n",
    "    ## Initialize the Cash and Portfolio Value prior to processing positions\n",
    "    first_period = period_list[1]\n",
    "    second_period = period_list[2]\n",
    "    third_period = period_list[3]\n",
    "    \n",
    "    ## Initialize Daily Portfolio Positions prior to processing positions\n",
    "    df_portfolio.loc[first_period, 'total_position_notional'] = 0.0\n",
    "    df_portfolio.loc[first_period, 'available_cash'] = float(initial_capital)\n",
    "    df_portfolio.loc[first_period, 'total_portfolio_value'] = float(initial_capital)\n",
    "    df_portfolio.loc[first_period, 'total_portfolio_value_upper_limit'] = float(initial_capital) * (1 - cash_buffer_percentage)\n",
    "\n",
    "    ## Initialize Turnover Columns\n",
    "    df_portfolio = reset_turnover_for_period(df_portfolio, period=first_period)\n",
    "\n",
    "    run_counter = 0\n",
    "    run_counter_check = np.arange(0, len(period_list), 100).tolist()\n",
    "    for i, current_period in enumerate(period_list[1:1000], start=1):\n",
    "        if run_counter in run_counter_check:\n",
    "            print(run_counter)\n",
    "        prior_period = period_list[i - 1]\n",
    "    \n",
    "        ## Filtering Conditions\n",
    "        signal_current_period_cond = (df_signal.date == current_period)\n",
    "        df_signal_current_period = df_signal.loc[signal_current_period_cond].copy()\n",
    "    \n",
    "        if current_period > first_period:\n",
    "            df_portfolio = roll_portfolio_positions(df_portfolio, current_period=current_period)\n",
    "    \n",
    "        if current_period == first_period:\n",
    "            ## Open New Positions for Vintage 1\n",
    "            df_position, df_portfolio = open_new_vintage_positions(\n",
    "                df_position=df_position, df_portfolio=df_portfolio, df_signal=df_signal_current_period,\n",
    "                period=current_period, fwd_return_period=fwd_return_period, cash_buffer_percentage=cash_buffer_percentage,\n",
    "                transaction_cost_est=transaction_cost_est, passive_trade_rate=passive_trade_rate, enable_fees=enable_fees, vintage_name='Vintage_1', signal_col=signal_col)\n",
    "    \n",
    "        elif current_period == second_period:\n",
    "            ## Update Positions from Vintage 1\n",
    "            df_position, df_portfolio = update_open_vintage_positions(\n",
    "                df_position=df_position, df_portfolio=df_portfolio, df_signal=df_signal_current_period,\n",
    "                current_period=current_period, prior_period=prior_period, cash_buffer_percentage=cash_buffer_percentage, vintage_name='Vintage_1')\n",
    "    \n",
    "            ## Open New Positions for Vintage 2\n",
    "            df_position, df_portfolio = open_new_vintage_positions(\n",
    "                df_position=df_position, df_portfolio=df_portfolio, df_signal=df_signal_current_period,\n",
    "                period=current_period, fwd_return_period=fwd_return_period, cash_buffer_percentage=cash_buffer_percentage,\n",
    "                transaction_cost_est=transaction_cost_est, passive_trade_rate=passive_trade_rate, enable_fees=enable_fees, vintage_name='Vintage_2', signal_col=signal_col)\n",
    "    \n",
    "        elif current_period == third_period:\n",
    "            ## Update Positions from Vintage 1\n",
    "            df_position, df_portfolio = update_open_vintage_positions(\n",
    "                df_position=df_position, df_portfolio=df_portfolio, df_signal=df_signal_current_period,\n",
    "                current_period=current_period, prior_period=prior_period, cash_buffer_percentage=cash_buffer_percentage, vintage_name='Vintage_1')\n",
    "    \n",
    "            ## Update Positions from Vintage 2\n",
    "            df_position, df_portfolio = update_open_vintage_positions(\n",
    "                df_position=df_position, df_portfolio=df_portfolio, df_signal=df_signal_current_period,\n",
    "                current_period=current_period, prior_period=prior_period, cash_buffer_percentage=cash_buffer_percentage, vintage_name='Vintage_2')\n",
    "    \n",
    "            ## Open New Positions for Vintage 3\n",
    "            df_position, df_portfolio = open_new_vintage_positions(\n",
    "                df_position=df_position, df_portfolio=df_portfolio, df_signal=df_signal_current_period,\n",
    "                period=current_period, fwd_return_period=fwd_return_period, cash_buffer_percentage=cash_buffer_percentage,\n",
    "                transaction_cost_est=transaction_cost_est, passive_trade_rate=passive_trade_rate, enable_fees=enable_fees, vintage_name='Vintage_3', signal_col=signal_col)\n",
    "    \n",
    "        else:\n",
    "            vintage_list = df_position['vintage_id'].unique().tolist()\n",
    "            for vintage in vintage_list:\n",
    "                if pd.isna(vintage):\n",
    "                    continue\n",
    "                    \n",
    "                vintage_cond = (df_position['vintage_id'] == vintage)\n",
    "                ## Get the Holding Period Counter for the Vintage\n",
    "                prior_vals = df_position.loc[(df_position.date == prior_period) & vintage_cond, 'holding_period_counter']\n",
    "                if prior_vals.empty:\n",
    "                    previous_period_holding_counter = 0\n",
    "                else:\n",
    "                    previous_period_holding_counter = prior_vals.max()\n",
    "                    if pd.isna(previous_period_holding_counter):\n",
    "                        previous_period_holding_counter = 0\n",
    "                    previous_period_holding_counter = int(previous_period_holding_counter)\n",
    "                \n",
    "                if previous_period_holding_counter >= fwd_return_period:\n",
    "                    ## Exit all open positions in current period\n",
    "                    df_position, df_portfolio = exit_open_vintage_positions(\n",
    "                        df_position=df_position, df_portfolio=df_portfolio, df_signal=df_signal_current_period,\n",
    "                        current_period=current_period, prior_period=prior_period, transaction_cost_est=transaction_cost_est, passive_trade_rate=passive_trade_rate, enable_fees=enable_fees,\n",
    "                        cash_buffer_percentage=cash_buffer_percentage, vintage_name=vintage)\n",
    "                    ## Open New Positions for Vintage that just exited\n",
    "                    df_position, df_portfolio = open_new_vintage_positions(\n",
    "                        df_position=df_position, df_portfolio=df_portfolio, df_signal=df_signal_current_period,\n",
    "                        period=current_period, fwd_return_period=fwd_return_period, cash_buffer_percentage=cash_buffer_percentage,\n",
    "                        transaction_cost_est=transaction_cost_est, passive_trade_rate=passive_trade_rate, enable_fees=enable_fees, vintage_name=vintage, signal_col=signal_col)\n",
    "                    \n",
    "                elif 1 <= previous_period_holding_counter <= (fwd_return_period - 1):\n",
    "                    ## Update Positions from Vintage\n",
    "                    df_position, df_portfolio = update_open_vintage_positions(\n",
    "                        df_position=df_position, df_portfolio=df_portfolio, df_signal=df_signal_current_period,\n",
    "                        current_period=current_period, prior_period=prior_period, cash_buffer_percentage=cash_buffer_percentage, vintage_name=vintage)\n",
    "\n",
    "                else:# previous_period_holding_counter == 0:\n",
    "                    ## Open New Positions for Vintage\n",
    "                    df_position, df_portfolio = open_new_vintage_positions(\n",
    "                        df_position=df_position, df_portfolio=df_portfolio, df_signal=df_signal_current_period,\n",
    "                        period=current_period, fwd_return_period=fwd_return_period, cash_buffer_percentage=cash_buffer_percentage,\n",
    "                        transaction_cost_est=transaction_cost_est, passive_trade_rate=passive_trade_rate, enable_fees=enable_fees, vintage_name=vintage, signal_col=signal_col)\n",
    "                    \n",
    "        ## Compute Turnover Ratios once per bar for the updated portfolio\n",
    "        df_portfolio = ensure_turnover_cols_in_df(df_portfolio)\n",
    "        df_portfolio = finalize_turnover_metrics(df_portfolio, current_period)\n",
    "        run_counter += 1\n",
    "\n",
    "    return df_position, df_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a81e399-ff16-4fee-8b60-28f394c5f2db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12de5e2f-a337-4a90-a761-941b1f11b8d7",
   "metadata": {},
   "source": [
    "## Signal Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0975f135-7d5b-4182-bbfe-cfdfc9148a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_z_score(df, return_col, date_col, z_score_col_name):\n",
    "\n",
    "    return_mean = df.groupby([date_col])[return_col].transform('mean')\n",
    "    return_std = df.groupby([date_col])[return_col].transform('std').replace(0, np.nan)\n",
    "    df[z_score_col_name] = (df[return_col] - return_mean) / return_std\n",
    "\n",
    "    return df\n",
    "    \n",
    "\n",
    "def build_return_features(df, min_z_score_ticker_count=20, fwd_return_period=3, winsorize_fwd_return=True, fwd_return_cap=0.50):\n",
    "\n",
    "    df_returns = df.copy()\n",
    "\n",
    "    ## Get Previous 4 hour returns\n",
    "    ticker_group_close = df_returns.groupby(['ticker'])['close']\n",
    "    df_returns['close_log_return_prev_4h'] = np.log(ticker_group_close.shift(1) / ticker_group_close.shift(2))\n",
    "\n",
    "    ## Require a minimum number of tickers to calculate Z-Score for a given bar\n",
    "    ticker_count_by_date = df_returns.groupby(['date'])['ticker'].transform('nunique')\n",
    "    df_returns = df_returns[ticker_count_by_date >= min_z_score_ticker_count]\n",
    "\n",
    "    ## Calculate cross-sectional Z-Score across all tickers per bar\n",
    "    df_returns = calculate_z_score(df_returns, return_col='close_log_return_prev_4h', date_col='date', z_score_col_name='close_log_return_z_score_prev_4h')\n",
    "\n",
    "    ## Get forward return for specified period (Open(T) to Open(T+H))\n",
    "    df_returns[f'fwd_open_log_return_{fwd_return_period * 4}h'] = np.log(df_returns.groupby(['ticker'])['open'].shift(-fwd_return_period) / df_returns['open'])\n",
    "\n",
    "    ## Winsorize Forward Return to reduce data glitches\n",
    "    if winsorize_fwd_return:\n",
    "        df_returns[f'fwd_open_log_return_{fwd_return_period * 4}h'] = df_returns[f'fwd_open_log_return_{fwd_return_period * 4}h'].clip(-fwd_return_cap, fwd_return_cap)\n",
    "\n",
    "    return df_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc07bc8-74bd-4ae6-a8ca-d4fcb824f7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_btc_residual_returns(\n",
    "    df: pd.DataFrame,\n",
    "    btc_ticker: str = \"BTC-USD\",\n",
    "    date_col: str = \"date\",\n",
    "    ticker_col: str = \"ticker\",\n",
    "    ret_col: str = \"close_log_return_prev_4h\",\n",
    "    lookback_days: int = 30,\n",
    "    min_obs_days: int = 10,\n",
    "    bars_per_day: int = 6,\n",
    "    lag_params: bool = True,\n",
    "    var_floor: float = 1e-12,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds rolling BTC-factor residual returns for each ticker:\n",
    "        resid = r_i - (alpha + beta * r_btc)\n",
    "\n",
    "    Uses rolling OLS with intercept over lookback window (in bars).\n",
    "    If lag_params=True, alpha/beta are shifted by 1 bar to avoid lookahead.\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "    out[date_col] = pd.to_datetime(out[date_col])\n",
    "    out = out.sort_values([ticker_col, date_col])\n",
    "\n",
    "    lookback_bars = int(lookback_days * bars_per_day)\n",
    "    min_periods = int(min_obs_days * bars_per_day)\n",
    "\n",
    "    # --- Pull BTC returns by timestamp and merge onto all rows ---\n",
    "    btc = (\n",
    "        out.loc[out[ticker_col] == btc_ticker, [date_col, ret_col]]\n",
    "        .drop_duplicates(subset=[date_col])\n",
    "        .rename(columns={ret_col: \"btc_ret\"})\n",
    "        .sort_values(date_col)\n",
    "    )\n",
    "\n",
    "    out = out.merge(btc, on=date_col, how=\"left\")\n",
    "\n",
    "    # Initialize columns\n",
    "    out[\"beta_btc\"] = np.nan\n",
    "    out[\"alpha_btc\"] = np.nan\n",
    "    out[\"resid_btc_prev_4h\"] = np.nan\n",
    "\n",
    "    # --- Compute rolling alpha/beta/resid per non-BTC ticker ---\n",
    "    non_btc_mask = out[ticker_col] != btc_ticker\n",
    "\n",
    "    def _per_ticker(g: pd.DataFrame) -> pd.DataFrame:\n",
    "        g = g.sort_values(date_col).copy()\n",
    "        y = g[ret_col].astype(float)\n",
    "        x = g[\"btc_ret\"].astype(float)\n",
    "\n",
    "        # rolling moments\n",
    "        mx  = x.rolling(lookback_bars, min_periods=min_periods).mean()\n",
    "        my  = y.rolling(lookback_bars, min_periods=min_periods).mean()\n",
    "        mxy = (x * y).rolling(lookback_bars, min_periods=min_periods).mean()\n",
    "        mx2 = (x * x).rolling(lookback_bars, min_periods=min_periods).mean()\n",
    "\n",
    "        cov_xy = mxy - mx * my\n",
    "        var_x  = mx2 - mx * mx\n",
    "\n",
    "        ## OLS Definitions for beta and alpha\n",
    "        beta = cov_xy / var_x\n",
    "        beta = beta.where(var_x > var_floor)  # avoid divide-by-zero issues\n",
    "        alpha = my - beta * mx\n",
    "\n",
    "        if lag_params:\n",
    "            beta = beta.shift(1)\n",
    "            alpha = alpha.shift(1)\n",
    "\n",
    "        resid = y - (alpha + beta * x)\n",
    "\n",
    "        g[\"beta_btc\"] = beta\n",
    "        g[\"alpha_btc\"] = alpha\n",
    "        g[\"resid_btc_prev_4h\"] = resid\n",
    "        return g\n",
    "\n",
    "    out.loc[non_btc_mask] = (\n",
    "        out.loc[non_btc_mask]\n",
    "        .groupby(ticker_col, group_keys=False)\n",
    "        .apply(_per_ticker)\n",
    "    )\n",
    "\n",
    "    # BTC itself: not tradable in this sleeve, keep residual NaN\n",
    "    # (If you prefer explicitly 0, uncomment below.)\n",
    "    # out.loc[out[ticker_col] == btc_ticker, \"resid_btc_prev_4h\"] = 0.0\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a8edef-e476-43b6-95a2-f5df8b4da425",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_signal_btc_residual = build_return_features(\n",
    "    df_ticker_price_impute,\n",
    "    min_z_score_ticker_count=20,\n",
    "    fwd_return_period=3,\n",
    "    winsorize_fwd_return=True,\n",
    "    fwd_return_cap=0.50,\n",
    ")\n",
    "\n",
    "df_signal_btc_residual = add_btc_residual_returns(\n",
    "    df_signal_btc_residual,\n",
    "    btc_ticker=\"BTC-USD\",\n",
    "    ret_col=\"close_log_return_prev_4h\",\n",
    "    lookback_days=30,   # 180 bars\n",
    "    min_obs_days=10,    # 60 bars\n",
    "    lag_params=True,    # strict no-lookahead\n",
    ")\n",
    "\n",
    "# Now build your cross-sectional z-score on resid instead of raw return\n",
    "df_signal_btc_residual = calculate_z_score(\n",
    "    df_signal_btc_residual,\n",
    "    return_col=\"resid_btc_prev_4h\",\n",
    "    date_col=\"date\",\n",
    "    z_score_col_name=\"resid_btc_zscore_prev_4h\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ed5b7b-c1f5-4f23-89cb-caa62648eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Break the Z-Scores per period into Deciles\n",
    "def cs_bucket(group, col, q=10):\n",
    "    # cross-sectional bucketing within each timestamp\n",
    "    return pd.qcut(group[col], q=q, labels=False, duplicates=\"drop\")\n",
    "\n",
    "df_signal_btc_residual[\"quantile_bucket\"] = df_signal_btc_residual.groupby(\"date\", group_keys=False).apply(\n",
    "    lambda g: cs_bucket(g, \"resid_btc_zscore_prev_4h\", q=10)\n",
    ")\n",
    "\n",
    "## Identify bottom performing tickers per period\n",
    "q = 0.2  # bottom 20%\n",
    "df_signal_btc_residual[\"bottom_quintile_signal\"] = df_signal_btc_residual.groupby(\"date\")[\"resid_btc_zscore_prev_4h\"].transform(\n",
    "    lambda s: s <= s.quantile(q)\n",
    ")\n",
    "\n",
    "# compute signal on bar close, execute next bar open\n",
    "df_signal_btc_residual = df_signal_btc_residual.sort_values([\"ticker\", \"date\"])\n",
    "df_signal_btc_residual[\"trade_signal\"] = df_signal_btc_residual[\"bottom_quintile_signal\"].astype(float)\n",
    "df_signal_btc_residual[\"trade_signal_exec\"] = df_signal_btc_residual.groupby(\"ticker\")[\"trade_signal\"].fillna(0.0)\n",
    "\n",
    "# then use trade_signal_exec (not trade_signal) in open_new_vintage_positions\n",
    "df_signal_btc_residual_filt = df_signal_btc_residual[df_signal_btc_residual['resid_btc_zscore_prev_4h'].notnull()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd25e63-d661-4c1b-ad99-a86aa793b7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Backtest with Transaction Costs and Passive Trade Rate of 5%\n",
    "df_daily_position_with_t_cost_btc_resid, df_daily_portfolio_with_t_cost_btc_resid = run_mean_reversion_backtest(df_signal_btc_residual_filt, fwd_return_period=fwd_return_period, initial_capital=initial_capital,\n",
    "                                                                                                                cash_buffer_percentage=cash_buffer_percentage, transaction_cost_est=transaction_cost_est,\n",
    "                                                                                                                passive_trade_rate=passive_trade_rate, enable_fees=enable_fees, signal_col='trade_signal_exec')\n",
    "\n",
    "df_daily_portfolio_with_t_cost_btc_resid['daily_pct_returns'] = df_daily_portfolio_with_t_cost_btc_resid['total_portfolio_value'].pct_change()\n",
    "df_daily_portfolio_with_t_cost_btc_resid['count_of_trades'] = 1.0\n",
    "perf.calculate_risk_and_performance_metrics(df_daily_portfolio_with_t_cost_btc_resid, strategy_daily_return_col='daily_pct_returns', strategy_trade_count_col='count_of_trades', annual_rf=0.05,\n",
    "    annual_trading_days=365,\n",
    "    include_transaction_costs_and_fees=False,\n",
    "    transaction_cost_est=0.001,\n",
    "    passive_trade_rate=0.05,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e20966b-61bf-4d70-af8b-126ad2e44348",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_returns[['close_log_return_z_score_prev_4h','resid_btc_zscore_prev_4h']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7724231f-7584-4887-98b0-460a3a8606de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798379f3-379e-47c9-9495-a03cbe0a04cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c007863-1895-4db3-bb70-b2076aaf69d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4e33f7-61b3-4b0a-8d3e-8d197ce3406f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c94e281-3cbd-484b-8a85-19ec9b0ab677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d13bc81-7932-4d33-9319-37322f8d73ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8327c6b6-3dee-48f1-9414-132ed65de3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe54fcb-4c9e-485a-b970-a653428bb5ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b21da9-8c3a-4f49-ad17-728c898ec1b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5615836c-9d59-4c9f-a3d2-c076bb515bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65213382-697b-45b2-a1b8-2fc8d3d3284a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12feb19f-c686-4e1b-a59e-ebc208b8595a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b50f79c-f4c5-4dbf-ae48-439c73c7ebd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e15d51-0643-4449-9f1c-bbfb60fe3e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46c0716-1996-4e2a-9cd5-d5e70396b386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a979270-db26-4fe2-bb62-d248ea424bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cef95b-a4c0-4e87-b63f-dbb200aad379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853d691f-f202-4a70-a108-ed0523146d85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d504e5-74c3-4c00-a863-854efc6ec892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6c79f6-593f-4600-ad39-d7174b624d66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
